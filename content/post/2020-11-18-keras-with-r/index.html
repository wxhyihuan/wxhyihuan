---
title: blogtest
author: wxhyihuan
date: '2020-11-18'
slug: keras-with-r
output:
  blogdown::html_page:
    toc: true
    toc_depth: 3
    fig_width: 6
    dev: "svg"
    css: style.css
categories:
  - R
  - Keras
tags:
  - Keras
  - RStudio
  - R
draft: true
---

<script src="{{< blogdown/postref >}}index_files/kePrint/kePrint.js"></script>
<link href="{{< blogdown/postref >}}index_files/lightable/lightable.css" rel="stylesheet" />
  <link rel="stylesheet" href="style.css" type="text/css" />

<div id="TOC">
<ul>
<li><a href="#kerasæœºå™¨å­¦ä¹ çš„åŸºç¡€">Kerasæœºå™¨å­¦ä¹ çš„åŸºç¡€</a><ul>
<li><a href="#æ¦‚è§ˆ">æ¦‚è§ˆ</a></li>
<li><a href="#åŸºæœ¬çš„å›¾åƒåˆ†ç±»">åŸºæœ¬çš„å›¾åƒåˆ†ç±»</a></li>
<li><a href="#å›å½’">å›å½’</a></li>
<li><a href="#æ–‡å­—åˆ†ç±»">æ–‡å­—åˆ†ç±»</a></li>
<li><a href="#ä½¿ç”¨tfhubä¸­çš„å­¦ä¹ æ¨¡å‹">ä½¿ç”¨tfhubä¸­çš„å­¦ä¹ æ¨¡å‹</a></li>
<li><a href="#è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ">è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ</a></li>
<li><a href="#ä¿å­˜å’Œæ¢å¤æ¨¡å‹">ä¿å­˜å’Œæ¢å¤æ¨¡å‹</a></li>
</ul></li>
</ul>
</div>

<div class="blackbox">
<div class="center">
<p><strong>NOTICE!</strong></p>
</div>
<p>Thank you for noticing this <strong>new notice</strong>! Your noticing it has
been noted, and <em>will be reported to the authorities</em>! ğŸ‘</p>
</div>
<div id="kerasæœºå™¨å­¦ä¹ çš„åŸºç¡€" class="section level2">
<h2>Kerasæœºå™¨å­¦ä¹ çš„åŸºç¡€</h2>
<div id="æ¦‚è§ˆ" class="section level3">
<h3>æ¦‚è§ˆ</h3>
<p>æœ¬è¯¾ç¨‹åŒ…æ‹¬å…³äºä½¿ç”¨Kerasè¿›è¡Œæœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µçš„æ•™ç¨‹ã€‚</p>
<ul>
<li><p><a href="#åŸºæœ¬çš„å›¾åƒåˆ†ç±»">å›¾åƒåˆ†ç±»</a>ï¼šä½¿ç”¨fashingmistæ•°æ®é›†è¿›è¡Œå›¾åƒåˆ†ç±»ã€‚</p></li>
<li><p><a href="#åŸºæœ¬çš„å›¾åƒåˆ†ç±»">å›å½’</a>ï¼šä½¿ç”¨æ³¢å£«é¡¿ä½æˆ¿æ•°æ®é›†è¿›è¡Œå›å½’ã€‚</p></li>
<li><p><a href="#åŸºæœ¬çš„å›¾åƒåˆ†ç±»">æ–‡æœ¬åˆ†ç±»</a>ï¼šä½¿ç”¨IMDBæ•°æ®é›†è¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€‚</p></li>
<li><p><a href="#åŸºæœ¬çš„å›¾åƒåˆ†ç±»">è¿‡æ‹Ÿåˆå’Œä¸æ‹Ÿåˆ</a>ï¼šå­¦ä¹ MLä¸­çš„è¿™äº›é‡è¦æ¦‚å¿µã€‚</p></li>
<li><p><a href="#åŸºæœ¬çš„å›¾åƒåˆ†ç±»">ä¿å­˜å’Œæ¢å¤</a>ï¼šå­¦ä¹ å¦‚ä½•ä¿å­˜å’Œæ¢å¤TensorFlowæ¨¡å‹ã€‚</p></li>
</ul>
</div>
<div id="åŸºæœ¬çš„å›¾åƒåˆ†ç±»" class="section level3">
<h3>åŸºæœ¬çš„å›¾åƒåˆ†ç±»</h3>
<p>åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹æ¥åˆ†ç±»æœè£…å›¾åƒï¼Œå¦‚è¿åŠ¨é‹å’Œè¡¬è¡«ã€‚å¦‚æœæ‚¨ä¸ç†è§£æ‰€æœ‰çš„ç»†èŠ‚ä¹Ÿæ²¡å…³ç³»ï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„Kerasç¨‹åºçš„å¿«é€Ÿæ¦‚è¿°ï¼Œè¯¦ç»†ä¿¡æ¯å°†éšæˆ‘ä»¬çš„è¿›å±•è€Œè§£é‡Šã€‚</p>
<pre class="r"><code>library(tensorflow)
library(keras)</code></pre>
<div id="å¯¼å…¥fashion-mnistæ•°æ®é›†" class="section level4">
<h4>å¯¼å…¥Fashion MNISTæ•°æ®é›†</h4>
<pre class="r"><code>fashion_mnist &lt;- dataset_fashion_mnist()</code></pre>
<p>æœ¬æŒ‡å—ä½¿ç”¨<a href="https://github.com/zalandoresearch/fashion-mnist">Fashion MNIST</a>æ•°æ®é›†ï¼ŒåŒ…å«10ä¸ªç±»åˆ«çš„7ä¸‡å¼ ç°åº¦å›¾åƒã€‚è¿™äº›å›¾ç‰‡ä»¥ä½åˆ†è¾¨ç‡(28x28åƒç´ )å±•ç¤ºäº†è¡£ä¸ªåˆ«æœï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º:</p>
<div class="figure" style="text-align: center"><span id="fig:fig1"></span>
<img src="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/images/fashion-mnist-sprite.png" alt="Fashion MNIST æ ·å“(*Zalando, MIT License*)" width="60%" />
<p class="caption">
Figure 1: Fashion MNIST æ ·å“(<em>Zalando, MIT License</em>)
</p>
</div>
<p><a href="https://github.com/zalandoresearch/fashion-mnist">Fashion MNIST</a>çš„ç›®çš„æ˜¯æ›¿ä»£ç»å…¸çš„<a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>æ•°æ®é›†ï¼Œåè€…é€šå¸¸è¢«ç”¨ä½œè®¡ç®—æœºè§†è§‰æœºå™¨å­¦ä¹ ç¨‹åºçš„â€œHello, Worldâ€ã€‚<a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>æ•°æ®é›†åŒ…å«æ‰‹å†™æ•°å­—(0ã€1ã€2ç­‰)çš„å›¾åƒï¼Œå…¶æ ¼å¼ä¸æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨çš„è¡£ç‰©æ•°æ®ç›¸åŒã€‚</p>
<p>æœ¬æŒ‡å—ä½¿ç”¨<a href="https://github.com/zalandoresearch/fashion-mnist">Fashion MNIST</a>è¿›è¡Œå„ç§å„æ ·çš„æ“ä½œï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªæ¯”å¸¸è§„<a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>æ›´å…·æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚è¿™ä¸¤ä¸ªæ•°æ®é›†éƒ½ç›¸å¯¹è¾ƒå°ï¼Œç”¨äºéªŒè¯ç®—æ³•æ˜¯å¦å¦‚é¢„æœŸçš„é‚£æ ·å·¥ä½œã€‚å®ƒä»¬æ˜¯æµ‹è¯•å’Œè°ƒè¯•ä»£ç çš„è‰¯å¥½èµ·ç‚¹ã€‚</p>
<p>æˆ‘ä»¬å°†ä½¿ç”¨60,000å¼ å›¾åƒæ¥è®­ç»ƒç½‘ç»œï¼Œå¹¶ä½¿ç”¨10,000å¼ å›¾åƒæ¥è¯„ä¼°ç½‘ç»œå­¦ä¹ åˆ†ç±»å›¾åƒçš„å‡†ç¡®æ€§ã€‚ä½ å¯ä»¥ç›´æ¥ä»Kerasè®¿é—®<a href="https://github.com/zalandoresearch/fashion-mnist">Fashion MNIST</a>ã€‚</p>
<pre class="r"><code>fashion_mnist &lt;- dataset_fashion_mnist()

c(train_images, train_labels) %&lt;-% fashion_mnist$train
c(test_images, test_labels) %&lt;-% fashion_mnist$test</code></pre>
<p>ç°åœ¨æˆ‘ä»¬æœ‰å››ä¸ªæ•°ç»„: train_imageså’Œtrain_labelsæ•°ç»„æ˜¯è®­ç»ƒé›†â€”â€”å³æ¨¡å‹ç”¨æ¥å­¦ä¹ çš„æ•°æ®ã€‚æ¨¡å‹æ ¹æ®æµ‹è¯•é›†è¿›è¡Œæµ‹è¯•çš„æµ‹è¯•æ•°æ®:test_imageså’Œtest_labelsã€‚</p>
æ¯ä¸ªå›¾åƒéƒ½æ˜¯28x28ä¸ªæ•°ç»„ï¼Œåƒç´ å€¼åœ¨0åˆ°255ä¹‹é—´ã€‚æ ‡ç­¾ä¸ºæ•´æ•°æ•°ç»„ï¼Œå–å€¼èŒƒå›´ä¸º0 ~ 9ã€‚è¿™äº›å¯¹åº”äºå›¾åƒæ‰€ä»£è¡¨çš„æœè£…ç±»åˆ«:
<table class=" lightable-paper lightable-striped lightable-classic-2" style='font-family: "Arial Narrow", arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto; font-family: "Arial Narrow", "Source Sans Pro", sans-serif; margin-left: auto; margin-right: auto;'>
<caption>
<span id="tab:tablable">Table 1: </span>æœè£…ç±»åˆ«åŠå¯¹åº”çš„æ•°å­—ç¼–å·
</caption>
<thead>
<tr>
<th style="text-align:center;">
Digit
</th>
<th style="text-align:center;">
Class
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
T-shirt/top
</td>
</tr>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
Trouser
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
Pullover
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
Dress
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
Coat
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
Sandal
</td>
</tr>
<tr>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
Shirt
</td>
</tr>
<tr>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
Sneaker
</td>
</tr>
<tr>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
Bag
</td>
</tr>
<tr>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
Ankle boot
</td>
</tr>
</tbody>
</table>
<p>æ¯ä¸ªå›¾åƒéƒ½æ˜ å°„åˆ°å•ä¸ªæ ‡ç­¾ã€‚ç”±äºç±»åä¸åŒ…å«åœ¨æ•°æ®é›†ä¸­ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªå‘é‡ä¸­ï¼Œä»¥ä¾¿ç¨åç»˜åˆ¶å›¾åƒæ—¶ä½¿ç”¨ã€‚</p>
<pre class="r"><code>class_names = c(&#39;T-shirt/top&#39;,              &#39;Trouser&#39;,
                &#39;Pullover&#39;,           &#39;Dress&#39;,
                &#39;Coat&#39;,               &#39;Sandal&#39;,
                &#39;Shirt&#39;,              &#39;Sneaker&#39;,
                &#39;Bag&#39;,                &#39;Ankle boot&#39;)</code></pre>
</div>
<div id="æ£€è§†æ•°æ®" class="section level4">
<h4>æ£€è§†æ•°æ®</h4>
<p>åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç ”ç©¶ä¸€ä¸‹æ•°æ®é›†çš„æ ¼å¼ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè®­ç»ƒé›†ä¸­æœ‰60000å¼ å›¾åƒï¼Œæ¯å¼ å›¾åƒç”¨28x28åƒç´ è¡¨ç¤ºã€‚</p>
<pre class="r"><code># è®­ç»ƒé›†ä¸­æœ‰60000å¼ å›¾åƒï¼Œæ¯å¼ å›¾åƒç”¨28x28åƒç´ è¡¨ç¤ºã€‚
dim(train_images)
dim(train_labels)
# è®­ç»ƒé›†æ¯ä¸ªæ ‡ç­¾æ˜¯0åˆ°9ä¹‹é—´çš„æ•´æ•°:
table(train_labels)

# æµ‹è¯•é›†ä¸­æœ‰10000å¼ å›¾åƒã€‚åŒæ ·ï¼Œæ¯å¼ å›¾åƒç”¨28Ã—28åƒç´ è¡¨ç¤º
dim(test_images)
dim(test_labels)
# æµ‹è¯•é›†æ¯ä¸ªæ ‡ç­¾æ˜¯0åˆ°9ä¹‹é—´çš„æ•´æ•°:
table(test_labels)
</code></pre>
</div>
<div id="æ•°æ®é¢„å¤„ç†" class="section level4">
<h4>æ•°æ®é¢„å¤„ç†</h4>
<p>åœ¨è®­ç»ƒç½‘ç»œä¹‹å‰ï¼Œå¿…é¡»å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚å¦‚æœä½ æ£€æŸ¥è®­ç»ƒé›†ä¸­çš„ç¬¬ä¸€å¼ å›¾åƒï¼Œä½ ä¼šçœ‹åˆ°åƒç´ å€¼çš„èŒƒå›´æ˜¯0åˆ°255:</p>
<pre class="r"><code>library(tidyr)
library(ggplot2)

image_1 &lt;- as.data.frame(train_images[1, , ])
colnames(image_1) &lt;- seq_len(ncol(image_1))
image_1$y &lt;- seq_len(nrow(image_1))
image_1 &lt;- gather(image_1, &quot;x&quot;, &quot;value&quot;, -y)
image_1$x &lt;- as.integer(image_1$x)

ggplot(image_1, aes(x = x, y = y, fill = value)) +
  geom_tile() +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;black&quot;, na.value = NA) +
  scale_y_reverse() +
  theme_minimal() +
  theme(panel.grid = element_blank())   +
  theme(aspect.ratio = 1) +
  xlab(&quot;&quot;) +
  ylab(&quot;&quot;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig2"></span>
<img src="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification_files/figure-html/unnamed-chunk-9-1.png" alt="æ£€æŸ¥è®­ç»ƒé›†ä¸­çš„ç¬¬ä¸€å¼ å›¾åƒ" width="49%" />
<p class="caption">
Figure 2: æ£€æŸ¥è®­ç»ƒé›†ä¸­çš„ç¬¬ä¸€å¼ å›¾åƒ
</p>
</div>
<p>åœ¨è¾“å…¥åˆ°ç¥ç»ç½‘ç»œæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬å°†è¿™äº›å€¼ç¼©æ”¾åˆ°0åˆ°1çš„èŒƒå›´å†…ã€‚å¯¹äºè¿™ä¸ªï¼Œæˆ‘ä»¬åªéœ€è¦é™¤ä»¥255ã€‚é‡è¦çš„æ˜¯è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä»¥ç›¸åŒçš„æ–¹å¼è¿›è¡Œé¢„å¤„ç†:</p>
<pre class="r"><code>train_images &lt;- train_images / 255
test_images &lt;- test_images / 255</code></pre>
<p>æ˜¾ç¤ºè®­ç»ƒé›†çš„å‰25å¼ å›¾åƒï¼Œå¹¶åœ¨æ¯å¼ å›¾åƒä¸‹é¢æ˜¾ç¤ºç±»åã€‚éªŒè¯æ•°æ®çš„æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œå¦‚æœæ²¡é—®é¢˜ï¼Œæ¥ä¸‹æ¥å°±å¯ä»¥æ„å»ºå’Œè®­ç»ƒæ¨¡å‹äº†ã€‚</p>
<pre class="r"><code>par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs=&#39;i&#39;, yaxs=&#39;i&#39;)
for (i in 1:25) { 
  img &lt;- train_images[i, , ]
  img &lt;- t(apply(img, 2, rev)) 
  image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = &#39;n&#39;, yaxt = &#39;n&#39;,
        main = paste(class_names[train_labels[i] + 1]))
}</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig3"></span>
<img src="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification_files/figure-html/unnamed-chunk-11-1.png" alt="è®­ç»ƒé›†çš„å‰25å¼ å›¾åƒå’Œç±»åã€‚" width="60%" />
<p class="caption">
Figure 3: è®­ç»ƒé›†çš„å‰25å¼ å›¾åƒå’Œç±»åã€‚
</p>
</div>
</div>
<div id="æ„å»ºæ¨¡å‹" class="section level4">
<h4>æ„å»ºæ¨¡å‹</h4>
<p>æ„å»ºç¥ç»ç½‘ç»œéœ€è¦é…ç½®æ¨¡å‹çš„å±‚ï¼Œç„¶åç¼–è¯‘æ¨¡å‹ã€‚</p>
<div id="è®¾ç½®ç¥ç»å±‚" class="section level5">
<h5>è®¾ç½®ç¥ç»å±‚</h5>
<p>ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ„ä»¶æ˜¯å±‚(ç¥ç»å±‚)ã€‚å±‚ä»è¾“å…¥åˆ°å®ƒä»¬çš„æ•°æ®ä¸­æå–è¡¨å¾ã€‚å¹¶ä¸”ï¼Œå¸Œæœ›è¿™äº›è¡¨å¾å¯¹äºæ‰‹å¤´çš„é—®é¢˜æ›´æœ‰æ„ä¹‰ã€‚</p>
<p>å¤§éƒ¨åˆ†æ·±åº¦å­¦ä¹ æ˜¯å°†ç®€å•çš„å±‚é“¾æ¥åœ¨ä¸€èµ·æ„æˆçš„ï¼Œå…¶ä¸­å¤§å¤šæ•°å±‚ï¼ˆä¾‹å¦‚layer_denseï¼‰åœ¨è®­ç»ƒæ¨¡å‹æ—¶éƒ½æœ‰å¯ä»¥è®¾å®šå­¦ä¹ çš„å‚æ•°ã€‚</p>
<pre class="r"><code>model &lt;- keras_model_sequential()
model %&gt;%
  layer_flatten(input_shape = c(28, 28)) %&gt;%
  layer_dense(units = 128, activation = &#39;relu&#39;) %&gt;%
  layer_dense(units = 10, activation = &#39;softmax&#39;)
</code></pre>
<p>è¯¥æ¨¡å‹çš„ç¬¬ä¸€å±‚layer_flattenå°†å›¾åƒæ ¼å¼ä»2ç»´æ•°ç»„(28x28åƒç´ )è½¬æ¢ä¸º28*28 = 784åƒç´ çš„1ç»´æ•°ç»„ã€‚å¯ä»¥æŠŠè¿™ä¸€å±‚æƒ³è±¡æˆå°†å›¾åƒä¸­çš„åƒç´ è¡Œæ‹†æ•£å¹¶æ’åˆ—èµ·æ¥ã€‚è¿™ä¸€å±‚æ²¡æœ‰å‚æ•°éœ€è¦å­¦ä¹ ï¼›å®ƒåªæ˜¯é‡æ–°æ ¼å¼åŒ–æ•°æ®ã€‚</p>
<p>åœ¨åƒç´ æ•°æ®è¢«å•ä¸€åŒ–åï¼Œæ¨¡å‹ç”±ä¸¤ä¸ªå¯†é›†å±‚ç»„æˆã€‚è¿™äº›æ˜¯ç´§å¯†ç›¸è¿æˆ–å®Œå…¨ç›¸è¿çš„ç¥ç»å±‚ã€‚ç¬¬ä¸€å¯†é›†å±‚æœ‰128ä¸ªèŠ‚ç‚¹(æˆ–ç¥ç»å…ƒ)ã€‚ç¬¬äºŒå±‚(ä¹Ÿæ˜¯æœ€åä¸€å±‚)æ˜¯ä¸€ä¸ªæœ‰10ä¸ªèŠ‚ç‚¹çš„softmaxå±‚â€”â€”å®ƒè¿”å›ä¸€ä¸ª10ä¸ªæ¦‚ç‡å¾—åˆ†çš„æ•°ç»„ï¼Œæ€»å’Œä¸º1ã€‚æ¯ä¸ªèŠ‚ç‚¹éƒ½åŒ…å«ä¸€ä¸ªåˆ†æ•°ï¼Œè¯¥åˆ†æ•°è¡¨ç¤ºå½“å‰å›¾åƒå±äº10ä¸ªæ•°å­—ç±»ä¹‹ä¸€çš„æ¦‚ç‡ã€‚</p>
</div>
<div id="ç¼–è¯‘æ¨¡å‹" class="section level5">
<h5>ç¼–è¯‘æ¨¡å‹</h5>
<p>åœ¨æ¨¡å‹å‡†å¤‡å¥½è¿›è¡Œè®­ç»ƒä¹‹å‰ï¼Œè¿˜éœ€è¦è¿›è¡Œä¸€äº›è®¾ç½®ã€‚è¿™äº›æ˜¯åœ¨æ¨¡å‹çš„ç¼–è¯‘æ­¥éª¤ä¸­æ·»åŠ çš„:
- Losså‡½æ•°(Loss function): è¿™åº¦é‡äº†æ¨¡å‹åœ¨è®­ç»ƒæœŸé—´çš„ç²¾ç¡®åº¦ã€‚æˆ‘ä»¬å¸Œæœ›æœ€å°åŒ–è¿™ä¸ªå‡½æ•°ï¼Œä»¥â€œå¼•å¯¼â€æ¨¡å‹æœæ­£ç¡®çš„æ–¹å‘å‘å±•ã€‚
- ä¼˜åŒ–å™¨(Optimizer ): è¿™æ˜¯æ¨¡å‹å¦‚ä½•æ ¹æ®å®ƒçœ‹åˆ°çš„æ•°æ®å’Œå®ƒçš„æŸå¤±å‡½æ•°è¿›è¡Œæ›´æ–°çš„æ–¹å¼ã€‚
- åº¦é‡æ ‡å‡†(Metrics): ç”¨äºç›‘æ§åŸ¹è®­å’Œæµ‹è¯•æ­¥éª¤ã€‚ä¸‹é¢çš„ç¤ºä¾‹ä½¿ç”¨å‡†ç¡®åº¦ï¼Œå³æ­£ç¡®åˆ†ç±»çš„å›¾åƒçš„æ¯”ä¾‹ã€‚</p>
<pre class="r"><code>model %&gt;% compile(
  optimizer = &#39;adam&#39;, 
  loss = &#39;sparse_categorical_crossentropy&#39;,
  metrics = c(&#39;accuracy&#39;)
)</code></pre>
</div>
<div id="è®­ç»ƒæ¨¡å‹" class="section level5">
<h5>è®­ç»ƒæ¨¡å‹</h5>
<p>è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹éœ€è¦ä»¥ä¸‹æ­¥éª¤:</p>
<ul>
<li>å°†è®­ç»ƒæ•°æ®æä¾›ç»™æ¨¡å‹â€”â€”åœ¨æœ¬ä¾‹ä¸­æ˜¯train_imageså’Œtrain_labelsæ•°ç»„ã€‚</li>
<li>è¿™ä¸ªæ¨¡å‹å­¦ä¼šäº†æŠŠå›¾åƒå’Œæ ‡ç­¾è”ç³»èµ·æ¥ã€‚</li>
<li>æˆ‘ä»¬è¦æ±‚æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹â€”â€”åœ¨æœ¬ä¾‹ä¸­æ˜¯test_imagesæ•°ç»„ã€‚æˆ‘ä»¬éªŒè¯é¢„æµ‹æ˜¯å¦ä¸test_labelsæ•°ç»„ä¸­çš„æ ‡ç­¾ç›¸åŒ¹é…ã€‚</li>
</ul>
<p>è¦å¼€å§‹è®­ç»ƒï¼Œè°ƒç”¨fitæ–¹æ³•-æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œâ€œæ‹Ÿåˆ(fit)â€:</p>
<pre class="r"><code>model %&gt;% fit(train_images, train_labels, epochs = 5, verbose = 2)
### Train on 60000 samples
### Epoch 1/5
### 60000/60000 - 2s - loss: 0.4945 - accuracy: 0.8262
### Epoch 2/5
### 60000/60000 - 2s - loss: 0.3751 - accuracy: 0.8643
### Epoch 3/5
### 60000/60000 - 2s - loss: 0.3354 - accuracy: 0.8758
### Epoch 4/5
### 60000/60000 - 2s - loss: 0.3135 - accuracy: 0.8854
### Epoch 5/5
### 60000/60000 - 2s - loss: 0.2956 - accuracy: 0.8918</code></pre>
<p>å½“æ¨¡å‹è¿è¡Œæ—¶ï¼ŒæŸå¤±å’Œç²¾åº¦æŒ‡æ ‡å°±ä¼šæ˜¾ç¤ºå‡ºæ¥ã€‚è¯¥æ¨¡å‹çš„ç²¾åº¦çº¦ä¸º0.8918(89.18%)ã€‚</p>
</div>
<div id="è¯„ä¼°å‡†ç¡®æ€§" class="section level5">
<h5>è¯„ä¼°å‡†ç¡®æ€§</h5>
<p>æ¥ä¸‹æ¥ï¼Œæ¯”è¾ƒæ¨¡å‹åœ¨æµ‹è¯•æ•°æ®é›†ä¸­çš„æ‰§è¡Œæƒ…å†µ:</p>
<pre class="r"><code>score &lt;- model %&gt;% evaluate(test_images, test_labels, verbose = 0)
score&lt;-as.list(score)
cat(&#39;Test loss:&#39;, score$loss, &quot;\n&quot;)
### Test loss: 0.3755946
cat(&#39;Test accuracy:&#39;, score$acc, &quot;\n&quot;)
### Test accuracy: 0.8644</code></pre>
<p>ç»“æœè¡¨æ˜ï¼Œæµ‹è¯•æ•°æ®é›†çš„ç²¾åº¦(86.44%)ç•¥ä½äºè®­ç»ƒæ•°æ®é›†çš„ç²¾åº¦(89.18%)ã€‚è®­ç»ƒç²¾åº¦å’Œæµ‹è¯•ç²¾åº¦ä¹‹é—´çš„å·®è·å°±æ˜¯<strong>è¿‡æ‹Ÿåˆ</strong>çš„ä¸€ä¸ªä¾‹å­ã€‚è¿‡æ‹Ÿåˆæ˜¯æŒ‡æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„è¡¨ç°æ¯”åœ¨è®­ç»ƒæ•°æ®ä¸Šå·®ã€‚</p>
</div>
<div id="ä½œå‡ºé¢„æµ‹" class="section level5">
<h5>ä½œå‡ºé¢„æµ‹</h5>
<p>ç»è¿‡è®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥é¢„æµ‹ä¸€äº›å›¾åƒã€‚</p>
<pre class="r"><code>predictions &lt;- model %&gt;% predict(test_images)</code></pre>
<p>è¿™é‡Œï¼Œæ¨¡å‹é¢„æµ‹äº†æµ‹è¯•é›†ä¸­æ¯ä¸ªå›¾åƒçš„æ ‡ç­¾ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ç¬¬ä¸€ä¸ªé¢„æµ‹:</p>
<pre class="r"><code>predictions[1, ]
### [1] 5.465935e-06 1.288366e-07 3.570543e-06 1.659937e-08 2.075325e-05
### [6] 1.836076e-02 2.499909e-06 1.217376e-01 2.614871e-05 8.598431e-01</code></pre>
<p>é¢„æµ‹ç»“æœæ˜¯ä¸€ä¸ªç”±10ä¸ªæ•°å­—ç»„æˆçš„æ•°ç»„ã€‚è¿™äº›æ•°å€¼æè¿°äº†æ¨¡å‹åˆ¤æ–­è¯¥å›¾åƒå¯¹åº”äº10ç§ä¸åŒçš„æœè£…ç±»å‹çš„â€œç½®ä¿¡åº¦â€ã€‚ æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å“ªä¸ªæ ‡ç­¾çš„ç½®ä¿¡åº¦æœ€é«˜ï¼š</p>
<pre class="r"><code>which.max(predictions[1, ])
### [1] 10</code></pre>
<p>ç”±äºæ ‡ç­¾(Labels)æ˜¯åŸºäº0èµ·å§‹çš„ï¼Œç„¶è€ŒRè¯­è¨€çš„æ•°æ®é›†æ ‡ç­¾æ˜¯ç”±1èµ·å§‹çš„ï¼Œæ‰€ä»¥predictions[1, ]é¢„æµ‹çš„æ ‡ç­¾ä¸º9ã€‚æ¨¡å‹éå¸¸ç¡®ä¿¡è¿™å¼ ç…§ç‰‡æ˜¯ä¸€ä»¶è¸é´(Ankle boot)ã€‚æˆ‘ä»¬å¯ä»¥æ£€æŸ¥æµ‹è¯•æ ‡ç­¾ï¼Œçœ‹çœ‹é¢„æµ‹ç»“æœæ˜¯å¦æ­£ç¡®ã€‚</p>
<pre class="r"><code>test_labels[1]</code></pre>
<p>æˆ–è€…ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥å¾—åˆ°ç±»é¢„æµ‹:</p>
<pre class="r"><code>class_pred &lt;- model %&gt;% predict_classes(test_images)
class_pred[1:20]
####  [1] 9 2 1 1 6 1 4 6 5 7 4 5 5 3 4 1 2 2 8 0</code></pre>
<p>è®©æˆ‘ä»¬ç”¨å‡ å¹…å›¾æ¥è¯´æ˜æ¨¡å‹çš„é¢„æµ‹ã€‚æ­£ç¡®çš„é¢„æµ‹æ ‡ç­¾ä¸ºç»¿è‰²ï¼Œé”™è¯¯çš„é¢„æµ‹æ ‡ç­¾ä¸ºçº¢è‰²ã€‚</p>
<pre class="r"><code>par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs=&#39;i&#39;, yaxs=&#39;i&#39;)
for (i in 1:25) { 
  img &lt;- test_images[i, , ]
  img &lt;- t(apply(img, 2, rev)) 
  # subtract 1 as labels go from 0 to 9
  predicted_label &lt;- which.max(predictions[i, ]) - 1
  true_label &lt;- test_labels[i]
  if (predicted_label == true_label) {
    color &lt;- &#39;#008800&#39; 
  } else {
    color &lt;- &#39;#bb0000&#39;
  }
  image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = &#39;n&#39;, yaxt = &#39;n&#39;,
        main = paste0(class_names[predicted_label + 1], &quot; (&quot;,
                      class_names[true_label + 1], &quot;)&quot;),
        col.main = color)
}</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig4"></span>
<img src="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification_files/figure-html/unnamed-chunk-21-1.png" alt="æ£€è§†éƒ¨åˆ†æ¨¡å‹é¢„æµ‹ç»“æœï¼Œæ­£ç¡®çš„é¢„æµ‹æ ‡ç­¾ä¸ºç»¿è‰²ï¼Œé”™è¯¯çš„é¢„æµ‹æ ‡ç­¾ä¸ºçº¢è‰²" width="60%" />
<p class="caption">
Figure 4: æ£€è§†éƒ¨åˆ†æ¨¡å‹é¢„æµ‹ç»“æœï¼Œæ­£ç¡®çš„é¢„æµ‹æ ‡ç­¾ä¸ºç»¿è‰²ï¼Œé”™è¯¯çš„é¢„æµ‹æ ‡ç­¾ä¸ºçº¢è‰²
</p>
</div>
<p>æœ€åï¼Œåˆ©ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹å•ä¸ªå›¾åƒè¿›è¡Œé¢„æµ‹ã€‚</p>
<pre class="r"><code># ä»æµ‹è¯•æ•°æ®é›†ä¸­è·å–ä¸€ä¸ªå›¾åƒ
# æ³¨æ„ä¿æŒå´å²–æ•°æ®çš„ç»´åº¦ä¿¡æ¯ï¼Œè¿™æ˜¯æ¨¡å‹æ‰€æœŸæœ›çš„ï¼Œåˆ©ç”¨drop = FALSEå¸®åŠ©å…³æ‰è¿”å›å‘é‡
str(test_images)
# num [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...
img &lt;- test_images[1, , , drop = FALSE]
dim(img)
# [1]  1 28 28</code></pre>
<p>ç°åœ¨é¢„æµ‹å›¾åƒ:</p>
<pre class="r"><code>predictions &lt;- model %&gt;% predict(img)
predictions
###              [,1]         [,2]         [,3]         [,4]         [,5]
### [1,] 5.465944e-06 1.288367e-07 3.570535e-06 1.659934e-08 2.075324e-05
###            [,6]         [,7]      [,8]         [,9]    [,10]
### [1,] 0.01836077 2.499906e-06 0.1217377 2.614871e-05 0.859843
</code></pre>
<p><em>predict</em>è¿”å›ä¸€ä¸ªåŒ…å«å­åˆ—è¡¨çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå­åˆ—è¡¨å¯¹åº”æ•°æ®æ‰¹ä¸­çš„æŸå›¾åƒã€‚åœ¨è¿™é‡Œçš„æ‰¹å¤„ç†ä¸­è·å–æˆ‘ä»¬çš„(å”¯ä¸€çš„)å›¾åƒçš„é¢„æµ‹:</p>
<pre class="r"><code># å› ä¸ºæ ‡ç­¾æ˜¯åŸºäº0çš„ï¼Œæ‰€ä»¥å‡å»1
prediction &lt;- predictions[1, ] - 1
which.max(prediction)
# [1] 10

# æˆ–è€…ï¼Œç›´æ¥å†æ¬¡è·å–ç±»é¢„æµ‹:
class_pred &lt;- model %&gt;% predict_classes(img)
class_pred
# [1] 9</code></pre>
</div>
</div>
</div>
<div id="å›å½’" class="section level3">
<h3>å›å½’</h3>
<p>åœ¨å›å½’é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯é¢„æµ‹ä¸€ä¸ªè¿ç»­å€¼çš„è¾“å‡ºï¼Œå¦‚ä»·æ ¼æˆ–æ¦‚ç‡ã€‚ä¸æ­¤å½¢æˆå¯¹æ¯”çš„æ˜¯åˆ†ç±»é—®é¢˜ï¼Œåœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯é¢„æµ‹ä¸€ä¸ªç¦»æ•£çš„æ ‡ç­¾(ä¾‹å¦‚ï¼Œä¸€å¼ å›¾ç‰‡ä¸­åŒ…å«ä¸€ä¸ªè‹¹æœæˆ–æ©˜å­)ã€‚</p>
<p>æœ¬ç¬”è®°å»ºç«‹äº†ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹20ä¸–çºª70å¹´ä»£ä¸­æœŸæ³¢å£«é¡¿éƒŠåŒºæˆ¿å±‹çš„ä¸­é—´ä»·æ ¼ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä¸ºæ¨¡å‹æä¾›ä¸€äº›å…³äºéƒŠåŒºçš„æ•°æ®ç‚¹ï¼Œå¦‚çŠ¯ç½ªç‡å’Œå½“åœ°æˆ¿äº§ç¨ç‡ã€‚</p>
<div id="æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†" class="section level4">
<h4>æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†</h4>
<p><a href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html">æ³¢å£«é¡¿æˆ¿ä»·</a>æ•°æ®å¯ä»¥ç›´æ¥ä»kerasè·å¾—ã€‚</p>
<pre class="r"><code>library(keras)
library(tfdatasets)

boston_housing &lt;- dataset_boston_housing()

c(train_data, train_labels) %&lt;-% boston_housing$train
c(test_data, test_labels) %&lt;-% boston_housing$test
</code></pre>
<div id="å®ä¾‹å’Œç‰¹ç‚¹" class="section level5">
<h5>å®ä¾‹å’Œç‰¹ç‚¹</h5>
<p>è¿™ä¸ªæ•°æ®é›†æ¯”æˆ‘ä»¬ç›®å‰ä½¿ç”¨çš„å…¶ä»–æ•°æ®é›†è¦å°å¾—å¤š:å®ƒæ€»å…±æœ‰506ä¸ªä¾‹å­ï¼Œåˆ†åˆ«åœ¨404ä¸ªè®­ç»ƒç¤ºä¾‹å’Œ102ä¸ªæµ‹è¯•ç¤ºä¾‹ä¹‹é—´åˆ’åˆ†:</p>
<pre class="r"><code>paste0(&quot;Training entries: &quot;, length(train_data), &quot;, labels: &quot;, length(train_labels))
### [1] &quot;Training entries: 5252, labels: 404&quot;</code></pre>
<p>æ•°æ®é›†åŒ…å«13ä¸ªä¸åŒçš„ç‰¹å¾ï¼š</p>
<ul>
<li><p>äººå‡çŠ¯ç½ªç‡ã€‚</p></li>
<li><p>è¶…è¿‡25,000å¹³æ–¹è‹±å°ºçš„ä½å®…ç”¨åœ°æ¯”ä¾‹ã€‚</p></li>
<li><p>æ¯ä¸ªåŸé•‡éé›¶å”®ä¸šåŠ¡è‹±äº©çš„æ¯”ä¾‹ã€‚</p></li>
<li><p>æŸ¥å°”æ–¯æ²³è™šæ‹Ÿå˜é‡ï¼ˆå¦‚æœæŸç¼šæ²³æµï¼Œåˆ™ä¸º1ï¼›å¦åˆ™ä¸º0ï¼‰ã€‚</p></li>
<li><p>ä¸€æ°§åŒ–æ°®æµ“åº¦ï¼ˆåƒä¸‡åˆ†ä¹‹ä¸€ï¼‰ã€‚</p></li>
<li><p>æ¯ä¸ªä½å®…çš„å¹³å‡æˆ¿é—´æ•°ã€‚</p></li>
<li><p>1940å¹´ä¹‹å‰å»ºé€ çš„è‡ªæœ‰ä½æˆ¿çš„æ¯”ä¾‹ã€‚</p></li>
<li><p>åˆ°äº”ä¸ªæ³¢å£«é¡¿å°±ä¸šä¸­å¿ƒçš„åŠ æƒè·ç¦»ã€‚</p></li>
<li><p>å¾„å‘å…¬è·¯çš„å¯è¾¾æ€§æŒ‡æ•°ã€‚</p></li>
<li><p>æ¯10,000ç¾å…ƒçš„å…¨å€¼è´¢äº§ç¨ç‡ã€‚</p></li>
<li><p>å„é•‡çš„å¸ˆç”Ÿæ¯”ä¾‹ã€‚</p></li>
<li><p>1000 *ï¼ˆBk-0.63ï¼‰** 2å…¶ä¸­Bkæ˜¯æŒ‰åŸé•‡åˆ’åˆ†çš„é»‘äººæ¯”ä¾‹ã€‚</p></li>
<li><p>äººå£ä¸­å¤„äºè¾ƒä½åœ°ä½çš„ç™¾åˆ†æ¯”ã€‚</p></li>
</ul>
<p>è¾“å…¥æ•°æ®çš„æ¯ä¸ªç‰¹æ€§äº’ç›¸ä½¿ç”¨ä¸åŒçš„æ ‡åº¦å­˜å‚¨ã€‚æœ‰äº›ç‰¹å¾ç”¨0åˆ°1ä¹‹é—´çš„æ¯”ä¾‹è¡¨ç¤ºï¼Œæœ‰äº›ç‰¹å¾ç”¨1åˆ°12ä¹‹é—´çš„èŒƒå›´è¡¨ç¤ºï¼Œæœ‰äº›ç‰¹å¾ç”¨0åˆ°100ä¹‹é—´çš„èŒƒå›´è¡¨ç¤ºï¼Œä»¥æ­¤ç±»æ¨ã€‚</p>
<pre class="r"><code># æ˜¾ç¤ºæ ·å“ç‰¹å¾ï¼Œæ³¨æ„ä¸åŒçš„æ ‡åº¦
train_data[1, ] 
###  [1]   1.23247   0.00000   8.14000   0.00000   0.53800   6.14200  91.70000
###  [8]   3.97690   4.00000 307.00000  21.00000 396.90000  18.72000</code></pre>
<p>ä¸ºæ•°æ®æ·»åŠ åˆ—åï¼Œä»¥ä¾¿æ›´å¥½åœ°æ£€æŸ¥æ•°æ®ã€‚</p>
<pre class="r"><code>library(dplyr)

column_names &lt;- c(&#39;CRIM&#39;, &#39;ZN&#39;, &#39;INDUS&#39;, &#39;CHAS&#39;, &#39;NOX&#39;, &#39;RM&#39;, &#39;AGE&#39;, 
                  &#39;DIS&#39;, &#39;RAD&#39;, &#39;TAX&#39;, &#39;PTRATIO&#39;, &#39;B&#39;, &#39;LSTAT&#39;)

train_df &lt;- train_data %&gt;% 
  as_tibble(.name_repair = &quot;minimal&quot;) %&gt;% 
  setNames(column_names) %&gt;% 
  mutate(label = train_labels)

test_df &lt;- test_data %&gt;% 
  as_tibble(.name_repair = &quot;minimal&quot;) %&gt;% 
  setNames(column_names) %&gt;% 
  mutate(label = test_labels)</code></pre>
</div>
<div id="æ ‡ç­¾" class="section level5">
<h5>æ ‡ç­¾</h5>
<p>è¿™äº›æ ‡ç­¾æ˜¯çš„æˆ¿ä»·å•ä½ï¼šåƒç¾å…ƒã€‚</p>
<pre class="r"><code>train_labels[1:10]
###  [1] 15.2 42.3 50.0 21.1 17.7 18.5 11.3 15.6 15.6 14.4</code></pre>
</div>
</div>
<div id="æ ‡å‡†åŒ–ç‰¹å¾æ•°æ®" class="section level4">
<h4>æ ‡å‡†åŒ–ç‰¹å¾æ•°æ®</h4>
<p>å»ºè®®å¯¹ä½¿ç”¨ä¸åŒæ ‡åº¦å’ŒèŒƒå›´çš„ç‰¹å¾æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ã€‚è™½ç„¶æ¨¡å‹åœ¨æ²¡æœ‰ç‰¹å¾å½’ä¸€åŒ–çš„æƒ…å†µä¸‹å¯èƒ½ä¹Ÿä¼šæ”¶æ•›ï¼Œä½†è¿™ä¼šä½¿è®­ç»ƒå˜å¾—æ›´åŠ å›°éš¾ï¼Œå¹¶ä¸”ä¼šä½¿å¾—åˆ°çš„æ¨¡å‹æ›´åŠ ä¾èµ–äºè¾“å…¥ä¸­ä½¿ç”¨çš„å•å…ƒçš„é€‰æ‹©ã€‚</p>
<p>æˆ‘ä»¬å°†ä½¿ç”¨åœ¨<em>tfdatasets</em>åŒ…ä¸­å®ç°çš„<em>feature_spec</em>æ¥å£è¿›è¡Œæ ‡å‡†åŒ–ã€‚<em>feature_columns</em>æ¥å£å…è®¸å¯¹è¡¨æ•°æ®è¿›è¡Œå…¶ä»–å¸¸è§çš„é¢„å¤„ç†æ“ä½œã€‚</p>
<pre class="r"><code>library(tfdatasets)

spec &lt;- feature_spec(train_df, label ~ . ) %&gt;% 
  step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %&gt;% 
  fit()

spec
### â”€â”€ Feature Spec â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
### A feature_spec with 13 steps.
### Fitted: TRUE 
### â”€â”€ Steps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
### The feature_spec has 1 dense features.
### StepNumericColumn: CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT 
### â”€â”€ Dense features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</code></pre>
<p>ä½¿ç”¨<em>tfdatasets</em>åˆ›å»ºçš„<em>spec</em>å¯ä»¥ä¸<em>layer_dense_features</em>ä¸€èµ·ä½¿ç”¨ï¼Œç›´æ¥åœ¨TensorFlowå›¾ä¸­æ‰§è¡Œé¢„å¤„ç†ã€‚</p>
<p>æˆ‘ä»¬å¯ä»¥çœ‹çœ‹è¿™ä¸ª<em>spec</em>åˆ›å»ºçš„å¯†é›†å±‚çš„è¾“å‡º:</p>
<pre class="r"><code>layer &lt;- layer_dense_features(
  feature_columns = dense_features(spec), 
  dtype = tf$float32
)
layer(train_df)</code></pre>
<p>æ³¨æ„ï¼Œè¿™å°†è¿”å›ä¸€ä¸ªæ¢ç®—åå€¼å¾—çš„æ•°æ®çŸ©é˜µ(åœ¨æœ¬ä¾‹ä¸­è¯´ï¼Œå®ƒæ˜¯ä¸€ä¸ªäºŒç»´çš„Tensor)ã€‚</p>
<div id="åˆ›å»ºæ¨¡å‹" class="section level5">
<h5>åˆ›å»ºæ¨¡å‹</h5>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬æ„å»ºæ¨¡å‹ã€‚è¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨Keras functional APIâ€”â€”è¿™æ˜¯ä½¿ç”¨feature_spec APIæ—¶æ¨èçš„æ–¹å¼ã€‚æ³¨æ„ï¼Œæˆ‘ä»¬åªéœ€è¦ä»æˆ‘ä»¬åˆšåˆšåˆ›å»ºçš„<em>spec</em>ä¸­ä¼ é€’<em>dense_features</em>ã€‚</p>
<pre class="r"><code>input &lt;- layer_input_from_dataset(train_df %&gt;% select(-label))

output &lt;- input %&gt;% 
  layer_dense_features(dense_features(spec)) %&gt;% 
  layer_dense(units = 64, activation = &quot;relu&quot;) %&gt;%
  layer_dense(units = 64, activation = &quot;relu&quot;) %&gt;%
  layer_dense(units = 1) 

model &lt;- keras_model(input, output)

summary(model)</code></pre>
<p>ç„¶åæˆ‘ä»¬ç”¨ä»¥ä¸‹æ–¹æ³•ç¼–è¯‘æ¨¡å‹:</p>
<pre class="r"><code>model %&gt;% 
  compile(
    loss = &quot;mse&quot;,
    optimizer = optimizer_rmsprop(),
    metrics = list(&quot;mean_absolute_error&quot;)
  )</code></pre>
<p>æˆ‘ä»¬å°†æŠŠæ¨¡å‹æ„å»ºä»£ç åŒ…è£…æˆä¸€ä¸ªå‡½æ•°ï¼Œä»¥ä¾¿èƒ½å¤Ÿåœ¨ä¸åŒçš„å®éªŒä¸­é‡ç”¨å®ƒã€‚è¯·è®°ä½ï¼ŒKeras <em>fit</em>ä¼šå°±åœ°ä¿®æ”¹æ¨¡å‹ã€‚</p>
<pre class="r"><code>build_model &lt;- function() {
  input &lt;- layer_input_from_dataset(train_df %&gt;% select(-label))
  
  output &lt;- input %&gt;% 
    layer_dense_features(dense_features(spec)) %&gt;% 
    layer_dense(units = 64, activation = &quot;relu&quot;) %&gt;%
    layer_dense(units = 64, activation = &quot;relu&quot;) %&gt;%
    layer_dense(units = 1) 
  
  model &lt;- keras_model(input, output)
  
  model %&gt;% 
    compile(
      loss = &quot;mse&quot;,
      optimizer = optimizer_rmsprop(),
      metrics = list(&quot;mean_absolute_error&quot;)
    )
  
  model
}</code></pre>
</div>
<div id="è®­ç»ƒæ¨¡å‹-1" class="section level5">
<h5>è®­ç»ƒæ¨¡å‹</h5>
<p>å¯¹æ¨¡å‹è¿›è¡Œäº†500ä¸ªepochsè®­ç»ƒï¼Œå¹¶åœ¨keras_training_historyå¯¹è±¡ä¸­è®°å½•äº†è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®æ€§ã€‚ æˆ‘ä»¬è¿˜å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰å›è°ƒæ–¹æ³•ï¼Œå°†æ¯ä¸ªepochsçš„é»˜è®¤è®­ç»ƒè¾“å‡ºæ›¿æ¢ä¸ºä¸€ä¸ªç‚¹ã€‚</p>
<pre class="r"><code># é€šè¿‡æ¯å®Œä¸€ä¸ªepochsæ‰“å°ä¸€ä¸ªç‚¹æ˜¾ç¤ºæ¥è®­ç»ƒè¿›åº¦ã€‚
print_dot_callback &lt;- callback_lambda(
  on_epoch_end = function(epoch, logs) {
    if (epoch %% 80 == 0) cat(&quot;\n&quot;)
    cat(&quot;.&quot;)
  }
)    

model1 &lt;- build_model()

history1 &lt;- model1 %&gt;% fit(
  x = train_df %&gt;% select(-label),
  y = train_df$label,
  epochs = 500,
  validation_split = 0.2,
  verbose = 0,
  callbacks = list(print_dot_callback)
)</code></pre>
<p>ç°åœ¨ï¼Œæˆ‘ä»¬ä½¿ç”¨å­˜å‚¨åœ¨<em>history</em>å˜é‡ä¸­çš„æŒ‡æ ‡æ¥å¯è§†åŒ–æ¨¡å‹çš„è®­ç»ƒè¿›åº¦ã€‚æˆ‘ä»¬æƒ³ç”¨è¿™äº›æ•°æ®æ¥ç¡®å®šåœ¨æ¨¡å‹åœæ­¢è¿›æ­¥ä¹‹å‰éœ€è¦è®­ç»ƒå¤šä¹…ã€‚</p>
<pre class="r"><code>library(ggplot2)
plot(history1)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig5"></span>
<img src="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_regression_files/figure-html/unnamed-chunk-13-1.png" alt="è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´" width="60%" />
<p class="caption">
Figure 5: è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´
</p>
</div>
<p>è¿™å¼ å›¾è¡¨æ˜¾ç¤ºï¼Œåœ¨å¤§çº¦200ä¸ªepochsä¹‹åï¼Œæ¨¡å‹å‡ ä¹æ²¡æœ‰ä»€ä¹ˆæ”¹è¿›ã€‚è®©æˆ‘ä»¬æ›´æ–°<em>fit</em>æ–¹æ³•ï¼Œå½“éªŒè¯åˆ†æ•°æ²¡æœ‰æé«˜æ—¶è‡ªåŠ¨åœæ­¢è®­ç»ƒã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªå›è°ƒæ¥æµ‹è¯•æ¯ä¸ªepochçš„è®­ç»ƒæ¡ä»¶ã€‚å¦‚æœç»è¿‡äº†ä¸€å®šæ•°é‡çš„epochï¼Œæ²¡æœ‰æ˜¾ç¤ºå‡ºæ”¹è¿›ï¼Œå®ƒä¼šè‡ªåŠ¨åœæ­¢è®­ç»ƒã€‚</p>
<pre class="r"><code># patience parameteræ˜¯è¦æ£€æŸ¥æ”¹è¿›çš„æ—¶æœŸæ•°ã€‚
early_stop &lt;- callback_early_stopping(monitor = &quot;val_loss&quot;, patience = 20)

model2 &lt;- build_model()

history2 &lt;- model2 %&gt;% fit(
  x = train_df %&gt;% select(-label),
  y = train_df$label,
  epochs = 500,
  validation_split = 0.2,
  verbose = 0,
  callbacks = list(early_stop)
)

plot(history2)
#Error in data.frame(epoch = seq_len(x$params$epochs), value = unlist(values),  :
#  arguments imply differing number of rows: 500, 368, 2000

str(history2)
List of 2
# $ params :List of 3
#  ..$ verbose: int 0
#  ..$ epochs : int 500
#  ..$ steps  : int 11
# $ metrics:List of 4
#  ..$ loss                   : num [1:92] 494 398 309 226 157 ...
#  ..$ mean_absolute_error    : num [1:92] 20.4 17.9 15.4 12.7 10.3 ...
#  ..$ val_loss               : num [1:92] 504 410 319 227 169 ...
#  ..$ val_mean_absolute_error: num [1:92] 20.5 18.2 15.5 12.5 10.3 ...
# - attr(*, &quot;class&quot;)= chr &quot;keras_training_history&quot;

history2$metrics$loss&lt;-c(history2$metrics$loss,rep(NA,history2$params$epochs-length(history2$metrics$loss)))
history2$metrics$mean_absolute_error&lt;-c(history2$metrics$mean_absolute_error,rep(NA,history2$params$epochs-length(history2$metrics$mean_absolute_error)))
history2$metrics$val_loss&lt;-c(history2$metrics$val_loss,rep(NA,history2$params$epochs-length(history2$metrics$val_loss)))
history2$metrics$val_mean_absolute_error&lt;-c(history2$metrics$val_mean_absolute_error,rep(NA,history2$params$epochs-length(history2$metrics$val_mean_absolute_error)))

plot(history2)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig6"></span>
<img src="https://s3.ax1x.com/2020/12/25/rWN4UK.png" alt="è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´2" width="60%" />
<p class="caption">
Figure 6: è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´2
</p>
</div>
<p>è¯¥å›¾æ˜¾ç¤ºå¹³å‡è¯¯å·®çº¦ä¸º2500ç¾å…ƒã€‚ è¿™ä¸ªå¥½å—ï¼Ÿ å¥½å§ï¼Œå½“æŸäº›æ ‡ç­¾ä»…ä¸º15,000ç¾å…ƒæ—¶ï¼Œ2,500ç¾å…ƒå¹¶ä¸æ˜¯å¾®ä¸è¶³é“çš„æ•°é¢ã€‚</p>
<p>è®©æˆ‘ä»¬çœ‹çœ‹æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°å¦‚ä½•ï¼š</p>
<pre class="r"><code>c(loss, mae) %&lt;-% (model1 %&gt;% evaluate(test_df %&gt;% select(-label), test_df$label, verbose = 0))
paste0(&quot;Mean absolute error on test set: $&quot;, sprintf(&quot;%.2f&quot;, mae * 1000))
# [1] &quot;Mean absolute error on test set: $2903.54&quot;

c(loss2, mae2) %&lt;-% (model2 %&gt;% evaluate(test_df %&gt;% select(-label), test_df$label, verbose = 0))
paste0(&quot;Mean absolute error on test set: $&quot;, sprintf(&quot;%.2f&quot;, mae2 * 1000))
# [1] &quot;Mean absolute error on test set: $3034.21&quot;</code></pre>
</div>
<div id="ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹" class="section level5">
<h5>ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹</h5>
<p>æœ€åï¼Œä½¿ç”¨æµ‹è¯•é›†ä¸­çš„æ•°æ®é¢„æµ‹ä¸€äº›æˆ¿ä»·ï¼š</p>
<pre class="r"><code>model&lt;-model2
test_predictions &lt;- model2 %&gt;% predict(test_df %&gt;% select(-label))
test_predictions[ , 1]
#  [1]  7.355123 17.675547 19.973572 32.076920 23.902725 19.619333 26.324997
#  [8] 21.288185 18.688896 21.509230 17.615231 16.178177 15.070681 39.809803
# [15] 20.088022 19.298931 25.012741 21.137566 17.962463 34.908684 10.398927
# [22] 14.056004 19.420004 13.601798 19.115681 24.314400 29.992420 29.077190
# [29]  9.517317 20.587708 18.875362 14.579519 31.711769 23.667265 17.235331
# [36]  7.131071 14.524129 17.223494 18.043385 24.907063 30.337440 26.690973
# [43] 12.751408 38.409725 28.244289 23.861389 24.783478 15.663984 22.516479
# [50] 20.941717 32.775738 19.605915  9.694613 13.944555 33.987289 26.646553
# [57] 11.730441 46.070683 32.869167 23.082375 24.691891 16.289280 15.114546
# [64] 18.146664 21.945438 21.380447 13.035687 21.360455 12.413694  5.442961
# [71] 34.066624 29.388529 24.445929 12.748474 23.918005 18.901218 19.777264
# [78] 21.921507 33.413986  9.202299 19.752489 36.857082 15.715253 12.539826
# [85] 16.558025 18.447201 20.974888 18.670275 21.062746 29.102020 19.141819
# [92] 18.646065 24.691332 41.360500 32.999287 18.146885 34.936665 51.217838
# [99] 25.158466 45.784126 31.594339 19.733921
#</code></pre>
</div>
<div id="ç»“è®º" class="section level5">
<h5>ç»“è®º</h5>
<p>æœ¬ç¬”è®°æœ¬ä»‹ç»äº†ä¸€äº›å¤„ç†å›å½’é—®é¢˜çš„æŠ€æœ¯ã€‚</p>
<ul>
<li><p>å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æ˜¯ç”¨äºå›å½’é—®é¢˜ï¼ˆä¸åŒäºåˆ†ç±»é—®é¢˜ï¼‰çš„å¸¸è§æŸå¤±å‡½æ•°ã€‚</p></li>
<li><p>åŒæ ·ï¼Œç”¨äºå›å½’çš„è¯„ä¼°æŒ‡æ ‡ä¹Ÿä¸åŒäºåˆ†ç±»ã€‚ å¸¸è§çš„å›å½’æŒ‡æ ‡æ˜¯å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ã€‚</p></li>
<li><p>å½“è¾“å…¥æ•°æ®è¦ç´ çš„å€¼å…·æœ‰ä¸åŒèŒƒå›´æ—¶ï¼Œæ¯ä¸ªè¦ç´ éƒ½åº”ç‹¬ç«‹ç¼©æ”¾ã€‚</p></li>
<li><p>å¦‚æœè®­ç»ƒæ•°æ®ä¸å¤šï¼Œåˆ™æœ€å¥½é€‰æ‹©ä¸€ä¸ªéšè—å±‚å¾ˆå°‘çš„å°å‹ç½‘ç»œï¼Œä»¥å…è¿‡åº¦æ‹Ÿåˆã€‚</p></li>
<li><p>æå‰åœæ­¢æ˜¯é˜²æ­¢è¿‡åº¦æ‹Ÿåˆçš„æœ‰ç”¨æŠ€æœ¯ã€‚</p></li>
</ul>
</div>
</div>
</div>
<div id="æ–‡å­—åˆ†ç±»" class="section level3">
<h3>æ–‡å­—åˆ†ç±»</h3>
<p><em>æ³¨æ„ï¼šæœ¬æ•™ç¨‹è¦æ±‚TensorFlowç‰ˆæœ¬&gt; = 2.1</em></p>
<p>æœ¬æ•™ç¨‹ä½¿ç”¨è¯„è®ºæ–‡æœ¬å°†ç”µå½±è¯„è®ºåˆ†ä¸ºæ­£é¢è¯„è®ºæˆ–è´Ÿé¢è¯„è®ºã€‚è¿™æ˜¯äºŒè¿›åˆ¶ï¼ˆæˆ–ä¸¤ç±»ï¼‰åˆ†ç±»çš„ç¤ºä¾‹ï¼Œå®ƒæ˜¯ä¸€ç§é‡è¦ä¸”å¹¿æ³›é€‚ç”¨çš„æœºå™¨å­¦ä¹ é—®é¢˜ã€‚</p>
<p>æˆ‘ä»¬å°†ä½¿ç”¨<a href="https://keras.rstudio.com/reference/dataset_imdb.html">IMDB</a>æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«æ¥è‡ª<a href="https://www.imdb.com/">Internet</a>ç”µå½±æ•°æ®åº“çš„50,000ä¸ªç”µå½±è¯„è®ºçš„æ–‡æœ¬ã€‚è¿™äº›å†…å®¹åˆ†ä¸º25,000æ¡ç”¨äºåŸ¹è®­çš„è¯„è®ºå’Œ25,000æ¡ç”¨äºæµ‹è¯•çš„è¯„è®ºã€‚è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ˜¯å¹³è¡¡çš„ï¼Œè¿™æ„å‘³ç€å®ƒä»¬åŒ…å«ç›¸åŒæ•°é‡çš„æ­£é¢å’Œè´Ÿé¢è¯„è®ºã€‚</p>
<p>å…ˆå¯åŠ¨å¹¶åŠ è½½Kerasä»¥åŠå…¶ä»–ä¸€äº›å¿…éœ€çš„åº“ã€‚</p>
<pre class="r"><code>library(keras)
library(dplyr)
library(ggplot2)
library(purrr)</code></pre>
<div id="ä¸‹è½½ç”µå½±è¯„è®ºæ•°æ®é›†" class="section level4">
<h4>ä¸‹è½½ç”µå½±è¯„è®ºæ•°æ®é›†</h4>
<p>æˆ‘ä»¬å°†ä½¿ç”¨ç”±Bo Pangå’ŒLillian Leeåˆ›å»ºçš„ç”µå½±è¯„è®ºæ•°æ®é›†ã€‚åœ¨ä½œè€…çš„å…è®¸ä¸‹ï¼ŒNLTKé‡æ–°å‘å¸ƒäº†è¯¥æ•°æ®é›†ã€‚</p>
<p>æ•°æ®é›†å¯åœ¨<a href="https://www.kaggle.com/nltkdata/movie-review#movie_review.csv">æ­¤å¤„</a>æ‰¾åˆ° ï¼Œå¹¶å¯ä»Kaggle UIæˆ–ä½¿ç”¨<a href="https://github.com/rstudio/pins">pins</a>åŒ…ä¸‹è½½ã€‚</p>
<p>å¦‚æœè¦ä½¿ç”¨<a href="https://github.com/rstudio/pins">pins</a> ï¼Œè¯·æŒ‰ç…§è¿™é‡Œçš„<a href="https://rstudio.github.io/pins/articles/boards-kaggle.html">æ•™ç¨‹</a>æ³¨å†ŒKaggleç”»æ¿ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥è¿è¡Œï¼š</p>
<pre class="r"><code>library(pins)
board_register(&quot;kaggle&quot;, token = &quot;/home/wangxh/Soft/kaggle.json&quot;)
paths &lt;- pins::pin_get(&quot;nltkdata/movie-review&quot;, &quot;kaggle&quot;)
# æˆ‘ä»¬åªéœ€è¦ movie_review.csv æ–‡ä»¶
path &lt;- paths[1]</code></pre>
<p>ç°åœ¨ï¼Œä½¿ç”¨åŒ…ä¸­çš„<em>read_csv</em>å‡½æ•°å°†å…¶è¯»å–åˆ°Rä¸­readrã€‚</p>
<pre class="r"><code>df &lt;- readr::read_csv(path)
head(df)
### # A tibble: 6 x 6
###   fold_id cv_tag html_id sent_id text                                 tag  
###     &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                                &lt;chr&gt;
### 1       0 cv000    29590       0 films adapted from comic books haveâ€¦ pos  
### 2       0 cv000    29590       1 for starters , it was created by alâ€¦ pos  
### 3       0 cv000    29590       2 to say moore and campbell thoroughlâ€¦ pos  
### 4       0 cv000    29590       3 &quot;the book ( or \&quot; graphic novel , \â€¦ pos  
### 5       0 cv000    29590       4 in other words , don&#39;t dismiss thisâ€¦ pos  
### 6       0 cv000    29590       5 if you can get past the whole comicâ€¦ pos</code></pre>
</div>
<div id="æ£€è§†æ•°æ®-1" class="section level4">
<h4>æ£€è§†æ•°æ®</h4>
<p>è®©æˆ‘ä»¬èŠ±ä¸€ç‚¹æ—¶é—´æ¥ç†è§£æ•°æ®çš„æ ¼å¼ã€‚æ•°æ®é›†æœ‰6ä¸‡è¡Œï¼Œæ¯è¡Œä»£è¡¨ç”µå½±è¯„è®ºã€‚è¯¥textåˆ—å…·æœ‰å®é™…è¯„è®ºï¼Œå¹¶ä¸”tag ä»£è¡¨å‘æˆ‘ä»¬æ˜¾ç¤ºäº†è¯¥è¯„è®ºçš„åˆ†ç±»æƒ…ç»ªã€‚æ•°æ®é›†é‡Œå¤§çº¦ä¸€åŠçš„è¯„è®ºæ˜¯è´Ÿé¢çš„(neg)ï¼Œå¦ä¸€åŠæ˜¯æ­£é¢çš„(pos)ã€‚</p>
<pre class="r"><code>df$text[1]
### [1] &quot;films adapted from comic books have had plenty of success , whether they&#39;re about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there&#39;s never really been a comic book like from hell before .&quot;

df %&gt;% count(tag)
# # A tibble: 2 x 2
#   tag       n
#   &lt;chr&gt; &lt;int&gt;
# 1 neg   31783
# 2 pos   32937

str(df)
# tibble [64,720 Ã— 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
 # $ fold_id: num [1:64720] 0 0 0 0 0 0 0 0 0 0 ...
 # $ cv_tag : chr [1:64720] &quot;cv000&quot; &quot;cv000&quot; &quot;cv000&quot; &quot;cv000&quot; ...
 # $ html_id: num [1:64720] 29590 29590 29590 29590 29590 ...
 # $ sent_id: num [1:64720] 0 1 2 3 4 5 6 7 8 9 ...
 # $ text   : chr [1:64720] &quot;films adapted from comic books have had plenty of # success , whether they&#39;re about superheroes ( batman , superm&quot;| __truncated__ # &quot;for starters , it was created by alan moore ( and eddie campbell ) , who # brought the medium to a whole new leve&quot;| __truncated__ &quot;to say moore and # campbell thoroughly researched the subject of jack the ripper would be like # saying michael jac&quot;| __truncated__ &quot;the book ( or \&quot; graphic novel , \&quot; if you # will ) is over 500 pages long and includes nearly 30 more that consi&quot;| # __truncated__ ...
 # $ tag    : chr [1:64720] &quot;pos&quot; &quot;pos&quot; &quot;pos&quot; &quot;pos&quot; ...
 # - attr(*, &quot;spec&quot;)=
 #  .. cols(
 #  ..   fold_id = col_double(),
 #  ..   cv_tag = col_character(),
 #  ..   html_id = col_double(),
 #  ..   sent_id = col_double(),
 #  ..   text = col_character(),
 #  ..   tag = col_character()
 #  .. )
</code></pre>
<p>è®©æˆ‘ä»¬å°†æ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸¤éƒ¨åˆ†ï¼š</p>
<pre class="r"><code>training_id &lt;- sample.int(nrow(df), size = nrow(df)*0.8)
training &lt;- df[training_id,]
testing &lt;- df[-training_id,]</code></pre>
<p>äº†è§£æ¯ä¸ªè¯„è®ºä¸­å•è¯æ•°é‡çš„å¤§è‡´åˆ†å¸ƒæƒ…å†µä¹Ÿå¾ˆæœ‰ç”¨ã€‚</p>
<pre class="r"><code>df$text %&gt;% 
  strsplit(&quot; &quot;) %&gt;% 
  sapply(length) %&gt;% 
  summary()
###    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
###    1.00   14.00   21.00   23.06   30.00  179.00</code></pre>
</div>
<div id="å‡†å¤‡æ•°æ®" class="section level4">
<h4>å‡†å¤‡æ•°æ®</h4>
<p>è¯„è®ºï¼ˆæ–‡æœ¬ï¼‰åœ¨è¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¹‹å‰å¿…é¡»å…ˆè½¬æ¢ä¸ºå¼ é‡(Tensor)ã€‚ é¦–å…ˆï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå­—å…¸å’Œä¸€ä¸ªæ•´æ•°ä»£è¡¨æ¯10,000ä¸ªæœ€å¸¸ç”¨çš„è¯ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¯ä¸ªè¯„è®ºéƒ½å°†ç”±æ•´æ•°åºåˆ—è¡¨ç¤ºã€‚</p>
<p>ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼è¡¨ç¤ºè¯„è®ºï¼š</p>
<ul>
<li><p>ç¬¬ä¸€ç§æ˜¯å¯¹æ•°ç»„è¿›è¡Œä¸€æ¬¡çƒ­ç¼–ç ï¼Œä»¥å°†å…¶è½¬æ¢ä¸ºç”±0å’Œ1ç»„æˆçš„å‘é‡ã€‚ä¾‹å¦‚ï¼Œåºåˆ—[3ï¼Œ5]å°†å˜æ¢ä¸ºä¸€ä¸ª10,000ç»´å‘é‡ï¼Œé™¤äº†ç´¢å¼•3å’Œ5éƒ½æ˜¯1ä¹‹å¤–ï¼Œå®ƒä»¬å…¨ä¸ºé›¶ã€‚ç„¶åï¼Œå°†å…¶è®¾ç½®ä¸ºæˆ‘ä»¬ç½‘ç»œä¸­çš„ç¬¬ä¸€å±‚ï¼Œå¯†é›†å±‚(dense layer )ï¼Œå³å¯ä»¥å¤„ç†æµ®ç‚¹çŸ¢é‡æ•°æ®çš„ä¸€å±‚ã€‚ä½†æ˜¯ï¼Œæ­¤æ–¹æ³•éœ€è¦å ç”¨å¤§é‡å†…å­˜ï¼Œè€Œä¸”éœ€è¦ä½¿ç”¨<em>num_words </em> num_reviews*å¤§å°çŸ©é˜µã€‚</p></li>
<li><p>ç¬¬äºŒç§æ˜¯å¯ä»¥å¡«å……æ•°ç»„ï¼Œä½¿å®ƒä»¬éƒ½å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼Œç„¶ååˆ›å»ºç»´åº¦ä¸ºnum_examples * max_lengthçš„å¼ é‡ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨èƒ½å¤Ÿå¤„ç†æ­¤ç»´åº¦çš„åµŒå…¥å±‚(embedding layer )ä½œä¸ºç½‘ç»œä¸­çš„ç¬¬ä¸€å±‚ã€‚</p></li>
</ul>
<p>åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç¬¬äºŒç§æ–¹æ³•ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®šä¹‰æ–‡æœ¬å‘é‡åŒ–å±‚(Text Vectorization layer)ï¼Œå®ƒå°†è´Ÿè´£è·å–å­—ç¬¦ä¸²è¾“å…¥å¹¶å°†å…¶è½¬æ¢ä¸ºå¼ é‡(Tensor)ã€‚</p>
<pre class="r"><code>num_words &lt;- 10000
max_length &lt;- 50
text_vectorization &lt;- layer_text_vectorization(
  max_tokens = num_words, 
  output_sequence_length = max_length, 
)</code></pre>
<p>ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦<em>adapt</em>æ–‡æœ¬å‘é‡åŒ–å±‚ã€‚adaptå±‚å°†äº†è§£æ•°æ®é›†ä¸­çš„å»é‡å¤è¯æ±‡ï¼Œå¹¶ä¸ºæ¯ä¸ªå•è¯åˆ†é…ä¸€ä¸ªæ•´æ•°å€¼ã€‚</p>
<pre class="r"><code>text_vectorization %&gt;% 
  adapt(df$text)</code></pre>
<p>æ‚¨å¯ä»¥çœ‹åˆ°æ–‡æœ¬çŸ¢é‡åŒ–å±‚å¦‚ä½•è½¬æ¢å…¶è¾“å…¥æ•°æ®çš„ï¼š</p>
<pre class="r"><code>text_vectorization(matrix(df$text[1], ncol = 1))
### tf.Tensor(
### [[  68 2835   30  359 1662   33   91 1056    5  632  631  321   41 7803
###    709 4865 1767   48 7600 1337  398 5161   48    2    1 1808 1800  148
###     17  140  109   90   69    3  359  408   40   30  503  142    0    0
###      0    0    0    0    0    0    0    0]], shape=(1, 50), dtype=int64)</code></pre>
</div>
<div id="å»ºç«‹æ¨¡å‹" class="section level4">
<h4>å»ºç«‹æ¨¡å‹</h4>
<p>ç¥ç»ç½‘ç»œæ˜¯é€šè¿‡å †å å±‚åˆ›å»ºçš„-è¿™éœ€è¦ä¸¤ä¸ªä¸»è¦çš„ä½“ç³»ç»“æ„å†³ç­–ï¼š</p>
<ul>
<li><p>åœ¨æ¨¡å‹ä¸­ä½¿ç”¨å¤šå°‘å±‚ï¼Ÿ</p></li>
<li><p>æ¯å±‚ä½¿ç”¨å¤šå°‘ä¸ªéšè—å•å…ƒï¼Ÿ</p></li>
</ul>
<p>åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œè¾“å…¥æ•°æ®ç”±å•è¯ç´¢å¼•æ•°ç»„ç»„æˆã€‚è¦é¢„æµ‹çš„æ ‡ç­¾ä¸º0æˆ–1(Negæˆ–è€…Pos)ã€‚è®©æˆ‘ä»¬ä¸ºè¿™ä¸ªé—®é¢˜å»ºç«‹ä¸€ä¸ªæ¨¡å‹ï¼š</p>
<pre class="r"><code>input &lt;- layer_input(shape = c(1), dtype = &quot;string&quot;)

output &lt;- input %&gt;% 
  text_vectorization() %&gt;% 
  layer_embedding(input_dim = num_words + 1, output_dim = 16) %&gt;%
  layer_global_average_pooling_1d() %&gt;%
  layer_dense(units = 16, activation = &quot;relu&quot;) %&gt;%
  layer_dropout(0.5) %&gt;% 
  layer_dense(units = 1, activation = &quot;sigmoid&quot;)

model &lt;- keras_model(input, output)
</code></pre>
<p>ä¾æ¬¡å †å å„å±‚ä»¥æ„å»ºåˆ†ç±»å™¨ï¼š</p>
<ul>
<li><p>ç¬¬ä¸€å±‚æ˜¯åµŒå…¥å±‚(embedding layer)ã€‚è¯¥å±‚è¾“å…¥æ•´æ•°ç¼–ç çš„è¯æ±‡è¡¨ï¼Œå¹¶ä¸ºæ¯ä¸ªå•è¯ç´¢å¼•æŸ¥æ‰¾åµŒå…¥å‘é‡ã€‚è¿™äº›å‘é‡å°†ç”¨äºè®­ç»ƒæ¨¡å‹ã€‚åµŒå…¥å‘é‡å°†æ·»åŠ åˆ°è¾“å‡ºæ•°ç»„ï¼Œè¾“å‡ºç»“æœçš„ç»´åº¦ä¸ºï¼šï¼ˆbatch, sequence, embeddingï¼‰ã€‚</p></li>
<li><p>æ¥ä¸‹æ¥ï¼Œglobal_average_pooling_1då±‚ å±‚é€šè¿‡å¯¹åºåˆ—ç»´åº¦è¿›è¡Œå¹³å‡ï¼Œä¸ºæ¯ä¸ªç¤ºä¾‹è¿”å›ä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¾“å‡ºå‘é‡ã€‚è¿™å…è®¸æ¨¡å‹ä»¥æœ€ç®€å•çš„æ–¹å¼å¤„ç†å¯å˜é•¿åº¦çš„è¾“å…¥ã€‚</p></li>
<li><p>è¯¥å›ºå®šé•¿åº¦çš„è¾“å‡ºå‘é‡é€šè¿‡ç®¡é“ä¼ è¾“åˆ°è®¾ç½®åŒ…å«æœ‰16ä¸ªéšè—å•å…ƒçš„å®Œå…¨è¿æ¥å±‚(dense layer)ã€‚</p></li>
<li><p>æœ€åä¸€å±‚æ˜¯å¯†é›†è¿æ¥çš„å•ä¸ªè¾“å‡ºèŠ‚ç‚¹ã€‚ä½¿ç”¨<em>sigmoid</em>æ¿€æ´»å‡½æ•°ï¼Œæ­¤å€¼æ˜¯0åˆ°1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºæ¦‚ç‡æˆ–ç½®ä¿¡åº¦ã€‚</p></li>
</ul>
<div id="éšè—çš„å•å…ƒ" class="section level5">
<h5>éšè—çš„å•å…ƒ</h5>
<p>ä¸Šé¢çš„æ¨¡å‹åœ¨è¾“å…¥å’Œè¾“å‡ºä¹‹é—´æœ‰ä¸¤ä¸ªä¸­é—´å±‚æˆ–â€œéšè—â€å±‚( intermediate or â€œhiddenâ€ layers)ã€‚è¾“å‡ºçš„æ•°é‡(å•å…ƒã€èŠ‚ç‚¹æˆ–ç¥ç»å…ƒ)æ˜¯è¯¥å±‚çš„è¡¨å¾çš„ç©ºé—´çš„ç»´æ•°ã€‚æ¢å¥è¯è¯´ï¼Œç½‘ç»œæ¨¡å‹å†å­¦ä¹ ä¸€ä¸ªå†…éƒ¨è¡¨å¾çš„è‡ªç”±åº¦æ˜¯ä»»æ„çš„ã€‚</p>
</div>
<div id="æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨" class="section level5">
<h5>æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨</h5>
<p>ä¸€ä¸ªæ¨¡å‹éœ€è¦ä¸€ä¸ªæŸå¤±å‡½æ•°å’Œä¸€ä¸ªè®­ç»ƒä¼˜åŒ–å™¨ã€‚ç”±äºæœ¬æ¡ˆä¾‹æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œæ¨¡å‹è¾“å‡ºä¸€ä¸ªæ¦‚ç‡(å¸¦æœ‰sigmoidæ¿€æ´»çš„å•ä¸ªå•å…ƒå±‚)ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<em>binary_crossentropy</em>æŸå¤±å‡½æ•°(Loss function)ã€‚</p>
<p>è¿™ä¸æ˜¯æŸå¤±å‡½æ•°çš„å”¯ä¸€é€‰æ‹©ï¼Œä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥é€‰æ‹©<em>mean_squared_error</em>ã€‚ä½†æ˜¯ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œ<em>binary_crossenpy</em>æ›´é€‚åˆå¤„ç†æ¦‚ç‡â€”â€”å®ƒæµ‹é‡æ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„â€œè·ç¦»â€ï¼Œæˆ–è€…åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œå³æ˜¯çœŸå®åˆ†å¸ƒå’Œé¢„æµ‹ä¹‹é—´çš„â€œè·ç¦»â€ã€‚</p>
<p>ç¨åï¼Œå½“æˆ‘ä»¬æ¢è®¨å›å½’é—®é¢˜(æ¯”å¦‚ï¼Œé¢„æµ‹æˆ¿å±‹ä»·æ ¼)æ—¶ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨å¦ä¸€ä¸ªç§°ä¸ºå‡æ–¹è¯¯å·®( mean squared error)çš„æŸå¤±å‡½æ•°ã€‚</p>
<p>ç°åœ¨ï¼Œé…ç½®æ¨¡å‹ä¸­ä½¿ç”¨çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ï¼š</p>
<pre class="r"><code>model %&gt;% compile(
  optimizer = &#39;adam&#39;,
  loss = &#39;binary_crossentropy&#39;,
  metrics = list(&#39;accuracy&#39;)
)</code></pre>
</div>
</div>
<div id="è®­ç»ƒæ¨¡å‹-2" class="section level4">
<h4>è®­ç»ƒæ¨¡å‹</h4>
<p>æ¨¡å‹è®­ç»ƒä½¿ç”¨åŒ…å«512ä¸ªæ ·æœ¬çš„å°æ‰¹é‡æ•°æ®é›†è¿›è¡Œ20ä¸ªepochsï¼Œä¹Ÿå°±æ˜¯å¯¹x_trainå’Œy_trainå¼ é‡ä¸­çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œ20æ¬¡è¿­ä»£ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œåœ¨éªŒè¯é›†çš„10,000ä¸ªæ ·æœ¬ä¸Šç›‘æ§æ¨¡å‹çš„æŸå¤±å’Œå‡†ç¡®æ€§:</p>
<pre class="r"><code>history &lt;- model %&gt;% fit(
  training$text,
  as.numeric(training$tag == &quot;pos&quot;),
  epochs = 10,
  batch_size = 512,
  validation_split = 0.2,
  verbose=2
)
### Epoch 1/10
### 81/81 - 1s - loss: 0.6922 - accuracy: 0.5284 - val_loss: 0.6900 - val_accuracy: 0.5717
### Epoch 2/10
### 81/81 - 1s - loss: 0.6872 - accuracy: 0.5616 - val_loss: 0.6823 - val_accuracy: 0.5972
### Epoch 3/10
### 81/81 - 1s - loss: 0.6750 - accuracy: 0.6003 - val_loss: 0.6676 - val_accuracy: 0.6338
### Epoch 4/10
### 81/81 - 1s - loss: 0.6529 - accuracy: 0.6426 - val_loss: 0.6463 - val_accuracy: 0.6536
### Epoch 5/10
### 81/81 - 1s - loss: 0.6250 - accuracy: 0.6713 - val_loss: 0.6251 - val_accuracy: 0.6642
### Epoch 6/10
### 81/81 - 1s - loss: 0.5980 - accuracy: 0.6940 - val_loss: 0.6092 - val_accuracy: 0.6731
### Epoch 7/10
### 81/81 - 1s - loss: 0.5746 - accuracy: 0.7105 - val_loss: 0.5998 - val_accuracy: 0.6771
### Epoch 8/10
### 81/81 - 1s - loss: 0.5557 - accuracy: 0.7259 - val_loss: 0.5940 - val_accuracy: 0.6797
### Epoch 9/10
### 81/81 - 1s - loss: 0.5401 - accuracy: 0.7372 - val_loss: 0.5918 - val_accuracy: 0.6812
### Epoch 10/10
### 81/81 - 1s - loss: 0.5255 - accuracy: 0.7488 - val_loss: 0.5917 - val_accuracy: 0.6831
</code></pre>
</div>
<div id="è¯„ä¼°æ¨¡å‹" class="section level4">
<h4>è¯„ä¼°æ¨¡å‹</h4>
<p>è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªæ¨¡å‹æ˜¯å¦‚ä½•è¿è¡Œçš„ã€‚å°†è¿”å›ä¸¤ä¸ªå€¼ã€‚æŸå¤±å€¼(ä¸€ä¸ªè¡¨ç¤ºæˆ‘ä»¬çš„è¯¯å·®çš„æ•°å­—ï¼Œè¶Šä½çš„å€¼è¶Šå¥½)å’Œå‡†ç¡®æ€§ã€‚</p>
<pre class="r"><code>results &lt;- model %&gt;% evaluate(testing$text, as.numeric(testing$tag == &quot;pos&quot;), verbose = 0)
results
###      loss  accuracy
### 0.5864145 0.6879635</code></pre>
<p>è¿™ç§ç›¸å½“æœ´ç´ çš„æ–¹æ³•å¯ä»¥è¾¾åˆ°çº¦68ï¼…çš„ç²¾åº¦ã€‚ä½¿ç”¨æ›´é«˜çº§çš„æ–¹æ³•ï¼Œæ¨¡å‹åº”æ¥è¿‘85ï¼…ã€‚</p>
</div>
<div id="åˆ›å»ºä¸€ä¸ªéšæ—¶é—´å˜åŒ–çš„å‡†ç¡®æ€§å’ŒæŸå¤±å›¾è¡¨" class="section level4">
<h4>åˆ›å»ºä¸€ä¸ªéšæ—¶é—´å˜åŒ–çš„å‡†ç¡®æ€§å’ŒæŸå¤±å›¾è¡¨</h4>
<p><em>fit</em>è¿”å›ä¸€ä¸ª<em>keras_training_history</em>å¯¹è±¡ï¼Œå®ƒçš„<em>metrics</em>åŒ…å«è®­ç»ƒæœŸé—´è®°å½•çš„ä¸¢å¤±å’Œåº¦é‡å€¼( loss and metrics values)ã€‚ä½ å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨å®ƒæ¥ç»˜åˆ¶æŸå¤±å’ŒæŒ‡æ ‡æ›²çº¿:</p>
<pre class="r"><code>plot(history)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig7"></span>
<img src="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_text_classification_files/figure-html/unnamed-chunk-16-1.png" alt="è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´2" width="60%" />
<p class="caption">
Figure 7: è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´2
</p>
</div>
<p>æŸå¤±å’ŒæŒ‡æ ‡çš„æ¼”å˜ï¼Œä¹Ÿå¯ä»¥åœ¨RStudioæµè§ˆå™¨çª—æ ¼è®­ç»ƒä¸­çœ‹å‡ºã€‚</p>
<p>è¯·æ³¨æ„ï¼Œè®­ç»ƒæŸå¤±éšæ¯ä¸ªepoch è€Œå‡å°‘ï¼Œè®­ç»ƒå‡†ç¡®åº¦éšæ¯ä¸ªepoch è€Œå¢åŠ ã€‚ ä½¿ç”¨æ¢¯åº¦ä¸‹é™ä¼˜åŒ–(gradient descent optimization)æ—¶ï¼Œè¿™æ˜¯å¯ä»¥é¢„æœŸçš„-å®ƒåº”åœ¨æ¯æ¬¡è¿­ä»£ä¸­å°†æ‰€éœ€çš„æ•°é‡æœ€å°åŒ–ã€‚</p>
</div>
</div>
<div id="ä½¿ç”¨tfhubä¸­çš„å­¦ä¹ æ¨¡å‹" class="section level3">
<h3>ä½¿ç”¨tfhubä¸­çš„å­¦ä¹ æ¨¡å‹</h3>
<p>æœ¬æ•™ç¨‹ä½¿ç”¨è¯„è®ºæ–‡æœ¬å°†ç”µå½±è¯„è®ºåˆ†ä¸ºæ­£é¢è¯„è®ºæˆ–è´Ÿé¢è¯„è®ºã€‚è¿™æ˜¯äºŒè¿›åˆ¶ï¼ˆæˆ–ä¸¤ç±»ï¼‰åˆ†ç±»çš„ç¤ºä¾‹ï¼Œå®ƒæ˜¯ä¸€ç§é‡è¦ä¸”å¹¿æ³›é€‚ç”¨çš„æœºå™¨å­¦ä¹ é—®é¢˜ã€‚</p>
<p>æˆ‘ä»¬å°†ä½¿ç”¨<a href="https://keras.rstudio.com/reference/dataset_imdb.html">IMDB</a>æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«æ¥è‡ª<a href="https://www.imdb.com/">Internet</a>ç”µå½±æ•°æ®åº“çš„50,000ä¸ªç”µå½±è¯„è®ºçš„æ–‡æœ¬ã€‚è¿™äº›å†…å®¹åˆ†ä¸º25,000æ¡ç”¨äºåŸ¹è®­çš„è¯„è®ºå’Œ25,000æ¡ç”¨äºæµ‹è¯•çš„è¯„è®ºã€‚è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ˜¯å¹³è¡¡çš„ï¼Œè¿™æ„å‘³ç€å®ƒä»¬åŒ…å«ç›¸åŒæ•°é‡çš„æ­£é¢å’Œè´Ÿé¢è¯„è®ºã€‚</p>
<p>æˆ‘ä»¬å°†ä½¿ç”¨<a href="https://github.com/rstudio/keras">Keras</a>æ„å»ºå’ŒåŸ¹è®­æ¨¡å‹ï¼Œä½¿ç”¨<a href="https://github.com/rstudio/tfhub">tfhub</a>è¿›è¡Œè¿ç§»å­¦ä¹ ã€‚æˆ‘ä»¬è¿˜å°†ä½¿ç”¨tfdsæ¥åŠ è½½IMDBæ•°æ®é›†ã€‚</p>
<p>å…ˆå¯åŠ¨å¹¶åŠ è½½Kerasä»¥åŠå…¶ä»–ä¸€äº›å¿…éœ€çš„åº“ã€‚</p>
<pre class="r"><code>library(keras)
library(tfhub)
library(tfds)
library(tfdatasets)</code></pre>
<div id="ä¸‹è½½imdbæ•°æ®é›†" class="section level4">
<h4>ä¸‹è½½IMDBæ•°æ®é›†</h4>
<p>IMDBæ•°æ®é›†å¯åœ¨<a href="https://github.com/tensorflow/datasets/blob/master/docs/datasets.md#imdb_reviews">IMDB reviews</a>æˆ–<a href="https://github.com/rstudio/tfds">tfd</a>ä¸Šè·å¾—ã€‚Kerasæ‰“åŒ…çš„æ–‡ä»¶å·²ç»ç»è¿‡äº†é¢„å¤„ç†ï¼Œå› æ­¤å¯¹æœ¬æ•™ç¨‹æ²¡æœ‰ç”¨å¤„ã€‚</p>
<p>ä»¥ä¸‹ä»£ç ä¸‹è½½IMDBæ•°æ®é›†åˆ°æ‚¨çš„æœºå™¨:</p>
<pre class="r"><code>imdb &lt;- tfds_load(
  &quot;imdb_reviews:1.0.0&quot;, 
  split = list(&quot;train[:60%]&quot;, &quot;train[-40%:]&quot;, &quot;test&quot;), 
  as_supervised = TRUE
)
summary(imdb)
### This is a dataset for binary sentiment classifica
### â¯ Name: imdb_reviews
### â¯ Version: 1.0.0
### â¯ URLs: http://ai.stanford.edu/~amaas/data/sentiment/
### â¯ Size:
### â¯ Splits:
###  â€” test ( examples)
###  â€” train ( examples)
###  â€” unsupervised ( examples)
### â¯ Schema:</code></pre>
<p><em>tfds_load</em>è¿”å›ä¸€ä¸ªTensorFlowæ•°æ®é›†ï¼Œæ˜¯è¡¨ç¤ºå…ƒç´ åºåˆ—çš„æŠ½è±¡ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ ç”±ä¸€ä¸ªæˆ–å¤šä¸ªç»„ä»¶ç»„æˆã€‚</p>
<p>è¦è®¿é—®æ•°æ®é›†çš„å•ä¸ªå…ƒç´ ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨:</p>
<pre class="r"><code>first &lt;- imdb[[1]] %&gt;% 
  dataset_batch(1) %&gt;% # Used to get only the first example
  reticulate::as_iterator() %&gt;% 
  reticulate::iter_next()
str(first)
### List of 2
###  $ :tf.Tensor([b&quot;This was an absolutely terrible movie. Don&#39;t be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie&#39;s ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor&#39;s like Christopher Walken&#39;s good name. I could barely sit through it.&quot;], shape=(1,), dtype=string)
###  $ :tf.Tensor([0], shape=(1,), dtype=int64)</code></pre>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°KerasçŸ¥é“å¦‚ä½•è‡ªåŠ¨ä»TensorFlowæ•°æ®é›†æå–å…ƒç´ ï¼Œè¿™æ¯”åœ¨ä¼ é€’ç»™Kerasä¹‹å‰å°†æ•´ä¸ªæ•°æ®é›†åŠ è½½åˆ°RAMä¸­æ›´æœ‰æ•ˆåœ°æé«˜äº†å†…å­˜æ•ˆç‡ã€‚</p>
</div>
<div id="æ„å»ºæ¨¡å‹-1" class="section level4">
<h4>æ„å»ºæ¨¡å‹</h4>
<p>ç¥ç»ç½‘ç»œæ˜¯é€šè¿‡å †å å±‚æ¥åˆ›å»ºçš„â€”â€”è¿™éœ€è¦ä¸‰ä¸ªä¸»è¦çš„æ¶æ„å†³ç­–:</p>
<ul>
<li><p>å¦‚ä½•ä»£è¡¨æ–‡å­—ï¼Ÿ</p></li>
<li><p>åœ¨æ¨¡å‹ä¸­ä½¿ç”¨å¤šå°‘å±‚ï¼Ÿ</p></li>
<li><p>æ¯å±‚ä½¿ç”¨å¤šå°‘ä¸ªéšè—å•å…ƒï¼Ÿ</p></li>
</ul>
<p>åœ¨æœ¬ä¾‹ä¸­ï¼Œè¾“å…¥æ•°æ®ç”±å¥å­ç»„æˆã€‚è¦é¢„æµ‹çš„æ ‡ç­¾ä¸æ˜¯0å°±æ˜¯1ã€‚</p>
<p>è¡¨ç¤ºæ–‡æœ¬çš„ä¸€ç§æ–¹æ³•æ˜¯å°†å¥å­è½¬æ¢ä¸ºåµŒå…¥å‘é‡ã€‚ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åµŒå…¥ä½œä¸ºç¬¬ä¸€å±‚ï¼Œè¿™å°†å…·æœ‰ä¸‰ä¸ªä¼˜ç‚¹ï¼š</p>
<ul>
<li><p>æˆ‘ä»¬ä¸å¿…æ‹…å¿ƒæ–‡æœ¬é¢„å¤„ç†ï¼Œ</p></li>
<li><p>æˆ‘ä»¬å¯ä»¥ä»è¿ç§»å­¦ä¹ ä¸­å—ç›Šï¼Œ</p></li>
<li><p>åµŒå…¥çš„å¤§å°æ˜¯å›ºå®šçš„ï¼Œå› æ­¤å¤„ç†èµ·æ¥æ›´ç®€å•ã€‚</p></li>
</ul>
<p>åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ¥è‡ª<a href="https://github.com/rstudio/tfhub">TensorFlow Hub</a>çš„é¢„è®­ç»ƒæ–‡æœ¬åµŒå…¥æ¨¡å‹<a href="https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1">google/tf2-preview/gnews-swivel-20dim/1</a>ã€‚</p>
<p>ä¸ºäº†æœ¬æ•™ç¨‹çš„ç›®çš„ï¼Œè¿˜éœ€è¦æµ‹è¯•å…¶ä»–ä¸‰ä¸ªé¢„å…ˆè®­ç»ƒè¿‡çš„æ¨¡å‹:</p>
<ul>
<li><p><a href="https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1">google/tf2-preview/gnews-swivel-20dim-with-oov/1</a>æ˜¯ä¸google/tf2-preview/gnews-swivel-20dim/1ç›¸åŒï¼Œä½†æœ‰2.5ï¼…çš„è¯æ±‡é‡è½¬æ¢ä¸ºOOVå­˜å‚¨æ¡¶ã€‚ å¦‚æœä»»åŠ¡çš„è¯æ±‡è¡¨å’Œæ¨¡å‹çš„è¯æ±‡è¡¨æ²¡æœ‰å®Œå…¨é‡å ï¼Œåˆ™å¯ä»¥æä¾›å¸®åŠ©ã€‚</p></li>
<li><p><a href="https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1">google/tf2-preview/nnlm-en-dim50/1</a>æ˜¯æ›´å¤§çš„æ¨¡å‹ï¼Œè¯æ±‡é‡çº¦ä¸ºä¸€ç™¾ä¸‡(1M)ï¼Œç»´åº¦ä¸º50ã€‚</p></li>
<li><p><a href="https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1">google/tf2-preview/nnlm-en-dim128/1</a>æ˜¯æ›´åŠ å¤§çš„è¯æ±‡æ¨¡å‹ï¼Œè¯æ±‡é‡çº¦ä¸º1Mï¼Œç»´åº¦ä¸º128ã€‚</p></li>
</ul>
<p>è®©æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªKeraså±‚(Keras layer)ï¼Œå®ƒä½¿ç”¨TensorFlow Hubä¸­çš„æ¨¡å‹æ¥åµŒå…¥å¥å­ï¼Œå¹¶åœ¨å‡ ä¸ªè¾“å…¥æ•°æ®çš„ç¤ºä¾‹ä¸­äº†è§£å®ƒã€‚æ³¨æ„ï¼Œæ— è®ºè¾“å…¥æ–‡æœ¬çš„é•¿åº¦æ˜¯å¤šå°‘ï¼ŒåµŒå…¥å±‚çš„è¾“å‡ºå½¢çŠ¶éƒ½æ˜¯:(num_examples, embeddding_dimension)ã€‚</p>
<p>æ³¨æ„ï¼šå¦‚æœå¤§é™†ç½‘ç»œæ— æ³•ä½¿ç”¨httpsè®¿é—®TensorFlow Hubä¸­çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆå°è¯•é€šè¿‡æµè§ˆå™¨å°†æ¨¡å‹æ•°æ®ä¸‹è½½åˆ°æœ¬åœ°(å¦‚<a href="https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1?tf-hub-format=compressed">tf2-preview_gnews-swivel-20dim_1.tar.gz</a>)ï¼Œç„¶åè§£å‹å‹ç¼©åŒ…åˆ°æŒ‡å®šè·¯å¾„(å¦‚ï¼š/tmp/tensorflow_hub/tf2-preview_gnews-swivel-20dim_1)ï¼Œåœ¨è°ƒç”¨æ¨¡å‹æ—¶ï¼Œä¾¿å¯ä»¥ç›´æ¥è°ƒç”¨æœ¬åœ°çš„æ¨¡å‹æ•°æ®äº†()ã€‚</p>
<pre class="r"><code>embedding_layer &lt;- layer_hub(handle = &quot;https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1&quot;)
embedding_layer(first[[1]])

# é€šè¿‡è°ƒç”¨ä¸‹è½½åˆ°æœ¬åœ°çš„æ¨¡å‹æ•°æ®
# embedding_layer &lt;- layer_hub(handle = &quot;/tmp/tensorflow_hub/tf2-preview_gnews-swivel-20dim_1&quot;)
# embedding_layer(first[[1]])

### tf.Tensor(
### [[ 1.765786   -3.882232    3.9134233  -1.5557289  -3.3362343  -1.7357955
###   -1.9954445   1.2989551   5.081598   -1.1041286  -2.0503852  -0.72675157
###   -0.65675956  0.24436149 -3.7208383   2.0954835   2.2969332  -2.0689783
###   -2.9489717  -1.1315987 ]], shape=(1, 20), dtype=float32)</code></pre>
<p>ç°åœ¨è®©æˆ‘ä»¬æ„å»ºå®Œæ•´çš„æ¨¡å‹:</p>
<pre class="r"><code>model &lt;- keras_model_sequential() %&gt;% 
  layer_hub(
    handle = &quot;https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1&quot;,
    input_shape = list(),
    dtype = tf$string,
    trainable = TRUE
  ) %&gt;% 
  layer_dense(units = 16, activation = &quot;relu&quot;) %&gt;% 
  layer_dense(units = 1, activation = &quot;sigmoid&quot;)

summary(model)
### Model: &quot;sequential&quot;
### ________________________________________________________________________________
### Layer (type)                        Output Shape                    Param #
### ================================================================================
### keras_layer_1 (KerasLayer)          (None, 20)                      400020
### ________________________________________________________________________________
### dense_3 (Dense)                     (None, 16)                      336
### ________________________________________________________________________________
### dense_2 (Dense)                     (None, 1)                       17
### ================================================================================
### Total params: 400,373
### Trainable params: 400,373
### Non-trainable params: 0
### ________________________________________________________________________________
</code></pre>
<p>ä¾æ¬¡å †å å„å±‚ä»¥æ„å»ºåˆ†ç±»å™¨ï¼š</p>
<ol style="list-style-type: decimal">
<li><p>ç¬¬ä¸€å±‚æ˜¯TensorFlow Hubå±‚(TensorFlow Hub layer)ã€‚è¯¥å±‚ä½¿ç”¨é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹å°†å¥å­æ˜ å°„åˆ°å…¶åµŒå…¥å‘é‡ä¸­ã€‚å³è¿™é‡Œä½¿ç”¨çš„ç»è¿‡é¢„è®­ç»ƒçš„æ–‡æœ¬åµŒå…¥æ¨¡å‹(<a href="https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1">google/tf2-preview/gnews-swivel-20dim/1</a>)å°†å¥å­æ‹†åˆ†ä¸ºæ ‡è®°ï¼ŒåµŒå…¥æ¯ä¸ªæ ‡è®°ï¼Œç„¶åç»„åˆåµŒå…¥å±‚ã€‚ ç»“æœç»´åº¦ä¸ºï¼šï¼ˆnum_examplesï¼Œembedding_dimensionï¼‰ã€‚</p></li>
<li><p>è¯¥å›ºå®šé•¿åº¦çš„è¾“å‡ºçŸ¢é‡é€šè¿‡å…·æœ‰16ä¸ªéšè—å•å…ƒçš„å®Œå…¨è¿æ¥ï¼ˆå¯†é›†ï¼‰å±‚è¿›è¡Œä¼ é€’ã€‚</p></li>
<li><p>æœ€åä¸€å±‚ä¸å•ä¸ªè¾“å‡ºèŠ‚ç‚¹ç´§å¯†è¿æ¥ã€‚ ä½¿ç”¨<em>sigmoid</em>æ¿€æ´»å‡½æ•°ï¼Œè¯¥å€¼æ˜¯0åˆ°1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºæ¦‚ç‡æˆ–ç½®ä¿¡åº¦ã€‚</p></li>
</ol>
</div>
<div id="ç¼–è¯‘æ¨¡å‹-1" class="section level4">
<h4>ç¼–è¯‘æ¨¡å‹</h4>
<div id="æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨-1" class="section level5">
<h5>æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨</h5>
<p>ä¸€ä¸ªæ¨¡å‹éœ€è¦ä¸€ä¸ªæŸå¤±å‡½æ•°å’Œä¸€ä¸ªè®­ç»ƒä¼˜åŒ–å™¨ã€‚ç”±äºæœ¬æ¡ˆä¾‹æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œæ¨¡å‹è¾“å‡ºä¸€ä¸ªæ¦‚ç‡(å¸¦æœ‰sigmoidæ¿€æ´»çš„å•ä¸ªå•å…ƒå±‚)ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<em>binary_crossentropy</em>æŸå¤±å‡½æ•°(Loss function)ã€‚</p>
<p>è¿™ä¸æ˜¯æŸå¤±å‡½æ•°çš„å”¯ä¸€é€‰æ‹©ï¼Œä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥é€‰æ‹©<em>mean_squared_error</em>ã€‚ä½†æ˜¯ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œ<em>binary_crossenpy</em>æ›´é€‚åˆå¤„ç†æ¦‚ç‡â€”â€”å®ƒæµ‹é‡æ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„â€œè·ç¦»â€ï¼Œæˆ–è€…åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œå³æ˜¯çœŸå®åˆ†å¸ƒå’Œé¢„æµ‹ä¹‹é—´çš„â€œè·ç¦»â€ã€‚</p>
<p>ç¨åï¼Œå½“æˆ‘ä»¬æ¢è®¨å›å½’é—®é¢˜(æ¯”å¦‚ï¼Œé¢„æµ‹æˆ¿å±‹ä»·æ ¼)æ—¶ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨å¦ä¸€ä¸ªç§°ä¸ºå‡æ–¹è¯¯å·®(mean squared error)çš„æŸå¤±å‡½æ•°ã€‚</p>
<p>ç°åœ¨ï¼Œé…ç½®æ¨¡å‹ä¸­ä½¿ç”¨çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ï¼š</p>
<pre class="r"><code>model %&gt;% 
  compile(
    optimizer = &quot;adam&quot;,
    loss = &quot;binary_crossentropy&quot;,
    metrics = &quot;accuracy&quot;
  )</code></pre>
</div>
</div>
<div id="æ¨¡å‹è®­ç»ƒ" class="section level4">
<h4>æ¨¡å‹è®­ç»ƒ</h4>
<p>æ¨¡å‹è®­ç»ƒä½¿ç”¨åŒ…å«512ä¸ªæ ·æœ¬çš„å°æ‰¹é‡æ•°æ®é›†è¿›è¡Œ20ä¸ªepochsï¼Œä¹Ÿå°±æ˜¯å¯¹x_trainå’Œy_trainå¼ é‡ä¸­çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œ20æ¬¡è¿­ä»£ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œåœ¨éªŒè¯é›†çš„10,000ä¸ªæ ·æœ¬ä¸Šç›‘æ§æ¨¡å‹çš„æŸå¤±å’Œå‡†ç¡®æ€§:</p>
<pre class="r"><code>history&lt;-model %&gt;% fit(
    imdb[[1]] %&gt;% dataset_shuffle(10000) %&gt;% dataset_batch(512),
    epochs = 20,
    validation_data = imdb[[2]] %&gt;% dataset_batch(512),
    verbose = 2
  )
</code></pre>
</div>
<div id="è¯„ä¼°æ¨¡å‹-1" class="section level4">
<h4>è¯„ä¼°æ¨¡å‹</h4>
<p>è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªæ¨¡å‹æ˜¯å¦‚ä½•è¿è¡Œçš„ã€‚å°†è¿”å›ä¸¤ä¸ªå€¼ã€‚æŸå¤±å€¼(ä¸€ä¸ªè¡¨ç¤ºæˆ‘ä»¬çš„è¯¯å·®çš„æ•°å­—ï¼Œè¶Šä½çš„å€¼è¶Šå¥½)å’Œå‡†ç¡®æ€§ã€‚</p>
<pre class="r"><code>results &lt;- model %&gt;% 
  evaluate(imdb[[3]] %&gt;%  dataset_batch(512), verbose = 0)
results
###      loss  accuracy
### 0.3169311 0.8660800</code></pre>
<p>è¿™ç§ç®€å•çš„æ–¹æ³•å¯ä»¥è¾¾åˆ°çº¦87ï¼…çš„ç²¾åº¦ã€‚ä½¿ç”¨æ›´é«˜çº§çš„æ–¹æ³•ï¼Œæ¨¡å‹å‡†ç¡®åº¦åº”æ¥è¿‘95ï¼…ã€‚</p>
</div>
<div id="å‡†ç¡®æ€§å’ŒæŸå¤±å‡½æ•°çš„å›¾è¡¨" class="section level4">
<h4>å‡†ç¡®æ€§å’ŒæŸå¤±å‡½æ•°çš„å›¾è¡¨</h4>
<p><em>fit</em>è¿”å›ä¸€ä¸ª<em>keras_training_history</em>å¯¹è±¡ï¼Œå®ƒçš„<em>metrics</em>åŒ…å«è®­ç»ƒæœŸé—´è®°å½•çš„ä¸¢å¤±å’Œåº¦é‡å€¼( loss and metrics values)ã€‚ä½ å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨å®ƒæ¥ç»˜åˆ¶æŸå¤±å’ŒæŒ‡æ ‡æ›²çº¿:</p>
<pre class="r"><code>plot(history)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig8"></span>
<img src="https://s3.ax1x.com/2020/12/26/rhVyPP.png" alt="è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´3" width="60%" />
<p class="caption">
Figure 8: è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´3
</p>
</div>
</div>
</div>
<div id="è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ" class="section level3">
<h3>è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ</h3>
<p>åœ¨ä¹‹å‰çš„ä¸¤ä¸ªæ•™ç¨‹ä¸­â€”â€”å¯¹<a href="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_overfit_underfit/tutorial_basic_text_classification.html">ç”µå½±è¯„è®ºè¿›è¡Œåˆ†ç±»</a>å’Œ<a href="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_overfit_underfit/tutorial_basic_regression.html">é¢„æµ‹æˆ¿ä»·</a>â€”â€”æˆ‘ä»¬çœ‹åˆ°ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨éªŒè¯æ•°æ®ä¸Šçš„å‡†ç¡®æ€§åœ¨ç»è¿‡è‹¥å¹²ä¸ªepochçš„è®­ç»ƒåå°†è¾¾åˆ°å³°å€¼ï¼Œç„¶åå¼€å§‹ä¸‹é™ã€‚</p>
<p>æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å°†è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚ å­¦ä¹ å¦‚ä½•åº”å¯¹è¿‡åº¦æ‹Ÿåˆéå¸¸é‡è¦ã€‚ å°½ç®¡é€šå¸¸å¯ä»¥åœ¨è®­ç»ƒé›†ä¸Šè¾¾åˆ°å¾ˆé«˜çš„å‡†ç¡®æ€§ï¼Œä½†æˆ‘ä»¬çœŸæ­£æƒ³è¦çš„æ˜¯å¼€å‘å‡ºèƒ½å¤Ÿå¾ˆå¥½åœ°é¢„æµ‹æˆ–è€…æ¦‚æ‹¬æµ‹è¯•æ•°æ®ï¼ˆæˆ–ä¹‹å‰ä»æœªè§è¿‡çš„æ•°æ®ï¼‰çš„æ¨¡å‹ã€‚</p>
<p>è¿‡åº¦æ‹Ÿåˆçš„åé¢æ˜¯æ¬ æ‹Ÿåˆã€‚ å½“å‘ç°æµ‹è¯•æ•°æ®ä»æœ‰æ”¹è¿›ç©ºé—´æ—¶ï¼Œå°±ä¼šå‘ç”Ÿæ¬ æ‹Ÿåˆã€‚ å‘ç”Ÿè¿™ç§æƒ…å†µçš„åŸå› æœ‰å¾ˆå¤šï¼šå¦‚æ¨¡å‹ä¸å¤Ÿå¼ºå¤§ï¼Œæ¨¡å‹è¿‡äºè§„èŒƒåŒ–ï¼Œæˆ–è€…ä»…ä»…æ˜¯æ²¡æœ‰ç»è¿‡è¶³å¤Ÿé•¿æ—¶é—´çš„è®­ç»ƒã€‚ è¿™æ„å‘³ç€ç½‘ç»œå°šæœªå­¦ä¹ è®­ç»ƒæ•°æ®ä¸­çš„ç›¸å…³æ¨¡å¼ã€‚</p>
<p>ä¸ºäº†é˜²æ­¢è¿‡åº¦æ‹Ÿåˆï¼Œæœ€å¥½çš„è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨æ›´å¤šçš„è®­ç»ƒæ•°æ®ã€‚ ç»è¿‡æ›´å¤šæ•°æ®è®­ç»ƒçš„æ¨¡å‹è‡ªç„¶ä¼šæ›´å¥½åœ°æ¨å¹¿ã€‚ å½“è¿™ä¸å†å¯èƒ½æ—¶ï¼Œä¸‹ä¸€ä¸ªæœ€ä½³è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨æ­£åˆ™åŒ–ä¹‹ç±»çš„æŠ€æœ¯ã€‚ è¿™äº›æ­£åˆ™åŒ–ä¹‹ç±»çš„æŠ€æœ¯é™åˆ¶äº†æ¨¡å‹å¯ä»¥å­˜å‚¨çš„ä¿¡æ¯çš„æ•°é‡å’Œç±»å‹ã€‚ å¦‚æœç½‘ç»œæ¨¡å‹åªèƒ½å­˜å‚¨å°‘é‡æ¨¡å¼ï¼Œé‚£ä¹ˆä¼˜åŒ–è¿‡ç¨‹å°†è¿«ä½¿å®ƒä¸“æ³¨äºæœ€çªå‡ºçš„æ¨¡å¼ï¼Œè¿™äº›æ¨¡å¼å…·æœ‰æ›´å¥½çš„æ³›åŒ–æ€§ã€‚</p>
<p>åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ä¸¤ç§å¸¸è§çš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼šæƒé‡æ­£åˆ™åŒ–(weight regularization)å’Œä¸¢åŒ…(dropout)ï¼Œå¹¶ä½¿ç”¨å®ƒä»¬æ¥æ”¹è¿›æˆ‘ä»¬çš„IMDBç”µå½±è¯„è®ºåˆ†ç±»ç»“æœã€‚</p>
<p>å…ˆå¯åŠ¨å¹¶åŠ è½½Kerasä»¥åŠå…¶ä»–ä¸€äº›å¿…éœ€çš„åº“ã€‚</p>
<pre class="r"><code>library(keras)
library(dplyr)
library(ggplot2)
library(tidyr)
library(tibble)</code></pre>
<div id="ä¸‹è½½imdbæ•°æ®é›†-1" class="section level4">
<h4>ä¸‹è½½IMDBæ•°æ®é›†</h4>
<pre class="r"><code>num_words &lt;- 1000
imdb &lt;- dataset_imdb(num_words = num_words)
#https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz
c(train_data, train_labels) %&lt;-% imdb$train
c(test_data, test_labels) %&lt;-% imdb$test</code></pre>
<p>ä¸åœ¨å‰é¢çš„ç¬”è®°ä¸­ä½¿ç”¨åµŒå…¥å±‚ä¸åŒï¼Œè¿™é‡Œæˆ‘ä»¬å°†å¯¹å¥å­è¿›è¡Œå¤šæ¬¡çƒ­ç¼–ç ã€‚è¯¥æ¨¡å‹å°†å¿«é€Ÿåœ°å¯¹è®­ç»ƒé›†è¿›è¡Œè¿‡æ‹Ÿåˆã€‚å®ƒå°†è¢«ç”¨æ¥æ¼”ç¤ºä½•æ—¶å‘ç”Ÿè¿‡æ‹Ÿåˆï¼Œä»¥åŠå¦‚ä½•åº”å¯¹è¿‡æ‹Ÿåˆã€‚</p>
<p>å¯¹åˆ—è¡¨è¿›è¡Œå¤šæ¬¡çƒ­ç¼–ç æ„å‘³ç€å°†å®ƒä»¬è½¬æ¢ä¸º0å’Œ1çš„å‘é‡ã€‚ å…·ä½“è€Œè¨€ï¼Œè¿™æ„å‘³ç€ä¾‹å¦‚å°†åºåˆ—[3ï¼Œ5]è½¬æ¢ä¸ºä¸€ä¸ª10,000ç»´å‘é‡ï¼Œè¯¥å‘é‡é™¤ç´¢å¼•3å’Œ5æ˜¯1å¤–ï¼Œå…¶ä½™çš„å…¨æ˜¯é›¶ã€‚</p>
<pre class="r"><code>multi_hot_sequences &lt;- function(sequences, dimension) {
  multi_hot &lt;- matrix(0, nrow = length(sequences), ncol = dimension)
  for (i in 1:length(sequences)) {
    multi_hot[i, sequences[[i]]] &lt;- 1
  }
  multi_hot
}

train_data &lt;- multi_hot_sequences(train_data, num_words)
test_data &lt;- multi_hot_sequences(test_data, num_words)</code></pre>
<p>è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å…¶ä¸­ä¸€ä¸ªå¤šæ¬¡çƒ­ç¼–ç ç‚¹çŸ¢é‡ã€‚ ç”±äºå•è¯ç´¢å¼•æ˜¯æŒ‰é¢‘ç‡æ’åºï¼Œå› æ­¤å¯ä»¥é¢„æœŸåœ¨ç´¢å¼•0é™„è¿‘æœ‰æ›´å¤šçš„1å€¼ï¼Œå¦‚æˆ‘ä»¬åœ¨è¯¥å›¾ä¸­æ‰€çœ‹åˆ°çš„ï¼š</p>
<pre class="r"><code>first_text &lt;- data.frame(word = 1:num_words, value = train_data[1, ])
ggplot(first_text, aes(x = word, y = value)) +
  geom_line() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig9"></span>
<img src="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_overfit_underfit_files/figure-html/unnamed-chunk-4-1.png" alt="è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´3" width="60%" />
<p class="caption">
Figure 9: è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´3
</p>
</div>
</div>
<div id="è¿‡æ‹Ÿåˆç¤ºä¾‹" class="section level4">
<h4>è¿‡æ‹Ÿåˆç¤ºä¾‹</h4>
<p>é˜²æ­¢è¿‡åº¦æ‹Ÿåˆçš„æœ€ç®€å•æ–¹æ³•æ˜¯å‡å°æ¨¡å‹çš„å¤§å°ï¼Œå³å‡å°æ¨¡å‹ä¸­å¯å­¦ä¹ çš„å‚æ•°çš„æ•°é‡ï¼ˆç”±å±‚æ•°å’Œæ¯å±‚å•å…ƒæ•°ç¡®å®šï¼‰ã€‚ åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ¨¡å‹ä¸­å¯å­¦ä¹ å‚æ•°çš„æ•°é‡é€šå¸¸ç§°ä¸ºæ¨¡å‹çš„â€œå®¹é‡â€ã€‚ ç›´è§‚åœ°è®²ï¼Œå…·æœ‰æ›´å¤šå‚æ•°çš„æ¨¡å‹å°†å…·æœ‰æ›´å¤šçš„â€œè®°å¿†èƒ½åŠ›â€ï¼Œå› æ­¤å°†èƒ½å¤Ÿè½»æ¾å­¦ä¹ è®­ç»ƒæ ·æœ¬ä¸å…¶ç›®æ ‡ä¹‹é—´çš„å®Œç¾çš„å­—å…¸å¼æ˜ å°„ï¼Œè¿™ç§æ˜ å°„æ²¡æœ‰ä»»ä½•æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨å¯¹ä»¥å‰çœ‹ä¸è§çš„æ•°æ®è¿›è¡Œé¢„æµ‹æ—¶ï¼Œè¿™å°†æ¯«æ— ç”¨å¤„ã€‚</p>
<blockquote>
<p>å§‹ç»ˆç‰¢è®°è¿™ä¸€ç‚¹ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹å¾€å¾€æ“…é•¿æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œä½†çœŸæ­£çš„æŒ‘æˆ˜æ˜¯<strong>æ³›åŒ–</strong>ï¼Œè€Œä¸æ˜¯æ‹Ÿåˆã€‚</p>
</blockquote>
<p>ä¸å¹¸çš„æ˜¯ï¼Œæ²¡æœ‰ç¥å¥‡çš„å…¬å¼æ¥ç¡®å®šæ¨¡å‹çš„æ­£ç¡®å¤§å°æˆ–ä½“ç³»ç»“æ„ï¼ˆæ ¹æ®å±‚æ•°æˆ–æ¯å±‚çš„å‚æ•°çš„æ­£ç¡®å¤§å°ï¼‰ã€‚ æ‚¨å°†ä¸å¾—ä¸å°è¯•ä½¿ç”¨ä¸€ç³»åˆ—ä¸åŒçš„ä½“ç³»ç»“æ„ã€‚</p>
<p>ä¸ºäº†æ‰¾åˆ°åˆé€‚çš„æ¨¡å‹å°ºå¯¸ï¼Œæœ€å¥½ä»ç›¸å¯¹è¾ƒå°‘çš„å›¾å±‚å’Œå‚æ•°å¼€å§‹ï¼Œç„¶åå¼€å§‹å¢åŠ å›¾å±‚çš„å¤§å°æˆ–æ·»åŠ æ–°çš„å›¾å±‚ï¼Œç›´åˆ°çœ‹åˆ°éªŒè¯æŸå¤±çš„æ”¶ç›Šé€’å‡ä¸ºæ­¢ã€‚ è®©æˆ‘ä»¬åœ¨ç”µå½±è¯„è®ºåˆ†ç±»ç½‘ç»œä¸Šå°è¯•ä¸€ä¸‹ã€‚</p>
<p>æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªä»…ä½¿ç”¨å¯†é›†å±‚çš„åŸºç¡€æ¨¡å‹ï¼Œå’Œä¸€ä¸ªæ¯”è¾ƒå°å‹çš„æ¨¡å‹ï¼Œå¹¶å¯¹å®ƒä»¬è¿›è¡Œè¿›è¡Œæ¯”è¾ƒã€‚</p>
<div id="å»ºç«‹åŸºç¡€æ¨¡å‹" class="section level5">
<h5>å»ºç«‹åŸºç¡€æ¨¡å‹</h5>
<pre class="r"><code>baseline_model &lt;- 
  keras_model_sequential() %&gt;%
  layer_dense(units = 16, activation = &quot;relu&quot;, input_shape = num_words) %&gt;%
  layer_dense(units = 16, activation = &quot;relu&quot;) %&gt;%
  layer_dense(units = 1, activation = &quot;sigmoid&quot;)

baseline_model %&gt;% compile(
  optimizer = &quot;adam&quot;,
  loss = &quot;binary_crossentropy&quot;,
  metrics = list(&quot;accuracy&quot;)
)

summary(baseline_model)
### Model: &quot;sequential&quot;
### ________________________________________________________________________________
### Layer (type)                        Output Shape                    Param #
### ================================================================================
### dense_2 (Dense)                     (None, 16)                      16016
### ________________________________________________________________________________
### dense_1 (Dense)                     (None, 16)                      272
### ________________________________________________________________________________
### dense (Dense)                       (None, 1)                       17
### ================================================================================
### Total params: 16,305
### Trainable params: 16,305
### Non-trainable params: 0
### ________________________________________________________________________________

baseline_history &lt;- baseline_model %&gt;% fit(
  train_data,
  train_labels,
  epochs = 20,
  batch_size = 512,
  validation_data = list(test_data, test_labels),
  verbose = 2
)
### Epoch 1/20
### 49/49 - 4s - loss: 0.5986 - accuracy: 0.6920 - val_loss: 0.4629 - val_accuracy: 0.8026
### ...
### Epoch 20/20
### 49/49 - 0s - loss: 0.1784 - accuracy: 0.9338 - val_loss: 0.4087 - val_accuracy: 0.8425
</code></pre>
</div>
<div id="åˆ›å»ºä¸€ä¸ªæ›´å°çš„æ¨¡å‹" class="section level5">
<h5>åˆ›å»ºä¸€ä¸ªæ›´å°çš„æ¨¡å‹</h5>
<p>è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåŒ…å«è¾ƒå°‘éšè—å•ä½çš„æ¨¡å‹ï¼Œä¸æˆ‘ä»¬åˆšåˆšåˆ›å»ºçš„åŸºç¡€æ¨¡å‹è¿›è¡Œæ¯”è¾ƒ:</p>
<pre class="r"><code>smaller_model &lt;- 
  keras_model_sequential() %&gt;%
  layer_dense(units = 4, activation = &quot;relu&quot;, input_shape = num_words) %&gt;%
  layer_dense(units = 4, activation = &quot;relu&quot;) %&gt;%
  layer_dense(units = 1, activation = &quot;sigmoid&quot;)

smaller_model %&gt;% compile(
  optimizer = &quot;adam&quot;,
  loss = &quot;binary_crossentropy&quot;,
  metrics = list(&quot;accuracy&quot;)
)

summary(smaller_model)
### Model: &quot;sequential_1&quot;
### ________________________________________________________________________________
### Layer (type)                        Output Shape                    Param #
### ================================================================================
### dense_5 (Dense)                     (None, 4)                       4004
### ________________________________________________________________________________
### dense_4 (Dense)                     (None, 4)                       20
### ________________________________________________________________________________
### dense_3 (Dense)                     (None, 1)                       5
### ================================================================================
### Total params: 4,029
### Trainable params: 4,029
### Non-trainable params: 0
### ________________________________________________________________________________
</code></pre>
<p>å¹¶ä½¿ç”¨ç›¸åŒçš„æ•°æ®è®­ç»ƒæ¨¡å‹:</p>
<pre class="r"><code>smaller_history &lt;- smaller_model %&gt;% fit(
  train_data,
  train_labels,
  epochs = 20,
  batch_size = 512,
  validation_data = list(test_data, test_labels),
  verbose = 2
)
### Epoch 1/20
### 49/49 - 0s - loss: 0.6219 - accuracy: 0.6821 - val_loss: 0.5364 - val_accuracy: 0.7832
### ...
### Epoch 20/20
### 49/49 - 0s - loss: 0.2952 - accuracy: 0.8787 - val_loss: 0.3320 - val_accuracy: 0.8589</code></pre>
</div>
<div id="åˆ›å»ºä¸€ä¸ªæ›´å¤§çš„æ¨¡å‹" class="section level5">
<h5>åˆ›å»ºä¸€ä¸ªæ›´å¤§çš„æ¨¡å‹</h5>
<p>æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬åœ¨è¿™ä¸ªåŸºå‡†ä¸Šæ·»åŠ ä¸€ä¸ªå®¹é‡æ›´å¤§çš„ç½‘ç»œï¼Œè¿œè¿œè¶…å‡ºäº†é—®é¢˜æ‰€èƒ½ä¿è¯çš„èŒƒå›´:</p>
<pre class="r"><code>bigger_model &lt;- 
  keras_model_sequential() %&gt;%
  layer_dense(units = 512, activation = &quot;relu&quot;, input_shape = num_words) %&gt;%
  layer_dense(units = 512, activation = &quot;relu&quot;) %&gt;%
  layer_dense(units = 1, activation = &quot;sigmoid&quot;)

bigger_model %&gt;% compile(
  optimizer = &quot;adam&quot;,
  loss = &quot;binary_crossentropy&quot;,
  metrics = list(&quot;accuracy&quot;)
)

summary(bigger_model)
### Model: &quot;sequential_2&quot;
### ________________________________________________________________________________
### Layer (type)                        Output Shape                    Param #
### ================================================================================
### dense_8 (Dense)                     (None, 512)                     512512
### ________________________________________________________________________________
### dense_7 (Dense)                     (None, 512)                     262656
### ________________________________________________________________________________
### dense_6 (Dense)                     (None, 1)                       513
### ================================================================================
### Total params: 775,681
### Trainable params: 775,681
### Non-trainable params: 0
### ________________________________________________________________________________</code></pre>
<p>å¹¶ä½¿ç”¨ç›¸åŒçš„æ•°æ®è®­ç»ƒæ¨¡å‹:</p>
<pre class="r"><code>bigger_history &lt;- bigger_model %&gt;% fit(
  train_data,
  train_labels,
  epochs = 20,
  batch_size = 512,
  validation_data = list(test_data, test_labels),
  verbose = 2
)
### Epoch 1/20
### 49/49 - 1s - loss: 0.4507 - accuracy: 0.7849 - val_loss: 0.3708 - val_accuracy: 0.8410
### ...
### Epoch 20/20
### 49/49 - 1s - loss: 5.0736e-05 - accuracy: 1.0000 - val_loss: 0.8649 - val_accuracy: 0.8527</code></pre>
</div>
</div>
<div id="ç»˜åˆ¶åŸ¹è®­å’ŒéªŒè¯æŸå¤±" class="section level4">
<h4>ç»˜åˆ¶åŸ¹è®­å’ŒéªŒè¯æŸå¤±</h4>
<p>ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç»˜åˆ¶3ç§æ¨¡å‹çš„æŸè€—æ›²çº¿ã€‚è¾ƒå°çš„ç½‘ç»œæ¨¡å‹å¼€å§‹è¿‡æ‹Ÿåˆçš„æ—¶é—´æ¯”åŸºçº¿æ¨¡å‹ç¨æ™šï¼Œå¹¶ä¸”ä¸€æ—¦å¼€å§‹è¿‡æ‹Ÿåˆï¼Œå®ƒçš„æ€§èƒ½ä¸‹é™å¾—æ›´æ…¢ã€‚è¯·æ³¨æ„ï¼Œè¾ƒå¤§çš„ç½‘ç»œæ¨¡å‹ä»…åœ¨ä¸€ä¸ªepochä¹‹åå°±å¼€å§‹è¿‡åº¦æ‹Ÿåˆï¼Œè€Œä¸”æ˜¯ä¸¥é‡è¿‡åº¦æ‹Ÿåˆã€‚ç½‘ç»œæ¨¡å‹å…·æœ‰çš„å®¹é‡è¶Šå¤šï¼Œå°†èƒ½å¤Ÿæ›´å¿«åœ°å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œå»ºæ¨¡ï¼ˆå¯¼è‡´è¾ƒä½çš„è®­ç»ƒæŸå¤±ï¼‰ï¼Œä½†å®ƒè¶Šå®¹æ˜“è¿‡æ‹Ÿåˆï¼ˆå¯¼è‡´è®­ç»ƒå’ŒéªŒè¯æŸå¤±ä¹‹é—´å­˜åœ¨è¾ƒå¤§å·®å¼‚ï¼‰ã€‚</p>
<pre class="r"><code>compare_cx &lt;- data.frame(
  baseline_train = baseline_history$metrics$loss,
  baseline_val = baseline_history$metrics$val_loss,
  smaller_train = smaller_history$metrics$loss,
  smaller_val = smaller_history$metrics$val_loss,
  bigger_train = bigger_history$metrics$loss,
  bigger_val = bigger_history$metrics$val_loss
) %&gt;%
  rownames_to_column() %&gt;%
  mutate(rowname = as.integer(rowname)) %&gt;%
  gather(key = &quot;type&quot;, value = &quot;value&quot;, -rowname)
  
ggplot(compare_cx, aes(x = rowname, y = value, color = type)) +
  geom_line() +
  xlab(&quot;epoch&quot;) +
  ylab(&quot;loss&quot;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig10"></span>
<img src="https://s3.ax1x.com/2020/12/26/rhbVuF.png" alt="bä¸åŒå¤æ‚ç¨‹åº¦çš„ç½‘ç»œæ¨¡å‹çš„æ‹Ÿåˆè¿‡ç¨‹å’Œæ—¶é—´" width="60%" />
<p class="caption">
Figure 10: bä¸åŒå¤æ‚ç¨‹åº¦çš„ç½‘ç»œæ¨¡å‹çš„æ‹Ÿåˆè¿‡ç¨‹å’Œæ—¶é—´
</p>
</div>
</div>
<div id="ç­–ç•¥" class="section level4">
<h4>ç­–ç•¥</h4>
<div id="æƒé‡æ­£åˆ™åŒ–" class="section level5">
<h5>æƒé‡æ­£åˆ™åŒ–</h5>
<p>ä½ å¯èƒ½ç†Ÿæ‚‰å¥¥å¡å§†å‰ƒåˆ€åŸç†(Occamâ€™s Razor principle): å¯¹äºæŸä»¶äº‹æœ‰ä¸¤ç§è§£é‡Šï¼Œæœ€æœ‰å¯èƒ½æ­£ç¡®çš„è§£é‡Šæ˜¯â€œæœ€ç®€å•çš„â€è¿™ç§è§£é‡Šï¼Œä¹Ÿå°±æ˜¯åšå‡ºæœ€å°‘å‡è®¾çš„é‚£ä¸ªè§£é‡Šã€‚è¿™ä¹Ÿé€‚ç”¨äºç¥ç»ç½‘ç»œå­¦ä¹ çš„æ¨¡å‹:ç»™å®šä¸€äº›è®­ç»ƒæ•°æ®å’Œä¸€ä¸ªç½‘ç»œæ¶æ„ï¼Œæœ‰å¤šä¸ªæƒé‡å€¼é›†(å¤šä¸ªæ¨¡å‹)å¯ä»¥è§£é‡Šæ•°æ®ï¼Œç®€å•çš„æ¨¡å‹æ¯”å¤æ‚çš„æ¨¡å‹æ›´ä¸å®¹æ˜“è¿‡åº¦æ‹Ÿåˆã€‚</p>
<p>åœ¨è¿™ä¸ªä¸Šä¸‹æ–‡ä¸­ï¼Œâ€œç®€å•æ¨¡å‹â€æ˜¯æŒ‡å‚æ•°å€¼åˆ†å¸ƒçš„ç†µæ›´å°‘çš„æ¨¡å‹(æˆ–è€…æ˜¯ä¸€ä¸ªå…·æœ‰æ›´å°‘å‚æ•°çš„æ¨¡å‹ï¼Œå¦‚æˆ‘ä»¬åœ¨ä¸Šé¢ä¸€èŠ‚ä¸­çœ‹åˆ°çš„)ã€‚å› æ­¤ï¼Œå‡å°‘è¿‡åº¦æ‹Ÿåˆçš„ä¸€ç§å¸¸è§æ–¹æ³•æ˜¯é€šè¿‡å¼ºåˆ¶ç½‘ç»œçš„æƒé‡ä»…é‡‡ç”¨è¾ƒå°çš„å€¼æ¥å¯¹ç½‘ç»œçš„å¤æ‚æ€§æ–½åŠ çº¦æŸï¼Œè¿™ä½¿å¾—æƒé‡å€¼çš„åˆ†å¸ƒæ›´åŠ â€œè§„åˆ™â€ã€‚ è¿™ç§°ä¸ºâ€œæƒé‡è°ƒæ•´â€ï¼Œè¿™æ˜¯é€šè¿‡å‘ç½‘ç»œçš„æŸå¤±å‡½æ•°æ·»åŠ ä¸æ‹¥æœ‰å¤§æƒé‡ç›¸å…³çš„ä»£ä»·æ¥å®ç°çš„ã€‚è¿™ç§ä»£ä»·æœ‰ä¸¤ä¸ªæ–¹é¢:</p>
<ul>
<li>L1æ­£åˆ™åŒ–ï¼Œå…¶ä¸­å¢åŠ çš„æˆæœ¬ä¸æƒé‡ç³»æ•°çš„ç»å¯¹å€¼æˆæ¯”ä¾‹(å³ä¸æƒé‡çš„â€œL1èŒƒæ•°â€æˆæ¯”ä¾‹)ã€‚</li>
<li>L2æ­£åˆ™åŒ–ï¼Œå…¶ä¸­å¢åŠ çš„æˆæœ¬ä¸æƒé‡ç³»æ•°çš„å€¼çš„å¹³æ–¹æˆæ­£æ¯”ï¼ˆå³ï¼Œæƒé‡çš„æ‰€è°“â€œ L2èŒƒæ•°â€ï¼‰ã€‚ L2æ­£åˆ™åŒ–åœ¨ç¥ç»ç½‘ç»œä¸­ä¹Ÿç§°ä¸ºæƒé‡è¡°å‡ã€‚ ä¸è¦è®©ä¸åŒçš„åå­—è¿·æƒ‘ä½ :é‡é‡è¡°å‡åœ¨æ•°å­¦ä¸Šå’ŒL2æ­£åˆ™åŒ–æ˜¯å®Œå…¨ä¸€æ ·çš„ã€‚</li>
</ul>
<p>åœ¨Kerasä¸­ï¼Œæƒé‡æ­£åˆ™åŒ–æ˜¯é€šè¿‡å°†æƒé‡æ­£åˆ™åŒ–å®ä¾‹ä¼ é€’ç»™å±‚æ¥æ·»åŠ çš„ã€‚ç°åœ¨è®©æˆ‘ä»¬å°†L2æƒé‡æ­£åˆ™åŒ–æ·»åŠ åˆ°åŸºçº¿æ¨¡å‹ä¸­ã€‚</p>
<pre class="r"><code>l2_model &lt;- 
  keras_model_sequential() %&gt;%
  layer_dense(units = 16, activation = &quot;relu&quot;, input_shape = num_words,
              kernel_regularizer = regularizer_l2(l = 0.001)) %&gt;%
  layer_dense(units = 16, activation = &quot;relu&quot;,
              kernel_regularizer = regularizer_l2(l = 0.001)) %&gt;%
  layer_dense(units = 1, activation = &quot;sigmoid&quot;)

l2_model %&gt;% compile(
  optimizer = &quot;adam&quot;,
  loss = &quot;binary_crossentropy&quot;,
  metrics = list(&quot;accuracy&quot;)
)

l2_history &lt;- l2_model %&gt;% fit(
  train_data,
  train_labels,
  epochs = 20,
  batch_size = 512,
  validation_data = list(test_data, test_labels),
  verbose = 2
)
### Epoch 1/20
### 49/49 - 0s - loss: 0.5858 - accuracy: 0.7506 - val_loss: 0.4587 - val_accuracy: 0.8314
### ...
### Epoch 20/20
### 49/49 - 0s - loss: 0.3177 - accuracy: 0.8785 - val_loss: 0.3523 - val_accuracy: 0.8592</code></pre>
<p>regularizer_l2(l = 0.001)è¡¨ç¤ºè¯¥å±‚æƒé‡çŸ©é˜µä¸­çš„æ¯ä¸€ä¸ªç³»æ•°éƒ½ä¼šä½¿ç½‘ç»œçš„æ€»æŸè€—å¢åŠ 0.001 * weight_coefficient_valueã€‚æ³¨æ„ï¼Œå› ä¸ºè¿™ä¸ªæƒ©ç½šåªåœ¨è®­ç»ƒæ—¶æ·»åŠ ï¼Œæ‰€ä»¥è¿™ä¸ªç½‘ç»œæ¨¡å‹åœ¨è®­ç»ƒæ—¶çš„æŸå¤±è¦æ¯”åœ¨æµ‹è¯•æ—¶é«˜å¾—å¤šã€‚</p>
<p>ä»¥ä¸‹æ˜¯L2æ­£åˆ™åŒ–æƒ©ç½šçš„å½±å“:</p>
<pre class="r"><code>compare_cx &lt;- data.frame(
  baseline_train = baseline_history$metrics$loss,
  baseline_val = baseline_history$metrics$val_loss,
  l2_train = l2_history$metrics$loss,
  l2_val = l2_history$metrics$val_loss
) %&gt;%
  rownames_to_column() %&gt;%
  mutate(rowname = as.integer(rowname)) %&gt;%
  gather(key = &quot;type&quot;, value = &quot;value&quot;, -rowname)
  
ggplot(compare_cx, aes(x = rowname, y = value, color = type)) +
  geom_line() +
  xlab(&quot;epoch&quot;) +
  ylab(&quot;loss&quot;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig11"></span>
<img src="https://s3.ax1x.com/2020/12/26/rhbv26.png" alt="l2æƒé‡æ­£åˆ™åŒ–å¤„ç†çš„ç½‘ç»œæ¨¡å‹çš„æ‹Ÿåˆè¿‡ç¨‹" width="60%" />
<p class="caption">
Figure 11: l2æƒé‡æ­£åˆ™åŒ–å¤„ç†çš„ç½‘ç»œæ¨¡å‹çš„æ‹Ÿåˆè¿‡ç¨‹
</p>
</div>
<p>å¦‚æ‚¨æ‰€è§ï¼ŒL2æ­£åˆ™åŒ–æ¨¡å‹æ¯”åŸºç¡€æ¨¡å‹æ›´èƒ½æŠµæŠ—è¿‡æ‹Ÿåˆï¼Œå³ä½¿ä¸¤ä¸ªæ¨¡å‹å…·æœ‰ç›¸åŒæ•°é‡çš„å‚æ•°ã€‚</p>
</div>
<div id="ä¸¢åŒ…" class="section level5">
<h5>ä¸¢åŒ…</h5>
<p>ä¸¢åŒ…(dropout)æ˜¯ç¥ç»ç½‘ç»œæœ€æœ‰æ•ˆå’Œæœ€å¸¸ç”¨çš„æ­£åˆ™åŒ–æŠ€æœ¯ä¹‹ä¸€ï¼Œç”±Hintonå’Œä»–åœ¨å¤šä¼¦å¤šå¤§å­¦çš„å­¦ç”Ÿå¼€å‘ã€‚ä¸¢åŒ…(dropout)åº”ç”¨äºä¸€ä¸ªå±‚ï¼Œç”±è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºâ€œDropoutâ€(å³è®¾ç½®ä¸ºé›¶)è¯¥å±‚çš„ä¸€äº›è¾“å‡ºç‰¹å¾ç»„æˆã€‚å‡è®¾ç»™å®šçš„å±‚é€šå¸¸ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸ºç»™å®šçš„è¾“å…¥æ ·æœ¬è¿”å›ä¸€ä¸ªå‘é‡[0.2,0.5,1.3,0.8,1.1];åº”ç”¨dropoutåï¼Œè¿™ä¸ªå‘é‡å°†æœ‰å‡ ä¸ªéšæœºåˆ†å¸ƒçš„é›¶é¡¹ï¼Œä¾‹å¦‚[0,0.5,1.3,0,1.1]ã€‚â€œé€€å‡ºç‡â€(â€œdropout rateâ€)æ˜¯è¢«å½’é›¶çš„ç‰¹å¾çš„åˆ†æ•°;é€šå¸¸è®¾ç½®åœ¨0.2åˆ°0.5ä¹‹é—´ã€‚åœ¨æµ‹è¯•æ—¶ï¼Œæ²¡æœ‰å•ä½è¢«åˆ é™¤ï¼Œç›¸åï¼Œè¯¥å±‚çš„è¾“å‡ºå€¼è¢«ç¼©å°äº†ä¸€ä¸ªç­‰äºåˆ é™¤ç‡çš„å› å­ï¼Œä»¥ä¾¿å¹³è¡¡æ›´å¤šçš„å•ä½æ¯”è®­ç»ƒæ—¶æ´»è·ƒçš„äº‹å®ã€‚</p>
<p>åœ¨Kerasä¸­ï¼Œæ‚¨å¯ä»¥é€šè¿‡<em>layer_dropout</em>åœ¨ç½‘ç»œæ¨¡å‹ä¸­å¼•å…¥ä¸¢åŒ…ï¼Œè¯¥ä¸¢åŒ…å°†ç«‹å³åº”ç”¨äºå›¾å±‚çš„è¾“å‡ºã€‚</p>
<p>è®©æˆ‘ä»¬åœ¨IMDBç½‘ç»œä¸­æ·»åŠ ä¸¤ä¸ªdropoutå±‚ï¼Œçœ‹çœ‹å®ƒä»¬åœ¨å‡å°‘è¿‡æ‹Ÿåˆæ–¹é¢åšå¾—å¦‚ä½•:</p>
<pre class="r"><code>dropout_model &lt;- 
  keras_model_sequential() %&gt;%
  layer_dense(units = 16, activation = &quot;relu&quot;, input_shape = num_words) %&gt;%
  layer_dropout(0.6) %&gt;%
  layer_dense(units = 16, activation = &quot;relu&quot;) %&gt;%
  layer_dropout(0.6) %&gt;%
  layer_dense(units = 1, activation = &quot;sigmoid&quot;)

dropout_model %&gt;% compile(
  optimizer = &quot;adam&quot;,
  loss = &quot;binary_crossentropy&quot;,
  metrics = list(&quot;accuracy&quot;)
)

dropout_history &lt;- dropout_model %&gt;% fit(
  train_data,
  train_labels,
  epochs = 20,
  batch_size = 512,
  validation_data = list(test_data, test_labels),
  verbose = 2
)</code></pre>
<p>å®ƒçš„æ•ˆæœå¦‚ä½•?æ·»åŠ dropoutæ˜¯å¯¹åŸºçº¿æ¨¡å‹çš„æ˜æ˜¾æ”¹è¿›ã€‚</p>
<pre class="r"><code>compare_cx &lt;- data.frame(
  baseline_train = baseline_history$metrics$loss,
  baseline_val = baseline_history$metrics$val_loss,
  dropout_train = dropout_history$metrics$loss,
  dropout_val = dropout_history$metrics$val_loss
) %&gt;%
  rownames_to_column() %&gt;%
  mutate(rowname = as.integer(rowname)) %&gt;%
  gather(key = &quot;type&quot;, value = &quot;value&quot;, -rowname)
  
ggplot(compare_cx, aes(x = rowname, y = value, color = type)) +
  geom_line() +
  xlab(&quot;epoch&quot;) +
  ylab(&quot;loss&quot;)
</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig12"></span>
<img src="https://s3.ax1x.com/2020/12/26/rhOF3t.png" alt="ä¸¢åŒ…æ­£åˆ™åŒ–å¤„ç†çš„ç½‘ç»œæ¨¡å‹çš„æ‹Ÿåˆè¿‡ç¨‹" width="60%" />
<p class="caption">
Figure 12: ä¸¢åŒ…æ­£åˆ™åŒ–å¤„ç†çš„ç½‘ç»œæ¨¡å‹çš„æ‹Ÿåˆè¿‡ç¨‹
</p>
</div>
<p>æ€»ç»“ä¸€ä¸‹ï¼Œä»¥ä¸‹æ˜¯é˜²æ­¢ç¥ç»ç½‘ç»œè¿‡åº¦æ‹Ÿåˆçš„æœ€å¸¸è§æ–¹æ³•:</p>
<ul>
<li><p>è·å–æ›´å¤šçš„è®­ç»ƒæ•°æ®ã€‚</p></li>
<li><p>è¯·é™ä½ç½‘ç»œå®¹é‡ã€‚</p></li>
<li><p>å¢åŠ æƒé‡æ­£åˆ™åŒ–å¤„ç†</p></li>
<li><p>å¢åŠ ä¸¢åŒ…æ­£åˆ™åŒ–å¤„ç†</p></li>
</ul>
<p>æœ¬æŒ‡å—ä¸­æ²¡æœ‰æ¶‰åŠçš„ä¸¤ç§é‡è¦æ–¹æ³•æ˜¯æ•°æ®å¢å¼º(Data augmentation )å’Œæ‰¹å½’ä¸€åŒ–(Batch normalization)ã€‚</p>
</div>
</div>
</div>
<div id="ä¿å­˜å’Œæ¢å¤æ¨¡å‹" class="section level3">
<h3>ä¿å­˜å’Œæ¢å¤æ¨¡å‹</h3>
<p>å¯ä»¥åœ¨è®­ç»ƒåå’Œè®­ç»ƒä¸­ä¿å­˜æ¨¡å‹è¿›åº¦ã€‚è¿™æ„å‘³ç€ä¸€ä¸ªæ¨¡å‹å¯ä»¥åœ¨å®ƒåœæ­¢çš„åœ°æ–¹æ¢å¤ï¼Œé¿å…é•¿æ—¶é—´çš„è®­ç»ƒã€‚ä¿å­˜è¿˜æ„å‘³ç€æ‚¨å¯ä»¥å…±äº«æ‚¨çš„æ¨¡å‹ï¼Œå…¶ä»–äººå¯ä»¥é‡æ–°åˆ›å»ºæ‚¨çš„å·¥ä½œã€‚åœ¨å‘å¸ƒç ”ç©¶æ¨¡å‹å’ŒæŠ€æœ¯æ—¶ï¼Œä¸å¤§å¤šæ•°æœºå™¨å­¦ä¹ å®è·µè€…åˆ†äº«:</p>
<ul>
<li><p>åˆ›å»ºæ¨¡å‹çš„ä»£ç </p></li>
<li><p>è®­ç»ƒè¿‡çš„æƒé‡ï¼Œæˆ–æ¨¡å‹çš„å‚æ•°</p></li>
</ul>
<p>å…±äº«è¿™äº›æ•°æ®å¯ä»¥å¸®åŠ©å…¶ä»–äººç†è§£æ¨¡å‹çš„å·¥ä½œæ–¹å¼ï¼Œå¹¶ä½¿ç”¨æ–°æ•°æ®è‡ªå·±å°è¯•ã€‚</p>
<div id="é€‰é¡¹" class="section level4">
<h4>é€‰é¡¹</h4>
<p>æœ‰å¾ˆå¤šä¸åŒçš„æ–¹æ³•æ¥ä¿å­˜TensorFlowæ¨¡å‹â€”â€”è¿™å–å†³äºä½ ä½¿ç”¨çš„APIã€‚æœ¬æŒ‡å—ä½¿ç”¨Kerasï¼Œä¸€ä¸ªé«˜çº§APIæ¥æ„å»ºå’Œè®­ç»ƒTensorFlowæ¨¡å‹ã€‚å¯¹äºå…¶ä»–æ–¹æ³•ï¼Œå‚è§<a href="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_save_and_restore/todo">TensorFlow Save and Restore guide</a>æˆ–<a href="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_save_and_restore/todo">Saving in eager</a>ã€‚</p>
</div>
<div id="è®¾ç½®" class="section level4">
<h4>è®¾ç½®</h4>
<p>æˆ‘ä»¬å°†ä½¿ç”¨<a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>æ•°æ®é›†è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹æ¥æ¼”ç¤ºä¿å­˜è®­ç»ƒåçš„æƒé‡ã€‚ä¸ºäº†åŠ å¿«è¿™äº›æ¼”ç¤ºçš„è¿è¡Œé€Ÿåº¦ï¼Œåªä½¿ç”¨å‰1000ä¸ªç¤ºä¾‹:</p>
<pre class="r"><code>library(keras)

mnist &lt;- dataset_mnist()

c(train_images, train_labels) %&lt;-% mnist$train
c(test_images, test_labels) %&lt;-% mnist$test

train_labels &lt;- train_labels[1:1000]
test_labels &lt;- test_labels[1:1000]

train_images &lt;- train_images[1:1000, , ] %&gt;%
  array_reshape(c(1000, 28 * 28))
train_images &lt;- train_images / 255

test_images &lt;- test_images[1:1000, , ] %&gt;%
  array_reshape(c(1000, 28 * 28))
test_images &lt;- test_images / 255</code></pre>
</div>
<div id="å®šä¹‰ä¸€ä¸ªæ¨¡å‹" class="section level4">
<h4>å®šä¹‰ä¸€ä¸ªæ¨¡å‹</h4>
<p>è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªç®€å•çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®ƒæ¥æ¼”ç¤ºä¿å­˜å’ŒåŠ è½½æƒé‡ã€‚</p>
<pre class="r"><code># è¿”å›ä¸€ä¸ªçŸ­åºåˆ—æ¨¡å‹
create_model &lt;- function() {
  model &lt;- keras_model_sequential() %&gt;%
    layer_dense(units = 512, activation = &quot;relu&quot;, input_shape = 784) %&gt;%
    layer_dropout(0.2) %&gt;%
    layer_dense(units = 10, activation = &quot;softmax&quot;)
  model %&gt;% compile(
    optimizer = &quot;adam&quot;,
    loss = &quot;sparse_categorical_crossentropy&quot;,
    metrics = list(&quot;accuracy&quot;)
  )
  model
}

model &lt;- create_model()
summary(model)
### Model: &quot;sequential&quot;
### ________________________________________________________________________________
### Layer (type)                        Output Shape                    Param #
### ================================================================================
### dense_1 (Dense)                     (None, 512)                     401920
### ________________________________________________________________________________
### dropout (Dropout)                   (None, 512)                     0
### ________________________________________________________________________________
### dense (Dense)                       (None, 10)                      5130
### ================================================================================
### Total params: 407,050
### Trainable params: 407,050
### Non-trainable params: 0
### ________________________________________________________________________________
### 
</code></pre>
</div>
<div id="ä¿å­˜æ•´ä¸ªæ¨¡å‹" class="section level4">
<h4>ä¿å­˜æ•´ä¸ªæ¨¡å‹</h4>
<p>è°ƒç”¨<em>save_model_*</em> å°†æ¨¡å‹çš„æ¶æ„ã€æƒé‡å’Œè®­ç»ƒé…ç½®ä¿å­˜åœ¨å•ä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹ä¸­ã€‚è¿™å…è®¸æ‚¨å¯¼å‡ºæ¨¡å‹ï¼Œä»¥ä¾¿åœ¨ä¸è®¿é—®åŸå§‹ä»£ç çš„æƒ…å†µä¸‹ä½¿ç”¨å®ƒã€‚ç”±äºä¼˜åŒ–å™¨çŠ¶æ€å·²ç»æ¢å¤ï¼Œæ‚¨å¯ä»¥ä»ä¸­æ–­çš„ä½ç½®æ¢å¤è®­ç»ƒã€‚</p>
<p>ä¿å­˜æ¨¡å‹çš„å¸¸ç”¨å‡½æ•°åŠå…¶åŠ è½½å‡½æ•°ï¼š
- save_model_hdf5() å’Œ load_model_hdf5</p>
<ul>
<li><p>save_model_tf() å’Œ load_model_tf()</p></li>
<li><p>save_model_weights_hdf5() å’Œ load_model_weights_hdf5():</p></li>
<li><p>save_model_weights_tf() å’Œ load_model_weights_tf():</p></li>
</ul>
<p>ä¿å­˜ä¸€ä¸ªå…¨åŠŸèƒ½æ¨¡å‹æ˜¯éå¸¸æœ‰ç”¨çš„â€”â€”ä½ å¯ä»¥åœ¨TensorFlow.js (HDF5, Saved Model)ä¸­åŠ è½½å®ƒä»¬ï¼Œç„¶ååœ¨webæµè§ˆå™¨ä¸­è®­ç»ƒå’Œè¿è¡Œå®ƒä»¬ï¼Œæˆ–è€…ä½¿ç”¨TensorFlow Lite (HDF5, Saved Nodel)å°†å®ƒä»¬è½¬æ¢åˆ°ç§»åŠ¨è®¾å¤‡ä¸Šè¿è¡Œã€‚</p>
</div>
<div id="savedmodelæ ¼å¼" class="section level4">
<h4>SAVEDMODELæ ¼å¼</h4>
<p>SavedModelæ ¼å¼æ˜¯ä¸€ç§åºåˆ—åŒ–æ¨¡å‹çš„æ–¹æ³•ã€‚ä»¥è¿™ç§æ ¼å¼ä¿å­˜çš„æ¨¡å‹å¯ä»¥ä½¿ç”¨<em>load_model_t()</em>æ¢å¤ï¼Œå¹¶ä¸”ä¸TensorFlowæœåŠ¡å…¼å®¹ã€‚<a href="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_save_and_restore/todo">SavedModelæŒ‡å—</a>è¯¦ç»†ä»‹ç»äº†å¦‚ä½•æœåŠ¡/æ£€æŸ¥SavedModelã€‚ä¸‹é¢çš„éƒ¨åˆ†æ¼”ç¤ºäº†ä¿å­˜å’Œæ¢å¤æ¨¡å‹çš„æ­¥éª¤ã€‚ä¸‹é¢çš„éƒ¨åˆ†æ¼”ç¤ºäº†ä¿å­˜å’Œæ¢å¤æ¨¡å‹çš„æ­¥éª¤ã€‚</p>
<pre class="r"><code>model &lt;- create_model()

model %&gt;% fit(train_images, train_labels, epochs = 5, verbose = 2)

### SavedModel æ ¼å¼æ˜¯ä¸€ä¸ªåŒ…å«protobufäºŒè¿›åˆ¶æ–‡ä»¶å’ŒTensorflowæ£€æŸ¥ç‚¹çš„ç›®å½•ã€‚
model %&gt;% save_model_tf(&quot;model&quot;)
##æ£€æŸ¥ä¿å­˜çš„æ¨¡å‹ç›®å½•:
list.files(&quot;model&quot;)

### ä»ä¿å­˜çš„æ¨¡å‹ä¸­é‡æ–°åŠ è½½ä¸€ä¸ªæ–°çš„Kerasæ¨¡å‹:
new_model &lt;- load_model_tf(&quot;model&quot;)
summary(new_model)</code></pre>
</div>
<div id="hdf5æ ¼å¼" class="section level4">
<h4>HDF5æ ¼å¼</h4>
<p>Kerasä½¿ç”¨HDF5æ ‡å‡†æä¾›äº†åŸºæœ¬çš„ä¿å­˜æ ¼å¼ã€‚</p>
<pre class="r"><code>model &lt;- create_model()
model %&gt;% fit(train_images, train_labels, epochs = 5, verbose = 2)

model %&gt;% save_model_hdf5(&quot;my_model.h5&quot;)

### ç°åœ¨ä»æ–‡ä»¶ä¸­é‡æ–°åˆ›å»ºæ¨¡å‹:
new_model &lt;- load_model_hdf5(&quot;my_model.h5&quot;)
summary(new_model)</code></pre>
<p>è¿™ç§æŠ€æœ¯å¯ä»¥ä¿å­˜æ‰€æœ‰ä¿¡æ¯ï¼š</p>
<ul>
<li><p>æƒé‡å€¼</p></li>
<li><p>æ¨¡å‹çš„é…ç½®ï¼ˆæ¶æ„ï¼‰</p></li>
<li><p>ä¼˜åŒ–å™¨é…ç½®</p></li>
</ul>
<p>Kerasçš„SavedModelé€šè¿‡æ£€æŸ¥æ¶æ„æ¥ä¿å­˜æ¨¡å‹ã€‚ç›®å‰ï¼ŒSavedModelä¸èƒ½ä¿å­˜TensorFlowä¼˜åŒ–å™¨(åœ¨tf$trainä¸­)ã€‚åœ¨ä½¿ç”¨SavedModelæ—¶ï¼Œæ‚¨å°†éœ€è¦åœ¨åŠ è½½åé‡æ–°ç¼–è¯‘æ¨¡å‹ï¼Œå¹¶ä¸”æ‚¨å°†ä¸¢å¤±ä¼˜åŒ–å™¨çš„çŠ¶æ€ã€‚</p>
</div>
<div id="ä¿å­˜è‡ªå®šä¹‰å¯¹è±¡" class="section level4">
<h4>ä¿å­˜è‡ªå®šä¹‰å¯¹è±¡</h4>
<p>å¦‚æœæ‚¨ä½¿ç”¨SavedModelæ ¼å¼ï¼Œåˆ™å¯ä»¥è·³è¿‡æœ¬èŠ‚ã€‚HDF5å’ŒSavedModelçš„å…³é”®åŒºåˆ«åœ¨äºï¼ŒHDF5ä½¿ç”¨å¯¹è±¡é…ç½®æ¥ä¿å­˜æ¨¡å‹æ¶æ„ï¼Œè€ŒSavedModelåˆ™ä¿å­˜æ‰§è¡Œå›¾ã€‚</p>
<p>å› æ­¤ï¼ŒSavedModelsèƒ½å¤Ÿä¿å­˜è‡ªå®šä¹‰å¯¹è±¡ï¼Œå¦‚å­ç±»æ¨¡å‹å’Œè‡ªå®šä¹‰å±‚ï¼Œè€Œä¸éœ€è¦åŸå§‹ä»£ç ã€‚</p>
<p>è¦å°†è‡ªå®šä¹‰å¯¹è±¡ä¿å­˜åˆ°HDF5ï¼Œå¿…é¡»æ‰§è¡Œä»¥ä¸‹æ“ä½œ:</p>
<ol style="list-style-type: decimal">
<li><p>åœ¨å¯¹è±¡ä¸­å®šä¹‰ä¸€ä¸ªget_configæ–¹æ³•ï¼Œè¿˜æœ‰ä¸€ä¸ªfrom_configç±»æ–¹æ³•ã€‚</p>
<ul>
<li><p>get_config()è¿”å›ä¸€ä¸ªjsonå¯åºåˆ—åŒ–çš„å‚æ•°å­—å…¸ï¼Œå…¶ä¸­åŒ…å«é‡æ–°åˆ›å»ºå¯¹è±¡æ‰€éœ€çš„å‚æ•°ã€‚</p></li>
<li><p>from_config(config)ä½¿ç”¨ä»get_config()è¿”å›çš„é…ç½®æ¥åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è±¡ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¯¥å‡½æ•°å°†ä½¿ç”¨configä½œä¸ºåˆå§‹åŒ–å‚æ•°ã€‚</p></li>
</ul></li>
<li><p>åœ¨åŠ è½½æ¨¡å‹æ—¶å°†å¯¹è±¡ä¼ é€’ç»™<em>custom_objects</em>å‚æ•°ã€‚å‚æ•°å¿…é¡»æ˜¯ä¸€ä¸ªå°†å­—ç¬¦ä¸²ç±»åæ˜ å°„åˆ°ç±»å®šä¹‰çš„å‘½ååˆ—è¡¨ã€‚ä¾‹å¦‚ load_keras_model_hdf5(path, custom_objects=list(â€œCustomLayerâ€ = CustomLayer))</p></li>
</ol>
<p>å…³äºcustom_objects()å’Œget_config()çš„ç¤ºä¾‹ï¼Œè¯·å‚é˜…<a href="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_save_and_restore/todo">ä»å¤´ç¼–å†™å±‚å’Œæ¨¡å‹æ•™ç¨‹</a>ï¼Œ<strong>è²Œä¼¼è¿™éƒ¨åˆ†å†…å®¹è¿˜æ²¡å®Œæˆ</strong>ã€‚</p>
</div>
<div id="åœ¨è®­ç»ƒæœŸé—´ä¿å­˜æ£€æŸ¥ç‚¹" class="section level4">
<h4>åœ¨è®­ç»ƒæœŸé—´ä¿å­˜æ£€æŸ¥ç‚¹</h4>
<p>åœ¨è®­ç»ƒæœŸé—´å’Œç»“æŸæ—¶è‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸€ä¸ªè®­ç»ƒè¿‡çš„æ¨¡å‹ï¼Œè€Œä¸å¿…é‡æ–°è®­ç»ƒå®ƒï¼Œæˆ–è€…åœ¨ä½ ç¦»å¼€çš„åœ°æ–¹æ¥ä¸Šè®­ç»ƒï¼Œä»¥é˜²è®­ç»ƒè¿‡ç¨‹ä¸­æ–­ã€‚</p>
<p>callback_model_checkpointæ˜¯æ‰§è¡Œæ­¤ä»»åŠ¡çš„å›è°ƒå‡½æ•°ã€‚</p>
<p>å›è°ƒå‡½æ•°æ¥å—ä¸¤ä¸ªå‚æ•°æ¥é…ç½®æ£€æŸ¥ç‚¹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œsave_weights_onlyè®¾ç½®ä¸ºfalseï¼Œè¿™æ„å‘³ç€ä¿å­˜å®Œæ•´çš„æ¨¡å‹â€”â€”åŒ…æ‹¬æ¶æ„å’Œé…ç½®ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥æŒ‰ç…§å‰ä¸€æ®µæ‰€è¿°çš„æ–¹å¼æ¢å¤æ¨¡å‹ã€‚</p>
<p>ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä¸“æ³¨äºä¿å­˜å’Œæ¢å¤æƒé‡ã€‚åœ¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬å°†save_weights_onlyè®¾ç½®ä¸ºtrueï¼Œå› æ­¤åœ¨æ¢å¤æ—¶éœ€è¦æ¨¡å‹å®šä¹‰ã€‚</p>
<div id="ä½¿ç”¨æ£€æŸ¥ç‚¹å›è°ƒ" class="section level5">
<h5>ä½¿ç”¨æ£€æŸ¥ç‚¹å›è°ƒ</h5>
<p>è®­ç»ƒæ¨¡å‹å¹¶ç»™å®ƒä¼ é€’callback_model_checkpoint:</p>
<pre class="r"><code>checkpoint_path &lt;- &quot;checkpoints/cp.ckpt&quot;

# Create checkpoint callback
cp_callback &lt;- callback_model_checkpoint(
  filepath = checkpoint_path,
  save_weights_only = TRUE,
  verbose = 0
)

model &lt;- create_model()

model %&gt;% fit(
  train_images,
  train_labels,
  epochs = 10, 
  validation_data = list(test_images, test_labels),
  callbacks = list(cp_callback),  # pass callback to training
  verbose = 2
)</code></pre>
<p>æ£€æŸ¥åˆ›å»ºçš„æ–‡ä»¶:</p>
<pre class="r"><code>list.files(dirname(checkpoint_path))</code></pre>
<p>åˆ›å»ºä¸€ä¸ªæ–°çš„æœªç»è®­ç»ƒçš„æ¨¡å‹ã€‚å½“ä»…ä»æƒé‡æ¢å¤æ¨¡å‹æ—¶ï¼Œæ‚¨å¿…é¡»æ‹¥æœ‰ä¸åŸå§‹æ¨¡å‹å…·æœ‰ç›¸åŒæ¶æ„çš„æ¨¡å‹ã€‚ç”±äºå®ƒæ˜¯ç›¸åŒçš„æ¨¡å‹æ¶æ„ï¼Œæˆ‘ä»¬å¯ä»¥å…±äº«æƒé‡ï¼Œå°½ç®¡å®ƒæ˜¯æ¨¡å‹çš„ä¸åŒå®ä¾‹ã€‚</p>
<p>ç°åœ¨é‡å»ºä¸€ä¸ªæ–°çš„ï¼Œæœªç»è®­ç»ƒçš„æ¨¡å‹ï¼Œå¹¶åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°å®ƒã€‚æœªç»è®­ç»ƒçš„æ¨¡å‹å°†åœ¨æ¦‚ç‡æ°´å¹³(~7% ç²¾ç¡®åº¦)æ‰§è¡Œ:</p>
<pre class="r"><code>fresh_model &lt;- create_model()
fresh_model %&gt;% evaluate(test_images, test_labels, verbose = 0)
###     loss accuracy
### 2.326613 0.069000
</code></pre>
<p>ç„¶åä»æœ€æ–°çš„æ£€æŸ¥ç‚¹(epoch 10)åŠ è½½æƒé‡ï¼Œå¹¶é‡æ–°è¯„ä¼°:</p>
<pre class="r"><code>fresh_model %&gt;% load_model_weights_tf(filepath = checkpoint_path)
fresh_model %&gt;% evaluate(test_images, test_labels, verbose = 0)
###      loss  accuracy
### 0.4079803 0.8700000
</code></pre>
</div>
<div id="æ£€æŸ¥ç‚¹å›è°ƒé€‰é¡¹" class="section level5">
<h5>æ£€æŸ¥ç‚¹å›è°ƒé€‰é¡¹</h5>
<p>å¦å¤–ï¼Œæ‚¨å¯ä»¥å†³å®šä»…ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œæœ€ä½³æ¨¡å‹å®šä¹‰ä¸ºéªŒè¯æŸå¤±æœ€å°ã€‚ æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§<a href="https://tensorflow.rstudio.com/keras/reference/callback_model_checkpoint.html">callback_model_checkpointçš„æ–‡æ¡£</a>ã€‚</p>
<pre class="r"><code>checkpoint_path &lt;- &quot;checkpoints/cp.ckpt&quot;

# Create checkpoint callback
cp_callback &lt;- callback_model_checkpoint(
  filepath = checkpoint_path,
  save_weights_only = TRUE,
  save_best_only = TRUE,
  verbose = 1
)

model &lt;- create_model()

model %&gt;% fit(
  train_images,
  train_labels,
  epochs = 10, 
  validation_data = list(test_images, test_labels),
  callbacks = list(cp_callback), # pass callback to training,
  verbose = 2
)

list.files(dirname(checkpoint_path))</code></pre>
</div>
<div id="è¿™äº›æ–‡ä»¶æ˜¯ä»€ä¹ˆ" class="section level5">
<h5>è¿™äº›æ–‡ä»¶æ˜¯ä»€ä¹ˆ?</h5>
<p>ä¸Šä¸Šé¢çš„ä»£ç å°†æƒé‡å­˜å‚¨åˆ°<a href="https://www.tensorflow.org/guide/saved_model#save_and_restore_variables">æ£€æŸ¥ç‚¹æ ¼å¼</a> (<a href="https://www.tensorflow.org/guide/saved_model#save_and_restore_variables">checkpoint-formatted</a>)çš„æ–‡ä»¶é›†åˆä¸­ï¼Œè¿™äº›æ–‡ä»¶ä»…ä»¥äºŒè¿›åˆ¶æ ¼å¼åŒ…å«è®­ç»ƒè¿‡çš„æƒé‡ã€‚ æ£€æŸ¥ç‚¹åŒ…å«ï¼š</p>
<ul>
<li><p>ä¸€ä¸ªæˆ–å¤šä¸ªåŒ…å«æ¨¡å‹æƒé‡çš„ç¢ç‰‡ã€‚</p></li>
<li><p>ä¸€ä¸ªç´¢å¼•æ–‡ä»¶ï¼ŒæŒ‡ç¤ºå“ªäº›æƒé‡å­˜å‚¨åœ¨å“ªä¸ªåˆ†ç‰‡ä¸­ã€‚</p></li>
</ul>
<p>å¦‚æœæ‚¨ä»…åœ¨ä¸€å°æœºå™¨ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œåˆ™åç¼€ä¸º <em>.s-data-00000-of-00001</em>ã€‚</p>
</div>
</div>
<div id="æ‰‹åŠ¨ä¿å­˜æƒé‡" class="section level4">
<h4>æ‰‹åŠ¨ä¿å­˜æƒé‡</h4>
<p>æ‚¨äº†è§£äº†å¦‚ä½•å°†æƒé‡åŠ è½½åˆ°æ¨¡å‹ä¸­ã€‚æ‰‹åŠ¨ä¿å­˜å®ƒä»¬ä½¿ç”¨save_model_weights_tfå‡½æ•°ä¹Ÿä¸€æ ·ç®€å•ã€‚</p>
<pre class="r"><code># ä¿å­˜æƒé‡
model %&gt;% save_model_weights_tf(&quot;checkpoints/cp.ckpt&quot;)

# åˆ›å»ºä¸€ä¸ªæ–°çš„æ¨¡å‹å®ä¾‹
new_model &lt;- create_model()

# æ¢å¤æƒé‡è¿›å…¥ç¿»è¯‘é¡µé¢
new_model %&gt;% load_model_weights_tf(&#39;checkpoints/cp.ckpt&#39;)

# è¯„ä»·æ¨¡å‹
new_model %&gt;% evaluate(test_images, test_labels, verbose = 0)
###     loss accuracy
###  0.39937  0.86800
</code></pre>
</div>
</div>
</div>
