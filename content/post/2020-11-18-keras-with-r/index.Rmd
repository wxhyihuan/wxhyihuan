---
title: blogtest
author: wxhyihuan
date: '2020-11-18'
slug: keras-with-r
output:
  blogdown::html_page:
    toc: true
    toc_depth: 3
    fig_width: 6
    dev: "svg"
    css: style.css
categories:
  - R
  - Keras
tags:
  - Keras
  - RStudio
  - R
draft: true
---

:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**NOTICE!**
:::
Thank you for noticing this **new notice**! Your noticing it has
been noted, and _will be reported to the authorities_! ğŸ‘
::::

## Kerasæœºå™¨å­¦ä¹ çš„åŸºç¡€

### æ¦‚è§ˆ
æœ¬è¯¾ç¨‹åŒ…æ‹¬å…³äºä½¿ç”¨Kerasè¿›è¡Œæœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µçš„æ•™ç¨‹ã€‚

- [å›¾åƒåˆ†ç±»](#åŸºæœ¬çš„å›¾åƒåˆ†ç±»)ï¼šä½¿ç”¨fashingmistæ•°æ®é›†è¿›è¡Œå›¾åƒåˆ†ç±»ã€‚
  
- [å›å½’](#åŸºæœ¬çš„å›¾åƒåˆ†ç±»)ï¼šä½¿ç”¨æ³¢å£«é¡¿ä½æˆ¿æ•°æ®é›†è¿›è¡Œå›å½’ã€‚
  
- [æ–‡æœ¬åˆ†ç±»](#åŸºæœ¬çš„å›¾åƒåˆ†ç±»)ï¼šä½¿ç”¨IMDBæ•°æ®é›†è¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€‚
  
- [è¿‡æ‹Ÿåˆå’Œä¸æ‹Ÿåˆ](#åŸºæœ¬çš„å›¾åƒåˆ†ç±»)ï¼šå­¦ä¹ MLä¸­çš„è¿™äº›é‡è¦æ¦‚å¿µã€‚
  
- [ä¿å­˜å’Œæ¢å¤](#åŸºæœ¬çš„å›¾åƒåˆ†ç±»)ï¼šå­¦ä¹ å¦‚ä½•ä¿å­˜å’Œæ¢å¤TensorFlowæ¨¡å‹ã€‚

### åŸºæœ¬çš„å›¾åƒåˆ†ç±»

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹æ¥åˆ†ç±»æœè£…å›¾åƒï¼Œå¦‚è¿åŠ¨é‹å’Œè¡¬è¡«ã€‚å¦‚æœæ‚¨ä¸ç†è§£æ‰€æœ‰çš„ç»†èŠ‚ä¹Ÿæ²¡å…³ç³»ï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„Kerasç¨‹åºçš„å¿«é€Ÿæ¦‚è¿°ï¼Œè¯¦ç»†ä¿¡æ¯å°†éšæˆ‘ä»¬çš„è¿›å±•è€Œè§£é‡Šã€‚

```r
library(tensorflow)
library(keras)
```

#### å¯¼å…¥Fashion MNISTæ•°æ®é›†
```r
fashion_mnist <- dataset_fashion_mnist()
```
æœ¬æŒ‡å—ä½¿ç”¨[Fashion MNIST]æ•°æ®é›†ï¼ŒåŒ…å«10ä¸ªç±»åˆ«çš„7ä¸‡å¼ ç°åº¦å›¾åƒã€‚è¿™äº›å›¾ç‰‡ä»¥ä½åˆ†è¾¨ç‡(28x28åƒç´ )å±•ç¤ºäº†è¡£ä¸ªåˆ«æœï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º:

```{r fig1, echo=FALSE, out.width="60%", fig.cap ='Fashion MNIST æ ·å“(*Zalando, MIT License*)',fig.align='center'} 

knitr::include_graphics("https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/images/fashion-mnist-sprite.png")
```
[Fashion MNIST]çš„ç›®çš„æ˜¯æ›¿ä»£ç»å…¸çš„[MNIST]æ•°æ®é›†ï¼Œåè€…é€šå¸¸è¢«ç”¨ä½œè®¡ç®—æœºè§†è§‰æœºå™¨å­¦ä¹ ç¨‹åºçš„â€œHello, Worldâ€ã€‚[MNIST]æ•°æ®é›†åŒ…å«æ‰‹å†™æ•°å­—(0ã€1ã€2ç­‰)çš„å›¾åƒï¼Œå…¶æ ¼å¼ä¸æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨çš„è¡£ç‰©æ•°æ®ç›¸åŒã€‚

æœ¬æŒ‡å—ä½¿ç”¨[Fashion MNIST]è¿›è¡Œå„ç§å„æ ·çš„æ“ä½œï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªæ¯”å¸¸è§„[MNIST]æ›´å…·æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚è¿™ä¸¤ä¸ªæ•°æ®é›†éƒ½ç›¸å¯¹è¾ƒå°ï¼Œç”¨äºéªŒè¯ç®—æ³•æ˜¯å¦å¦‚é¢„æœŸçš„é‚£æ ·å·¥ä½œã€‚å®ƒä»¬æ˜¯æµ‹è¯•å’Œè°ƒè¯•ä»£ç çš„è‰¯å¥½èµ·ç‚¹ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨60,000å¼ å›¾åƒæ¥è®­ç»ƒç½‘ç»œï¼Œå¹¶ä½¿ç”¨10,000å¼ å›¾åƒæ¥è¯„ä¼°ç½‘ç»œå­¦ä¹ åˆ†ç±»å›¾åƒçš„å‡†ç¡®æ€§ã€‚ä½ å¯ä»¥ç›´æ¥ä»Kerasè®¿é—®[Fashion MNIST]ã€‚

```r
fashion_mnist <- dataset_fashion_mnist()

c(train_images, train_labels) %<-% fashion_mnist$train
c(test_images, test_labels) %<-% fashion_mnist$test
```

ç°åœ¨æˆ‘ä»¬æœ‰å››ä¸ªæ•°ç»„: train_imageså’Œtrain_labelsæ•°ç»„æ˜¯è®­ç»ƒé›†â€”â€”å³æ¨¡å‹ç”¨æ¥å­¦ä¹ çš„æ•°æ®ã€‚æ¨¡å‹æ ¹æ®æµ‹è¯•é›†è¿›è¡Œæµ‹è¯•çš„æµ‹è¯•æ•°æ®:test_imageså’Œtest_labelsã€‚

æ¯ä¸ªå›¾åƒéƒ½æ˜¯28x28ä¸ªæ•°ç»„ï¼Œåƒç´ å€¼åœ¨0åˆ°255ä¹‹é—´ã€‚æ ‡ç­¾ä¸ºæ•´æ•°æ•°ç»„ï¼Œå–å€¼èŒƒå›´ä¸º0 ~ 9ã€‚è¿™äº›å¯¹åº”äºå›¾åƒæ‰€ä»£è¡¨çš„æœè£…ç±»åˆ«:
```{r tablable, echo=FALSE,warning=FALSE,message=FALSE} 
library("dplyr")
library("kableExtra") 
Digit<-c(0:9)
Class = c('T-shirt/top',              'Trouser',
                'Pullover',           'Dress',
                'Coat',               'Sandal',
                'Shirt',              'Sneaker',
                'Bag',                'Ankle boot')
funsiontab<-cbind(Digit,Class)
knitr::kable( funsiontab, caption = 'æœè£…ç±»åˆ«åŠå¯¹åº”çš„æ•°å­—ç¼–å·',
    booktabs = TRUE, digits = '4', align='ccc',format.args = list(scientific = FALSE)) %>%
kable_paper("striped", full_width = F)  %>% 
kableExtra::kable_classic_2() 
```
æ¯ä¸ªå›¾åƒéƒ½æ˜ å°„åˆ°å•ä¸ªæ ‡ç­¾ã€‚ç”±äºç±»åä¸åŒ…å«åœ¨æ•°æ®é›†ä¸­ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªå‘é‡ä¸­ï¼Œä»¥ä¾¿ç¨åç»˜åˆ¶å›¾åƒæ—¶ä½¿ç”¨ã€‚
```r
class_names = c('T-shirt/top',              'Trouser',
                'Pullover',           'Dress',
                'Coat',               'Sandal',
                'Shirt',              'Sneaker',
                'Bag',                'Ankle boot')
```

#### æ£€è§†æ•°æ®
åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç ”ç©¶ä¸€ä¸‹æ•°æ®é›†çš„æ ¼å¼ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè®­ç»ƒé›†ä¸­æœ‰60000å¼ å›¾åƒï¼Œæ¯å¼ å›¾åƒç”¨28x28åƒç´ è¡¨ç¤ºã€‚

```r
# è®­ç»ƒé›†ä¸­æœ‰60000å¼ å›¾åƒï¼Œæ¯å¼ å›¾åƒç”¨28x28åƒç´ è¡¨ç¤ºã€‚
dim(train_images)
dim(train_labels)
# è®­ç»ƒé›†æ¯ä¸ªæ ‡ç­¾æ˜¯0åˆ°9ä¹‹é—´çš„æ•´æ•°:
table(train_labels)

# æµ‹è¯•é›†ä¸­æœ‰10000å¼ å›¾åƒã€‚åŒæ ·ï¼Œæ¯å¼ å›¾åƒç”¨28Ã—28åƒç´ è¡¨ç¤º
dim(test_images)
dim(test_labels)
# æµ‹è¯•é›†æ¯ä¸ªæ ‡ç­¾æ˜¯0åˆ°9ä¹‹é—´çš„æ•´æ•°:
table(test_labels)

```

#### æ•°æ®é¢„å¤„ç†

åœ¨è®­ç»ƒç½‘ç»œä¹‹å‰ï¼Œå¿…é¡»å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚å¦‚æœä½ æ£€æŸ¥è®­ç»ƒé›†ä¸­çš„ç¬¬ä¸€å¼ å›¾åƒï¼Œä½ ä¼šçœ‹åˆ°åƒç´ å€¼çš„èŒƒå›´æ˜¯0åˆ°255:

```r
library(tidyr)
library(ggplot2)

image_1 <- as.data.frame(train_images[1, , ])
colnames(image_1) <- seq_len(ncol(image_1))
image_1$y <- seq_len(nrow(image_1))
image_1 <- gather(image_1, "x", "value", -y)
image_1$x <- as.integer(image_1$x)

ggplot(image_1, aes(x = x, y = y, fill = value)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "black", na.value = NA) +
  scale_y_reverse() +
  theme_minimal() +
  theme(panel.grid = element_blank())   +
  theme(aspect.ratio = 1) +
  xlab("") +
  ylab("")
```
```{r fig2, echo=FALSE,out.width="49%", fig.cap ='æ£€æŸ¥è®­ç»ƒé›†ä¸­çš„ç¬¬ä¸€å¼ å›¾åƒ',fig.align='center'} 

knitr::include_graphics('https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification_files/figure-html/unnamed-chunk-9-1.png')
```
åœ¨è¾“å…¥åˆ°ç¥ç»ç½‘ç»œæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬å°†è¿™äº›å€¼ç¼©æ”¾åˆ°0åˆ°1çš„èŒƒå›´å†…ã€‚å¯¹äºè¿™ä¸ªï¼Œæˆ‘ä»¬åªéœ€è¦é™¤ä»¥255ã€‚é‡è¦çš„æ˜¯è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä»¥ç›¸åŒçš„æ–¹å¼è¿›è¡Œé¢„å¤„ç†:
```r
train_images <- train_images / 255
test_images <- test_images / 255
```
æ˜¾ç¤ºè®­ç»ƒé›†çš„å‰25å¼ å›¾åƒï¼Œå¹¶åœ¨æ¯å¼ å›¾åƒä¸‹é¢æ˜¾ç¤ºç±»åã€‚éªŒè¯æ•°æ®çš„æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œå¦‚æœæ²¡é—®é¢˜ï¼Œæ¥ä¸‹æ¥å°±å¯ä»¥æ„å»ºå’Œè®­ç»ƒæ¨¡å‹äº†ã€‚
```r
par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')
for (i in 1:25) { 
  img <- train_images[i, , ]
  img <- t(apply(img, 2, rev)) 
  image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',
        main = paste(class_names[train_labels[i] + 1]))
}
```
```{r fig3, echo=FALSE,out.width="60%", fig.cap ='è®­ç»ƒé›†çš„å‰25å¼ å›¾åƒå’Œç±»åã€‚',fig.align='center'} 

knitr::include_graphics('https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification_files/figure-html/unnamed-chunk-11-1.png')
```

#### æ„å»ºæ¨¡å‹

æ„å»ºç¥ç»ç½‘ç»œéœ€è¦é…ç½®æ¨¡å‹çš„å±‚ï¼Œç„¶åç¼–è¯‘æ¨¡å‹ã€‚

##### è®¾ç½®ç¥ç»å±‚

ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ„ä»¶æ˜¯å±‚(ç¥ç»å±‚)ã€‚å±‚ä»è¾“å…¥åˆ°å®ƒä»¬çš„æ•°æ®ä¸­æå–è¡¨å¾ã€‚å¹¶ä¸”ï¼Œå¸Œæœ›è¿™äº›è¡¨å¾å¯¹äºæ‰‹å¤´çš„é—®é¢˜æ›´æœ‰æ„ä¹‰ã€‚

å¤§éƒ¨åˆ†æ·±åº¦å­¦ä¹ æ˜¯å°†ç®€å•çš„å±‚é“¾æ¥åœ¨ä¸€èµ·æ„æˆçš„ï¼Œå…¶ä¸­å¤§å¤šæ•°å±‚ï¼ˆä¾‹å¦‚layer_denseï¼‰åœ¨è®­ç»ƒæ¨¡å‹æ—¶éƒ½æœ‰å¯ä»¥è®¾å®šå­¦ä¹ çš„å‚æ•°ã€‚

```r
model <- keras_model_sequential()
model %>%
  layer_flatten(input_shape = c(28, 28)) %>%
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dense(units = 10, activation = 'softmax')

```
è¯¥æ¨¡å‹çš„ç¬¬ä¸€å±‚layer_flattenå°†å›¾åƒæ ¼å¼ä»2ç»´æ•°ç»„(28x28åƒç´ )è½¬æ¢ä¸º28*28 = 784åƒç´ çš„1ç»´æ•°ç»„ã€‚å¯ä»¥æŠŠè¿™ä¸€å±‚æƒ³è±¡æˆå°†å›¾åƒä¸­çš„åƒç´ è¡Œæ‹†æ•£å¹¶æ’åˆ—èµ·æ¥ã€‚è¿™ä¸€å±‚æ²¡æœ‰å‚æ•°éœ€è¦å­¦ä¹ ï¼›å®ƒåªæ˜¯é‡æ–°æ ¼å¼åŒ–æ•°æ®ã€‚

åœ¨åƒç´ æ•°æ®è¢«å•ä¸€åŒ–åï¼Œæ¨¡å‹ç”±ä¸¤ä¸ªå¯†é›†å±‚ç»„æˆã€‚è¿™äº›æ˜¯ç´§å¯†ç›¸è¿æˆ–å®Œå…¨ç›¸è¿çš„ç¥ç»å±‚ã€‚ç¬¬ä¸€å¯†é›†å±‚æœ‰128ä¸ªèŠ‚ç‚¹(æˆ–ç¥ç»å…ƒ)ã€‚ç¬¬äºŒå±‚(ä¹Ÿæ˜¯æœ€åä¸€å±‚)æ˜¯ä¸€ä¸ªæœ‰10ä¸ªèŠ‚ç‚¹çš„softmaxå±‚â€”â€”å®ƒè¿”å›ä¸€ä¸ª10ä¸ªæ¦‚ç‡å¾—åˆ†çš„æ•°ç»„ï¼Œæ€»å’Œä¸º1ã€‚æ¯ä¸ªèŠ‚ç‚¹éƒ½åŒ…å«ä¸€ä¸ªåˆ†æ•°ï¼Œè¯¥åˆ†æ•°è¡¨ç¤ºå½“å‰å›¾åƒå±äº10ä¸ªæ•°å­—ç±»ä¹‹ä¸€çš„æ¦‚ç‡ã€‚

##### ç¼–è¯‘æ¨¡å‹
åœ¨æ¨¡å‹å‡†å¤‡å¥½è¿›è¡Œè®­ç»ƒä¹‹å‰ï¼Œè¿˜éœ€è¦è¿›è¡Œä¸€äº›è®¾ç½®ã€‚è¿™äº›æ˜¯åœ¨æ¨¡å‹çš„ç¼–è¯‘æ­¥éª¤ä¸­æ·»åŠ çš„:
- Losså‡½æ•°(Loss function): è¿™åº¦é‡äº†æ¨¡å‹åœ¨è®­ç»ƒæœŸé—´çš„ç²¾ç¡®åº¦ã€‚æˆ‘ä»¬å¸Œæœ›æœ€å°åŒ–è¿™ä¸ªå‡½æ•°ï¼Œä»¥â€œå¼•å¯¼â€æ¨¡å‹æœæ­£ç¡®çš„æ–¹å‘å‘å±•ã€‚
- ä¼˜åŒ–å™¨(Optimizer ): è¿™æ˜¯æ¨¡å‹å¦‚ä½•æ ¹æ®å®ƒçœ‹åˆ°çš„æ•°æ®å’Œå®ƒçš„æŸå¤±å‡½æ•°è¿›è¡Œæ›´æ–°çš„æ–¹å¼ã€‚
- åº¦é‡æ ‡å‡†(Metrics): ç”¨äºç›‘æ§åŸ¹è®­å’Œæµ‹è¯•æ­¥éª¤ã€‚ä¸‹é¢çš„ç¤ºä¾‹ä½¿ç”¨å‡†ç¡®åº¦ï¼Œå³æ­£ç¡®åˆ†ç±»çš„å›¾åƒçš„æ¯”ä¾‹ã€‚

```r
model %>% compile(
  optimizer = 'adam', 
  loss = 'sparse_categorical_crossentropy',
  metrics = c('accuracy')
)
```

##### è®­ç»ƒæ¨¡å‹

è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹éœ€è¦ä»¥ä¸‹æ­¥éª¤:

- å°†è®­ç»ƒæ•°æ®æä¾›ç»™æ¨¡å‹â€”â€”åœ¨æœ¬ä¾‹ä¸­æ˜¯train_imageså’Œtrain_labelsæ•°ç»„ã€‚
- è¿™ä¸ªæ¨¡å‹å­¦ä¼šäº†æŠŠå›¾åƒå’Œæ ‡ç­¾è”ç³»èµ·æ¥ã€‚
- æˆ‘ä»¬è¦æ±‚æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹â€”â€”åœ¨æœ¬ä¾‹ä¸­æ˜¯test_imagesæ•°ç»„ã€‚æˆ‘ä»¬éªŒè¯é¢„æµ‹æ˜¯å¦ä¸test_labelsæ•°ç»„ä¸­çš„æ ‡ç­¾ç›¸åŒ¹é…ã€‚

è¦å¼€å§‹è®­ç»ƒï¼Œè°ƒç”¨fitæ–¹æ³•-æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œâ€œæ‹Ÿåˆ(fit)â€:
```r
model %>% fit(train_images, train_labels, epochs = 5, verbose = 2)
### Train on 60000 samples
### Epoch 1/5
### 60000/60000 - 2s - loss: 0.4945 - accuracy: 0.8262
### Epoch 2/5
### 60000/60000 - 2s - loss: 0.3751 - accuracy: 0.8643
### Epoch 3/5
### 60000/60000 - 2s - loss: 0.3354 - accuracy: 0.8758
### Epoch 4/5
### 60000/60000 - 2s - loss: 0.3135 - accuracy: 0.8854
### Epoch 5/5
### 60000/60000 - 2s - loss: 0.2956 - accuracy: 0.8918
```
å½“æ¨¡å‹è¿è¡Œæ—¶ï¼ŒæŸå¤±å’Œç²¾åº¦æŒ‡æ ‡å°±ä¼šæ˜¾ç¤ºå‡ºæ¥ã€‚è¯¥æ¨¡å‹çš„ç²¾åº¦çº¦ä¸º0.8918(89.18%)ã€‚

##### è¯„ä¼°å‡†ç¡®æ€§

æ¥ä¸‹æ¥ï¼Œæ¯”è¾ƒæ¨¡å‹åœ¨æµ‹è¯•æ•°æ®é›†ä¸­çš„æ‰§è¡Œæƒ…å†µ:

```r
score <- model %>% evaluate(test_images, test_labels, verbose = 0)
score<-as.list(score)
cat('Test loss:', score$loss, "\n")
### Test loss: 0.3755946
cat('Test accuracy:', score$acc, "\n")
### Test accuracy: 0.8644
```
ç»“æœè¡¨æ˜ï¼Œæµ‹è¯•æ•°æ®é›†çš„ç²¾åº¦(86.44%)ç•¥ä½äºè®­ç»ƒæ•°æ®é›†çš„ç²¾åº¦(89.18%)ã€‚è®­ç»ƒç²¾åº¦å’Œæµ‹è¯•ç²¾åº¦ä¹‹é—´çš„å·®è·å°±æ˜¯**è¿‡æ‹Ÿåˆ**çš„ä¸€ä¸ªä¾‹å­ã€‚è¿‡æ‹Ÿåˆæ˜¯æŒ‡æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„è¡¨ç°æ¯”åœ¨è®­ç»ƒæ•°æ®ä¸Šå·®ã€‚

##### ä½œå‡ºé¢„æµ‹

ç»è¿‡è®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥é¢„æµ‹ä¸€äº›å›¾åƒã€‚
```r
predictions <- model %>% predict(test_images)
```
è¿™é‡Œï¼Œæ¨¡å‹é¢„æµ‹äº†æµ‹è¯•é›†ä¸­æ¯ä¸ªå›¾åƒçš„æ ‡ç­¾ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ç¬¬ä¸€ä¸ªé¢„æµ‹:
```r
predictions[1, ]
### [1] 5.465935e-06 1.288366e-07 3.570543e-06 1.659937e-08 2.075325e-05
### [6] 1.836076e-02 2.499909e-06 1.217376e-01 2.614871e-05 8.598431e-01
```
é¢„æµ‹ç»“æœæ˜¯ä¸€ä¸ªç”±10ä¸ªæ•°å­—ç»„æˆçš„æ•°ç»„ã€‚è¿™äº›æ•°å€¼æè¿°äº†æ¨¡å‹åˆ¤æ–­è¯¥å›¾åƒå¯¹åº”äº10ç§ä¸åŒçš„æœè£…ç±»å‹çš„â€œç½®ä¿¡åº¦â€ã€‚ æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å“ªä¸ªæ ‡ç­¾çš„ç½®ä¿¡åº¦æœ€é«˜ï¼š
```r
which.max(predictions[1, ])
### [1] 10
```
ç”±äºæ ‡ç­¾(Labels)æ˜¯åŸºäº0èµ·å§‹çš„ï¼Œç„¶è€ŒRè¯­è¨€çš„æ•°æ®é›†æ ‡ç­¾æ˜¯ç”±1èµ·å§‹çš„ï¼Œæ‰€ä»¥predictions[1, ]é¢„æµ‹çš„æ ‡ç­¾ä¸º9ã€‚æ¨¡å‹éå¸¸ç¡®ä¿¡è¿™å¼ ç…§ç‰‡æ˜¯ä¸€ä»¶è¸é´(Ankle boot)ã€‚æˆ‘ä»¬å¯ä»¥æ£€æŸ¥æµ‹è¯•æ ‡ç­¾ï¼Œçœ‹çœ‹é¢„æµ‹ç»“æœæ˜¯å¦æ­£ç¡®ã€‚
```r
test_labels[1]
```

æˆ–è€…ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥å¾—åˆ°ç±»é¢„æµ‹:
```r
class_pred <- model %>% predict_classes(test_images)
class_pred[1:20]
####  [1] 9 2 1 1 6 1 4 6 5 7 4 5 5 3 4 1 2 2 8 0
```

è®©æˆ‘ä»¬ç”¨å‡ å¹…å›¾æ¥è¯´æ˜æ¨¡å‹çš„é¢„æµ‹ã€‚æ­£ç¡®çš„é¢„æµ‹æ ‡ç­¾ä¸ºç»¿è‰²ï¼Œé”™è¯¯çš„é¢„æµ‹æ ‡ç­¾ä¸ºçº¢è‰²ã€‚
```r
par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')
for (i in 1:25) { 
  img <- test_images[i, , ]
  img <- t(apply(img, 2, rev)) 
  # subtract 1 as labels go from 0 to 9
  predicted_label <- which.max(predictions[i, ]) - 1
  true_label <- test_labels[i]
  if (predicted_label == true_label) {
    color <- '#008800' 
  } else {
    color <- '#bb0000'
  }
  image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',
        main = paste0(class_names[predicted_label + 1], " (",
                      class_names[true_label + 1], ")"),
        col.main = color)
}
```
```{r fig4, echo=FALSE,out.width="60%", fig.cap ='æ£€è§†éƒ¨åˆ†æ¨¡å‹é¢„æµ‹ç»“æœï¼Œæ­£ç¡®çš„é¢„æµ‹æ ‡ç­¾ä¸ºç»¿è‰²ï¼Œé”™è¯¯çš„é¢„æµ‹æ ‡ç­¾ä¸ºçº¢è‰²',fig.align='center'} 

knitr::include_graphics('https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification_files/figure-html/unnamed-chunk-21-1.png')
```

æœ€åï¼Œåˆ©ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹å•ä¸ªå›¾åƒè¿›è¡Œé¢„æµ‹ã€‚

```r
# ä»æµ‹è¯•æ•°æ®é›†ä¸­è·å–ä¸€ä¸ªå›¾åƒ
# æ³¨æ„ä¿æŒå´å²–æ•°æ®çš„ç»´åº¦ä¿¡æ¯ï¼Œè¿™æ˜¯æ¨¡å‹æ‰€æœŸæœ›çš„ï¼Œåˆ©ç”¨drop = FALSEå¸®åŠ©å…³æ‰è¿”å›å‘é‡
str(test_images)
# num [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...
img <- test_images[1, , , drop = FALSE]
dim(img)
# [1]  1 28 28
```
ç°åœ¨é¢„æµ‹å›¾åƒ:
```r
predictions <- model %>% predict(img)
predictions
###              [,1]         [,2]         [,3]         [,4]         [,5]
### [1,] 5.465944e-06 1.288367e-07 3.570535e-06 1.659934e-08 2.075324e-05
###            [,6]         [,7]      [,8]         [,9]    [,10]
### [1,] 0.01836077 2.499906e-06 0.1217377 2.614871e-05 0.859843

```
*predict*è¿”å›ä¸€ä¸ªåŒ…å«å­åˆ—è¡¨çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå­åˆ—è¡¨å¯¹åº”æ•°æ®æ‰¹ä¸­çš„æŸå›¾åƒã€‚åœ¨è¿™é‡Œçš„æ‰¹å¤„ç†ä¸­è·å–æˆ‘ä»¬çš„(å”¯ä¸€çš„)å›¾åƒçš„é¢„æµ‹:

```r
# å› ä¸ºæ ‡ç­¾æ˜¯åŸºäº0çš„ï¼Œæ‰€ä»¥å‡å»1
prediction <- predictions[1, ] - 1
which.max(prediction)
# [1] 10

# æˆ–è€…ï¼Œç›´æ¥å†æ¬¡è·å–ç±»é¢„æµ‹:
class_pred <- model %>% predict_classes(img)
class_pred
# [1] 9
```

[Fashion MNIST]:https://github.com/zalandoresearch/fashion-mnist
[MNIST]: http://yann.lecun.com/exdb/mnist/

### å›å½’

åœ¨å›å½’é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯é¢„æµ‹ä¸€ä¸ªè¿ç»­å€¼çš„è¾“å‡ºï¼Œå¦‚ä»·æ ¼æˆ–æ¦‚ç‡ã€‚ä¸æ­¤å½¢æˆå¯¹æ¯”çš„æ˜¯åˆ†ç±»é—®é¢˜ï¼Œåœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯é¢„æµ‹ä¸€ä¸ªç¦»æ•£çš„æ ‡ç­¾(ä¾‹å¦‚ï¼Œä¸€å¼ å›¾ç‰‡ä¸­åŒ…å«ä¸€ä¸ªè‹¹æœæˆ–æ©˜å­)ã€‚

æœ¬ç¬”è®°å»ºç«‹äº†ä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹20ä¸–çºª70å¹´ä»£ä¸­æœŸæ³¢å£«é¡¿éƒŠåŒºæˆ¿å±‹çš„ä¸­é—´ä»·æ ¼ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä¸ºæ¨¡å‹æä¾›ä¸€äº›å…³äºéƒŠåŒºçš„æ•°æ®ç‚¹ï¼Œå¦‚çŠ¯ç½ªç‡å’Œå½“åœ°æˆ¿äº§ç¨ç‡ã€‚

#### æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†

[æ³¢å£«é¡¿æˆ¿ä»·]æ•°æ®å¯ä»¥ç›´æ¥ä»kerasè·å¾—ã€‚

```r
library(keras)
library(tfdatasets)

boston_housing <- dataset_boston_housing()

c(train_data, train_labels) %<-% boston_housing$train
c(test_data, test_labels) %<-% boston_housing$test

```

##### å®ä¾‹å’Œç‰¹ç‚¹

è¿™ä¸ªæ•°æ®é›†æ¯”æˆ‘ä»¬ç›®å‰ä½¿ç”¨çš„å…¶ä»–æ•°æ®é›†è¦å°å¾—å¤š:å®ƒæ€»å…±æœ‰506ä¸ªä¾‹å­ï¼Œåˆ†åˆ«åœ¨404ä¸ªè®­ç»ƒç¤ºä¾‹å’Œ102ä¸ªæµ‹è¯•ç¤ºä¾‹ä¹‹é—´åˆ’åˆ†:

```r
paste0("Training entries: ", length(train_data), ", labels: ", length(train_labels))
### [1] "Training entries: 5252, labels: 404"
```

æ•°æ®é›†åŒ…å«13ä¸ªä¸åŒçš„ç‰¹å¾ï¼š

- äººå‡çŠ¯ç½ªç‡ã€‚

- è¶…è¿‡25,000å¹³æ–¹è‹±å°ºçš„ä½å®…ç”¨åœ°æ¯”ä¾‹ã€‚

- æ¯ä¸ªåŸé•‡éé›¶å”®ä¸šåŠ¡è‹±äº©çš„æ¯”ä¾‹ã€‚

- æŸ¥å°”æ–¯æ²³è™šæ‹Ÿå˜é‡ï¼ˆå¦‚æœæŸç¼šæ²³æµï¼Œåˆ™ä¸º1ï¼›å¦åˆ™ä¸º0ï¼‰ã€‚

- ä¸€æ°§åŒ–æ°®æµ“åº¦ï¼ˆåƒä¸‡åˆ†ä¹‹ä¸€ï¼‰ã€‚

- æ¯ä¸ªä½å®…çš„å¹³å‡æˆ¿é—´æ•°ã€‚

- 1940å¹´ä¹‹å‰å»ºé€ çš„è‡ªæœ‰ä½æˆ¿çš„æ¯”ä¾‹ã€‚

- åˆ°äº”ä¸ªæ³¢å£«é¡¿å°±ä¸šä¸­å¿ƒçš„åŠ æƒè·ç¦»ã€‚

- å¾„å‘å…¬è·¯çš„å¯è¾¾æ€§æŒ‡æ•°ã€‚

- æ¯10,000ç¾å…ƒçš„å…¨å€¼è´¢äº§ç¨ç‡ã€‚

- å„é•‡çš„å¸ˆç”Ÿæ¯”ä¾‹ã€‚

- 1000 *ï¼ˆBk-0.63ï¼‰** 2å…¶ä¸­Bkæ˜¯æŒ‰åŸé•‡åˆ’åˆ†çš„é»‘äººæ¯”ä¾‹ã€‚

- äººå£ä¸­å¤„äºè¾ƒä½åœ°ä½çš„ç™¾åˆ†æ¯”ã€‚

è¾“å…¥æ•°æ®çš„æ¯ä¸ªç‰¹æ€§äº’ç›¸ä½¿ç”¨ä¸åŒçš„æ ‡åº¦å­˜å‚¨ã€‚æœ‰äº›ç‰¹å¾ç”¨0åˆ°1ä¹‹é—´çš„æ¯”ä¾‹è¡¨ç¤ºï¼Œæœ‰äº›ç‰¹å¾ç”¨1åˆ°12ä¹‹é—´çš„èŒƒå›´è¡¨ç¤ºï¼Œæœ‰äº›ç‰¹å¾ç”¨0åˆ°100ä¹‹é—´çš„èŒƒå›´è¡¨ç¤ºï¼Œä»¥æ­¤ç±»æ¨ã€‚
```r
# æ˜¾ç¤ºæ ·å“ç‰¹å¾ï¼Œæ³¨æ„ä¸åŒçš„æ ‡åº¦
train_data[1, ] 
###  [1]   1.23247   0.00000   8.14000   0.00000   0.53800   6.14200  91.70000
###  [8]   3.97690   4.00000 307.00000  21.00000 396.90000  18.72000
```
ä¸ºæ•°æ®æ·»åŠ åˆ—åï¼Œä»¥ä¾¿æ›´å¥½åœ°æ£€æŸ¥æ•°æ®ã€‚
```r
library(dplyr)

column_names <- c('CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 
                  'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT')

train_df <- train_data %>% 
  as_tibble(.name_repair = "minimal") %>% 
  setNames(column_names) %>% 
  mutate(label = train_labels)

test_df <- test_data %>% 
  as_tibble(.name_repair = "minimal") %>% 
  setNames(column_names) %>% 
  mutate(label = test_labels)
```

##### æ ‡ç­¾

è¿™äº›æ ‡ç­¾æ˜¯çš„æˆ¿ä»·å•ä½ï¼šåƒç¾å…ƒã€‚
```r
train_labels[1:10]
###  [1] 15.2 42.3 50.0 21.1 17.7 18.5 11.3 15.6 15.6 14.4
```

#### æ ‡å‡†åŒ–ç‰¹å¾æ•°æ®

å»ºè®®å¯¹ä½¿ç”¨ä¸åŒæ ‡åº¦å’ŒèŒƒå›´çš„ç‰¹å¾æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ã€‚è™½ç„¶æ¨¡å‹åœ¨æ²¡æœ‰ç‰¹å¾å½’ä¸€åŒ–çš„æƒ…å†µä¸‹å¯èƒ½ä¹Ÿä¼šæ”¶æ•›ï¼Œä½†è¿™ä¼šä½¿è®­ç»ƒå˜å¾—æ›´åŠ å›°éš¾ï¼Œå¹¶ä¸”ä¼šä½¿å¾—åˆ°çš„æ¨¡å‹æ›´åŠ ä¾èµ–äºè¾“å…¥ä¸­ä½¿ç”¨çš„å•å…ƒçš„é€‰æ‹©ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨åœ¨*tfdatasets*åŒ…ä¸­å®ç°çš„*feature_spec*æ¥å£è¿›è¡Œæ ‡å‡†åŒ–ã€‚*feature_columns*æ¥å£å…è®¸å¯¹è¡¨æ•°æ®è¿›è¡Œå…¶ä»–å¸¸è§çš„é¢„å¤„ç†æ“ä½œã€‚
```r
library(tfdatasets)

spec <- feature_spec(train_df, label ~ . ) %>% 
  step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>% 
  fit()

spec
### â”€â”€ Feature Spec â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
### A feature_spec with 13 steps.
### Fitted: TRUE 
### â”€â”€ Steps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 
### The feature_spec has 1 dense features.
### StepNumericColumn: CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT 
### â”€â”€ Dense features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

ä½¿ç”¨*tfdatasets*åˆ›å»ºçš„*spec*å¯ä»¥ä¸*layer_dense_features*ä¸€èµ·ä½¿ç”¨ï¼Œç›´æ¥åœ¨TensorFlowå›¾ä¸­æ‰§è¡Œé¢„å¤„ç†ã€‚

æˆ‘ä»¬å¯ä»¥çœ‹çœ‹è¿™ä¸ª*spec*åˆ›å»ºçš„å¯†é›†å±‚çš„è¾“å‡º:

```r
layer <- layer_dense_features(
  feature_columns = dense_features(spec), 
  dtype = tf$float32
)
layer(train_df)
```
æ³¨æ„ï¼Œè¿™å°†è¿”å›ä¸€ä¸ªæ¢ç®—åå€¼å¾—çš„æ•°æ®çŸ©é˜µ(åœ¨æœ¬ä¾‹ä¸­è¯´ï¼Œå®ƒæ˜¯ä¸€ä¸ªäºŒç»´çš„Tensor)ã€‚

##### åˆ›å»ºæ¨¡å‹

æ¥ä¸‹æ¥æˆ‘ä»¬æ„å»ºæ¨¡å‹ã€‚è¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨Keras functional APIâ€”â€”è¿™æ˜¯ä½¿ç”¨feature_spec APIæ—¶æ¨èçš„æ–¹å¼ã€‚æ³¨æ„ï¼Œæˆ‘ä»¬åªéœ€è¦ä»æˆ‘ä»¬åˆšåˆšåˆ›å»ºçš„*spec*ä¸­ä¼ é€’*dense_features*ã€‚

```r
input <- layer_input_from_dataset(train_df %>% select(-label))

output <- input %>% 
  layer_dense_features(dense_features(spec)) %>% 
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 1) 

model <- keras_model(input, output)

summary(model)
```

ç„¶åæˆ‘ä»¬ç”¨ä»¥ä¸‹æ–¹æ³•ç¼–è¯‘æ¨¡å‹:
```r
model %>% 
  compile(
    loss = "mse",
    optimizer = optimizer_rmsprop(),
    metrics = list("mean_absolute_error")
  )
```
æˆ‘ä»¬å°†æŠŠæ¨¡å‹æ„å»ºä»£ç åŒ…è£…æˆä¸€ä¸ªå‡½æ•°ï¼Œä»¥ä¾¿èƒ½å¤Ÿåœ¨ä¸åŒçš„å®éªŒä¸­é‡ç”¨å®ƒã€‚è¯·è®°ä½ï¼ŒKeras *fit*ä¼šå°±åœ°ä¿®æ”¹æ¨¡å‹ã€‚
```r
build_model <- function() {
  input <- layer_input_from_dataset(train_df %>% select(-label))
  
  output <- input %>% 
    layer_dense_features(dense_features(spec)) %>% 
    layer_dense(units = 64, activation = "relu") %>%
    layer_dense(units = 64, activation = "relu") %>%
    layer_dense(units = 1) 
  
  model <- keras_model(input, output)
  
  model %>% 
    compile(
      loss = "mse",
      optimizer = optimizer_rmsprop(),
      metrics = list("mean_absolute_error")
    )
  
  model
}
```

##### è®­ç»ƒæ¨¡å‹

å¯¹æ¨¡å‹è¿›è¡Œäº†500ä¸ªepochsè®­ç»ƒï¼Œå¹¶åœ¨keras_training_historyå¯¹è±¡ä¸­è®°å½•äº†è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®æ€§ã€‚ æˆ‘ä»¬è¿˜å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰å›è°ƒæ–¹æ³•ï¼Œå°†æ¯ä¸ªepochsçš„é»˜è®¤è®­ç»ƒè¾“å‡ºæ›¿æ¢ä¸ºä¸€ä¸ªç‚¹ã€‚
```r
# é€šè¿‡æ¯å®Œä¸€ä¸ªepochsæ‰“å°ä¸€ä¸ªç‚¹æ˜¾ç¤ºæ¥è®­ç»ƒè¿›åº¦ã€‚
print_dot_callback <- callback_lambda(
  on_epoch_end = function(epoch, logs) {
    if (epoch %% 80 == 0) cat("\n")
    cat(".")
  }
)    

model1 <- build_model()

history1 <- model1 %>% fit(
  x = train_df %>% select(-label),
  y = train_df$label,
  epochs = 500,
  validation_split = 0.2,
  verbose = 0,
  callbacks = list(print_dot_callback)
)
```
ç°åœ¨ï¼Œæˆ‘ä»¬ä½¿ç”¨å­˜å‚¨åœ¨*history*å˜é‡ä¸­çš„æŒ‡æ ‡æ¥å¯è§†åŒ–æ¨¡å‹çš„è®­ç»ƒè¿›åº¦ã€‚æˆ‘ä»¬æƒ³ç”¨è¿™äº›æ•°æ®æ¥ç¡®å®šåœ¨æ¨¡å‹åœæ­¢è¿›æ­¥ä¹‹å‰éœ€è¦è®­ç»ƒå¤šä¹…ã€‚

```r
library(ggplot2)
plot(history1)
```
```{r fig5, echo=FALSE,out.width="60%", fig.cap ='è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´',fig.align='center'} 

knitr::include_graphics('https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_regression_files/figure-html/unnamed-chunk-13-1.png')
```
è¿™å¼ å›¾è¡¨æ˜¾ç¤ºï¼Œåœ¨å¤§çº¦200ä¸ªepochsä¹‹åï¼Œæ¨¡å‹å‡ ä¹æ²¡æœ‰ä»€ä¹ˆæ”¹è¿›ã€‚è®©æˆ‘ä»¬æ›´æ–°*fit*æ–¹æ³•ï¼Œå½“éªŒè¯åˆ†æ•°æ²¡æœ‰æé«˜æ—¶è‡ªåŠ¨åœæ­¢è®­ç»ƒã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªå›è°ƒæ¥æµ‹è¯•æ¯ä¸ªepochçš„è®­ç»ƒæ¡ä»¶ã€‚å¦‚æœç»è¿‡äº†ä¸€å®šæ•°é‡çš„epochï¼Œæ²¡æœ‰æ˜¾ç¤ºå‡ºæ”¹è¿›ï¼Œå®ƒä¼šè‡ªåŠ¨åœæ­¢è®­ç»ƒã€‚
```r
# patience parameteræ˜¯è¦æ£€æŸ¥æ”¹è¿›çš„æ—¶æœŸæ•°ã€‚
early_stop <- callback_early_stopping(monitor = "val_loss", patience = 20)

model2 <- build_model()

history2 <- model2 %>% fit(
  x = train_df %>% select(-label),
  y = train_df$label,
  epochs = 500,
  validation_split = 0.2,
  verbose = 0,
  callbacks = list(early_stop)
)

plot(history2)
#Error in data.frame(epoch = seq_len(x$params$epochs), value = unlist(values),  :
#  arguments imply differing number of rows: 500, 368, 2000

str(history2)
List of 2
# $ params :List of 3
#  ..$ verbose: int 0
#  ..$ epochs : int 500
#  ..$ steps  : int 11
# $ metrics:List of 4
#  ..$ loss                   : num [1:92] 494 398 309 226 157 ...
#  ..$ mean_absolute_error    : num [1:92] 20.4 17.9 15.4 12.7 10.3 ...
#  ..$ val_loss               : num [1:92] 504 410 319 227 169 ...
#  ..$ val_mean_absolute_error: num [1:92] 20.5 18.2 15.5 12.5 10.3 ...
# - attr(*, "class")= chr "keras_training_history"

history2$metrics$loss<-c(history2$metrics$loss,rep(NA,history2$params$epochs-length(history2$metrics$loss)))
history2$metrics$mean_absolute_error<-c(history2$metrics$mean_absolute_error,rep(NA,history2$params$epochs-length(history2$metrics$mean_absolute_error)))
history2$metrics$val_loss<-c(history2$metrics$val_loss,rep(NA,history2$params$epochs-length(history2$metrics$val_loss)))
history2$metrics$val_mean_absolute_error<-c(history2$metrics$val_mean_absolute_error,rep(NA,history2$params$epochs-length(history2$metrics$val_mean_absolute_error)))

plot(history2)
```
```{r fig6, echo=FALSE,out.width="60%", fig.cap ='è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´2',fig.align='center'} 

knitr::include_graphics('https://s3.ax1x.com/2020/12/25/rWN4UK.png')
```
è¯¥å›¾æ˜¾ç¤ºå¹³å‡è¯¯å·®çº¦ä¸º2500ç¾å…ƒã€‚ è¿™ä¸ªå¥½å—ï¼Ÿ å¥½å§ï¼Œå½“æŸäº›æ ‡ç­¾ä»…ä¸º15,000ç¾å…ƒæ—¶ï¼Œ2,500ç¾å…ƒå¹¶ä¸æ˜¯å¾®ä¸è¶³é“çš„æ•°é¢ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°å¦‚ä½•ï¼š

```r
c(loss, mae) %<-% (model1 %>% evaluate(test_df %>% select(-label), test_df$label, verbose = 0))
paste0("Mean absolute error on test set: $", sprintf("%.2f", mae * 1000))
# [1] "Mean absolute error on test set: $2903.54"

c(loss2, mae2) %<-% (model2 %>% evaluate(test_df %>% select(-label), test_df$label, verbose = 0))
paste0("Mean absolute error on test set: $", sprintf("%.2f", mae2 * 1000))
# [1] "Mean absolute error on test set: $3034.21"
```

##### ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹

æœ€åï¼Œä½¿ç”¨æµ‹è¯•é›†ä¸­çš„æ•°æ®é¢„æµ‹ä¸€äº›æˆ¿ä»·ï¼š

```r
model<-model2
test_predictions <- model2 %>% predict(test_df %>% select(-label))
test_predictions[ , 1]
#  [1]  7.355123 17.675547 19.973572 32.076920 23.902725 19.619333 26.324997
#  [8] 21.288185 18.688896 21.509230 17.615231 16.178177 15.070681 39.809803
# [15] 20.088022 19.298931 25.012741 21.137566 17.962463 34.908684 10.398927
# [22] 14.056004 19.420004 13.601798 19.115681 24.314400 29.992420 29.077190
# [29]  9.517317 20.587708 18.875362 14.579519 31.711769 23.667265 17.235331
# [36]  7.131071 14.524129 17.223494 18.043385 24.907063 30.337440 26.690973
# [43] 12.751408 38.409725 28.244289 23.861389 24.783478 15.663984 22.516479
# [50] 20.941717 32.775738 19.605915  9.694613 13.944555 33.987289 26.646553
# [57] 11.730441 46.070683 32.869167 23.082375 24.691891 16.289280 15.114546
# [64] 18.146664 21.945438 21.380447 13.035687 21.360455 12.413694  5.442961
# [71] 34.066624 29.388529 24.445929 12.748474 23.918005 18.901218 19.777264
# [78] 21.921507 33.413986  9.202299 19.752489 36.857082 15.715253 12.539826
# [85] 16.558025 18.447201 20.974888 18.670275 21.062746 29.102020 19.141819
# [92] 18.646065 24.691332 41.360500 32.999287 18.146885 34.936665 51.217838
# [99] 25.158466 45.784126 31.594339 19.733921
#
```

##### ç»“è®º

æœ¬ç¬”è®°æœ¬ä»‹ç»äº†ä¸€äº›å¤„ç†å›å½’é—®é¢˜çš„æŠ€æœ¯ã€‚

- å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æ˜¯ç”¨äºå›å½’é—®é¢˜ï¼ˆä¸åŒäºåˆ†ç±»é—®é¢˜ï¼‰çš„å¸¸è§æŸå¤±å‡½æ•°ã€‚

- åŒæ ·ï¼Œç”¨äºå›å½’çš„è¯„ä¼°æŒ‡æ ‡ä¹Ÿä¸åŒäºåˆ†ç±»ã€‚ å¸¸è§çš„å›å½’æŒ‡æ ‡æ˜¯å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ã€‚

- å½“è¾“å…¥æ•°æ®è¦ç´ çš„å€¼å…·æœ‰ä¸åŒèŒƒå›´æ—¶ï¼Œæ¯ä¸ªè¦ç´ éƒ½åº”ç‹¬ç«‹ç¼©æ”¾ã€‚

- å¦‚æœè®­ç»ƒæ•°æ®ä¸å¤šï¼Œåˆ™æœ€å¥½é€‰æ‹©ä¸€ä¸ªéšè—å±‚å¾ˆå°‘çš„å°å‹ç½‘ç»œï¼Œä»¥å…è¿‡åº¦æ‹Ÿåˆã€‚

- æå‰åœæ­¢æ˜¯é˜²æ­¢è¿‡åº¦æ‹Ÿåˆçš„æœ‰ç”¨æŠ€æœ¯ã€‚

[æ³¢å£«é¡¿æˆ¿ä»·]: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html

### æ–‡å­—åˆ†ç±»

*æ³¨æ„ï¼šæœ¬æ•™ç¨‹è¦æ±‚TensorFlowç‰ˆæœ¬> = 2.1*

æœ¬æ•™ç¨‹ä½¿ç”¨è¯„è®ºæ–‡æœ¬å°†ç”µå½±è¯„è®ºåˆ†ä¸ºæ­£é¢è¯„è®ºæˆ–è´Ÿé¢è¯„è®ºã€‚è¿™æ˜¯äºŒè¿›åˆ¶ï¼ˆæˆ–ä¸¤ç±»ï¼‰åˆ†ç±»çš„ç¤ºä¾‹ï¼Œå®ƒæ˜¯ä¸€ç§é‡è¦ä¸”å¹¿æ³›é€‚ç”¨çš„æœºå™¨å­¦ä¹ é—®é¢˜ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨[IMDB]æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«æ¥è‡ª[Internet]ç”µå½±æ•°æ®åº“çš„50,000ä¸ªç”µå½±è¯„è®ºçš„æ–‡æœ¬ã€‚è¿™äº›å†…å®¹åˆ†ä¸º25,000æ¡ç”¨äºåŸ¹è®­çš„è¯„è®ºå’Œ25,000æ¡ç”¨äºæµ‹è¯•çš„è¯„è®ºã€‚è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ˜¯å¹³è¡¡çš„ï¼Œè¿™æ„å‘³ç€å®ƒä»¬åŒ…å«ç›¸åŒæ•°é‡çš„æ­£é¢å’Œè´Ÿé¢è¯„è®ºã€‚

å…ˆå¯åŠ¨å¹¶åŠ è½½Kerasä»¥åŠå…¶ä»–ä¸€äº›å¿…éœ€çš„åº“ã€‚

```r
library(keras)
library(dplyr)
library(ggplot2)
library(purrr)
```
#### ä¸‹è½½ç”µå½±è¯„è®ºæ•°æ®é›†

æˆ‘ä»¬å°†ä½¿ç”¨ç”±Bo Pangå’ŒLillian Leeåˆ›å»ºçš„ç”µå½±è¯„è®ºæ•°æ®é›†ã€‚åœ¨ä½œè€…çš„å…è®¸ä¸‹ï¼ŒNLTKé‡æ–°å‘å¸ƒäº†è¯¥æ•°æ®é›†ã€‚

æ•°æ®é›†å¯åœ¨[æ­¤å¤„](https://www.kaggle.com/nltkdata/movie-review#movie_review.csv)æ‰¾åˆ° ï¼Œå¹¶å¯ä»Kaggle UIæˆ–ä½¿ç”¨[pins](https://github.com/rstudio/pins)åŒ…ä¸‹è½½ã€‚

å¦‚æœè¦ä½¿ç”¨[pins](https://github.com/rstudio/pins) ï¼Œè¯·æŒ‰ç…§è¿™é‡Œçš„[æ•™ç¨‹](https://rstudio.github.io/pins/articles/boards-kaggle.html)æ³¨å†ŒKaggleç”»æ¿ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥è¿è¡Œï¼š

```r
library(pins)
board_register("kaggle", token = "/home/wangxh/Soft/kaggle.json")
paths <- pins::pin_get("nltkdata/movie-review", "kaggle")
# æˆ‘ä»¬åªéœ€è¦ movie_review.csv æ–‡ä»¶
path <- paths[1]
```
ç°åœ¨ï¼Œä½¿ç”¨åŒ…ä¸­çš„*read_csv*å‡½æ•°å°†å…¶è¯»å–åˆ°Rä¸­readrã€‚
```r
df <- readr::read_csv(path)
head(df)
### # A tibble: 6 x 6
###   fold_id cv_tag html_id sent_id text                                 tag  
###     <dbl> <chr>    <dbl>   <dbl> <chr>                                <chr>
### 1       0 cv000    29590       0 films adapted from comic books haveâ€¦ pos  
### 2       0 cv000    29590       1 for starters , it was created by alâ€¦ pos  
### 3       0 cv000    29590       2 to say moore and campbell thoroughlâ€¦ pos  
### 4       0 cv000    29590       3 "the book ( or \" graphic novel , \â€¦ pos  
### 5       0 cv000    29590       4 in other words , don't dismiss thisâ€¦ pos  
### 6       0 cv000    29590       5 if you can get past the whole comicâ€¦ pos
```
#### æ£€è§†æ•°æ®

è®©æˆ‘ä»¬èŠ±ä¸€ç‚¹æ—¶é—´æ¥ç†è§£æ•°æ®çš„æ ¼å¼ã€‚æ•°æ®é›†æœ‰6ä¸‡è¡Œï¼Œæ¯è¡Œä»£è¡¨ç”µå½±è¯„è®ºã€‚è¯¥textåˆ—å…·æœ‰å®é™…è¯„è®ºï¼Œå¹¶ä¸”tag ä»£è¡¨å‘æˆ‘ä»¬æ˜¾ç¤ºäº†è¯¥è¯„è®ºçš„åˆ†ç±»æƒ…ç»ªã€‚æ•°æ®é›†é‡Œå¤§çº¦ä¸€åŠçš„è¯„è®ºæ˜¯è´Ÿé¢çš„(neg)ï¼Œå¦ä¸€åŠæ˜¯æ­£é¢çš„(pos)ã€‚

```r
df$text[1]
### [1] "films adapted from comic books have had plenty of success , whether they're about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there's never really been a comic book like from hell before ."

df %>% count(tag)
# # A tibble: 2 x 2
#   tag       n
#   <chr> <int>
# 1 neg   31783
# 2 pos   32937

str(df)
# tibble [64,720 Ã— 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
 # $ fold_id: num [1:64720] 0 0 0 0 0 0 0 0 0 0 ...
 # $ cv_tag : chr [1:64720] "cv000" "cv000" "cv000" "cv000" ...
 # $ html_id: num [1:64720] 29590 29590 29590 29590 29590 ...
 # $ sent_id: num [1:64720] 0 1 2 3 4 5 6 7 8 9 ...
 # $ text   : chr [1:64720] "films adapted from comic books have had plenty of # success , whether they're about superheroes ( batman , superm"| __truncated__ # "for starters , it was created by alan moore ( and eddie campbell ) , who # brought the medium to a whole new leve"| __truncated__ "to say moore and # campbell thoroughly researched the subject of jack the ripper would be like # saying michael jac"| __truncated__ "the book ( or \" graphic novel , \" if you # will ) is over 500 pages long and includes nearly 30 more that consi"| # __truncated__ ...
 # $ tag    : chr [1:64720] "pos" "pos" "pos" "pos" ...
 # - attr(*, "spec")=
 #  .. cols(
 #  ..   fold_id = col_double(),
 #  ..   cv_tag = col_character(),
 #  ..   html_id = col_double(),
 #  ..   sent_id = col_double(),
 #  ..   text = col_character(),
 #  ..   tag = col_character()
 #  .. )

```

è®©æˆ‘ä»¬å°†æ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸¤éƒ¨åˆ†ï¼š

```r
training_id <- sample.int(nrow(df), size = nrow(df)*0.8)
training <- df[training_id,]
testing <- df[-training_id,]
```
äº†è§£æ¯ä¸ªè¯„è®ºä¸­å•è¯æ•°é‡çš„å¤§è‡´åˆ†å¸ƒæƒ…å†µä¹Ÿå¾ˆæœ‰ç”¨ã€‚
```r
df$text %>% 
  strsplit(" ") %>% 
  sapply(length) %>% 
  summary()
###    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
###    1.00   14.00   21.00   23.06   30.00  179.00
```

#### å‡†å¤‡æ•°æ®

è¯„è®ºï¼ˆæ–‡æœ¬ï¼‰åœ¨è¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¹‹å‰å¿…é¡»å…ˆè½¬æ¢ä¸ºå¼ é‡(Tensor)ã€‚ é¦–å…ˆï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå­—å…¸å’Œä¸€ä¸ªæ•´æ•°ä»£è¡¨æ¯10,000ä¸ªæœ€å¸¸ç”¨çš„è¯ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¯ä¸ªè¯„è®ºéƒ½å°†ç”±æ•´æ•°åºåˆ—è¡¨ç¤ºã€‚

ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼è¡¨ç¤ºè¯„è®ºï¼š

- ç¬¬ä¸€ç§æ˜¯å¯¹æ•°ç»„è¿›è¡Œä¸€æ¬¡çƒ­ç¼–ç ï¼Œä»¥å°†å…¶è½¬æ¢ä¸ºç”±0å’Œ1ç»„æˆçš„å‘é‡ã€‚ä¾‹å¦‚ï¼Œåºåˆ—[3ï¼Œ5]å°†å˜æ¢ä¸ºä¸€ä¸ª10,000ç»´å‘é‡ï¼Œé™¤äº†ç´¢å¼•3å’Œ5éƒ½æ˜¯1ä¹‹å¤–ï¼Œå®ƒä»¬å…¨ä¸ºé›¶ã€‚ç„¶åï¼Œå°†å…¶è®¾ç½®ä¸ºæˆ‘ä»¬ç½‘ç»œä¸­çš„ç¬¬ä¸€å±‚ï¼Œå¯†é›†å±‚(dense layer )ï¼Œå³å¯ä»¥å¤„ç†æµ®ç‚¹çŸ¢é‡æ•°æ®çš„ä¸€å±‚ã€‚ä½†æ˜¯ï¼Œæ­¤æ–¹æ³•éœ€è¦å ç”¨å¤§é‡å†…å­˜ï¼Œè€Œä¸”éœ€è¦ä½¿ç”¨*num_words * num_reviews*å¤§å°çŸ©é˜µã€‚

- ç¬¬äºŒç§æ˜¯å¯ä»¥å¡«å……æ•°ç»„ï¼Œä½¿å®ƒä»¬éƒ½å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼Œç„¶ååˆ›å»ºç»´åº¦ä¸ºnum_examples * max_lengthçš„å¼ é‡ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨èƒ½å¤Ÿå¤„ç†æ­¤ç»´åº¦çš„åµŒå…¥å±‚(embedding layer )ä½œä¸ºç½‘ç»œä¸­çš„ç¬¬ä¸€å±‚ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç¬¬äºŒç§æ–¹æ³•ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®šä¹‰æ–‡æœ¬å‘é‡åŒ–å±‚(Text Vectorization layer)ï¼Œå®ƒå°†è´Ÿè´£è·å–å­—ç¬¦ä¸²è¾“å…¥å¹¶å°†å…¶è½¬æ¢ä¸ºå¼ é‡(Tensor)ã€‚

```r
num_words <- 10000
max_length <- 50
text_vectorization <- layer_text_vectorization(
  max_tokens = num_words, 
  output_sequence_length = max_length, 
)
```
ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦*adapt*æ–‡æœ¬å‘é‡åŒ–å±‚ã€‚adaptå±‚å°†äº†è§£æ•°æ®é›†ä¸­çš„å»é‡å¤è¯æ±‡ï¼Œå¹¶ä¸ºæ¯ä¸ªå•è¯åˆ†é…ä¸€ä¸ªæ•´æ•°å€¼ã€‚

```r
text_vectorization %>% 
  adapt(df$text)
```

æ‚¨å¯ä»¥çœ‹åˆ°æ–‡æœ¬çŸ¢é‡åŒ–å±‚å¦‚ä½•è½¬æ¢å…¶è¾“å…¥æ•°æ®çš„ï¼š

```r
text_vectorization(matrix(df$text[1], ncol = 1))
### tf.Tensor(
### [[  68 2835   30  359 1662   33   91 1056    5  632  631  321   41 7803
###    709 4865 1767   48 7600 1337  398 5161   48    2    1 1808 1800  148
###     17  140  109   90   69    3  359  408   40   30  503  142    0    0
###      0    0    0    0    0    0    0    0]], shape=(1, 50), dtype=int64)
```
#### å»ºç«‹æ¨¡å‹

ç¥ç»ç½‘ç»œæ˜¯é€šè¿‡å †å å±‚åˆ›å»ºçš„-è¿™éœ€è¦ä¸¤ä¸ªä¸»è¦çš„ä½“ç³»ç»“æ„å†³ç­–ï¼š

- åœ¨æ¨¡å‹ä¸­ä½¿ç”¨å¤šå°‘å±‚ï¼Ÿ

- æ¯å±‚ä½¿ç”¨å¤šå°‘ä¸ªéšè—å•å…ƒï¼Ÿ

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œè¾“å…¥æ•°æ®ç”±å•è¯ç´¢å¼•æ•°ç»„ç»„æˆã€‚è¦é¢„æµ‹çš„æ ‡ç­¾ä¸º0æˆ–1(Negæˆ–è€…Pos)ã€‚è®©æˆ‘ä»¬ä¸ºè¿™ä¸ªé—®é¢˜å»ºç«‹ä¸€ä¸ªæ¨¡å‹ï¼š

```r
input <- layer_input(shape = c(1), dtype = "string")

output <- input %>% 
  text_vectorization() %>% 
  layer_embedding(input_dim = num_words + 1, output_dim = 16) %>%
  layer_global_average_pooling_1d() %>%
  layer_dense(units = 16, activation = "relu") %>%
  layer_dropout(0.5) %>% 
  layer_dense(units = 1, activation = "sigmoid")

model <- keras_model(input, output)

```
ä¾æ¬¡å †å å„å±‚ä»¥æ„å»ºåˆ†ç±»å™¨ï¼š

- ç¬¬ä¸€å±‚æ˜¯åµŒå…¥å±‚(embedding layer)ã€‚è¯¥å±‚è¾“å…¥æ•´æ•°ç¼–ç çš„è¯æ±‡è¡¨ï¼Œå¹¶ä¸ºæ¯ä¸ªå•è¯ç´¢å¼•æŸ¥æ‰¾åµŒå…¥å‘é‡ã€‚è¿™äº›å‘é‡å°†ç”¨äºè®­ç»ƒæ¨¡å‹ã€‚åµŒå…¥å‘é‡å°†æ·»åŠ åˆ°è¾“å‡ºæ•°ç»„ï¼Œè¾“å‡ºç»“æœçš„ç»´åº¦ä¸ºï¼šï¼ˆbatch, sequence, embeddingï¼‰ã€‚

- æ¥ä¸‹æ¥ï¼Œglobal_average_pooling_1då±‚ å±‚é€šè¿‡å¯¹åºåˆ—ç»´åº¦è¿›è¡Œå¹³å‡ï¼Œä¸ºæ¯ä¸ªç¤ºä¾‹è¿”å›ä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¾“å‡ºå‘é‡ã€‚è¿™å…è®¸æ¨¡å‹ä»¥æœ€ç®€å•çš„æ–¹å¼å¤„ç†å¯å˜é•¿åº¦çš„è¾“å…¥ã€‚

- è¯¥å›ºå®šé•¿åº¦çš„è¾“å‡ºå‘é‡é€šè¿‡ç®¡é“ä¼ è¾“åˆ°è®¾ç½®åŒ…å«æœ‰16ä¸ªéšè—å•å…ƒçš„å®Œå…¨è¿æ¥å±‚(dense layer)ã€‚

- æœ€åä¸€å±‚æ˜¯å¯†é›†è¿æ¥çš„å•ä¸ªè¾“å‡ºèŠ‚ç‚¹ã€‚ä½¿ç”¨*sigmoid*æ¿€æ´»å‡½æ•°ï¼Œæ­¤å€¼æ˜¯0åˆ°1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºæ¦‚ç‡æˆ–ç½®ä¿¡åº¦ã€‚

##### éšè—çš„å•å…ƒ

ä¸Šé¢çš„æ¨¡å‹åœ¨è¾“å…¥å’Œè¾“å‡ºä¹‹é—´æœ‰ä¸¤ä¸ªä¸­é—´å±‚æˆ–â€œéšè—â€å±‚( intermediate or â€œhiddenâ€ layers)ã€‚è¾“å‡ºçš„æ•°é‡(å•å…ƒã€èŠ‚ç‚¹æˆ–ç¥ç»å…ƒ)æ˜¯è¯¥å±‚çš„è¡¨å¾çš„ç©ºé—´çš„ç»´æ•°ã€‚æ¢å¥è¯è¯´ï¼Œç½‘ç»œæ¨¡å‹å†å­¦ä¹ ä¸€ä¸ªå†…éƒ¨è¡¨å¾çš„è‡ªç”±åº¦æ˜¯ä»»æ„çš„ã€‚

##### æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨

ä¸€ä¸ªæ¨¡å‹éœ€è¦ä¸€ä¸ªæŸå¤±å‡½æ•°å’Œä¸€ä¸ªè®­ç»ƒä¼˜åŒ–å™¨ã€‚ç”±äºæœ¬æ¡ˆä¾‹æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œæ¨¡å‹è¾“å‡ºä¸€ä¸ªæ¦‚ç‡(å¸¦æœ‰sigmoidæ¿€æ´»çš„å•ä¸ªå•å…ƒå±‚)ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨*binary_crossentropy*æŸå¤±å‡½æ•°(Loss function)ã€‚

è¿™ä¸æ˜¯æŸå¤±å‡½æ•°çš„å”¯ä¸€é€‰æ‹©ï¼Œä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥é€‰æ‹©*mean_squared_error*ã€‚ä½†æ˜¯ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œ*binary_crossenpy*æ›´é€‚åˆå¤„ç†æ¦‚ç‡â€”â€”å®ƒæµ‹é‡æ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„â€œè·ç¦»â€ï¼Œæˆ–è€…åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œå³æ˜¯çœŸå®åˆ†å¸ƒå’Œé¢„æµ‹ä¹‹é—´çš„â€œè·ç¦»â€ã€‚

ç¨åï¼Œå½“æˆ‘ä»¬æ¢è®¨å›å½’é—®é¢˜(æ¯”å¦‚ï¼Œé¢„æµ‹æˆ¿å±‹ä»·æ ¼)æ—¶ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨å¦ä¸€ä¸ªç§°ä¸ºå‡æ–¹è¯¯å·®( mean squared error)çš„æŸå¤±å‡½æ•°ã€‚

ç°åœ¨ï¼Œé…ç½®æ¨¡å‹ä¸­ä½¿ç”¨çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ï¼š

```r
model %>% compile(
  optimizer = 'adam',
  loss = 'binary_crossentropy',
  metrics = list('accuracy')
)
```

#### è®­ç»ƒæ¨¡å‹

æ¨¡å‹è®­ç»ƒä½¿ç”¨åŒ…å«512ä¸ªæ ·æœ¬çš„å°æ‰¹é‡æ•°æ®é›†è¿›è¡Œ20ä¸ªepochsï¼Œä¹Ÿå°±æ˜¯å¯¹x_trainå’Œy_trainå¼ é‡ä¸­çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œ20æ¬¡è¿­ä»£ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œåœ¨éªŒè¯é›†çš„10,000ä¸ªæ ·æœ¬ä¸Šç›‘æ§æ¨¡å‹çš„æŸå¤±å’Œå‡†ç¡®æ€§:

```r
history <- model %>% fit(
  training$text,
  as.numeric(training$tag == "pos"),
  epochs = 10,
  batch_size = 512,
  validation_split = 0.2,
  verbose=2
)
### Epoch 1/10
### 81/81 - 1s - loss: 0.6922 - accuracy: 0.5284 - val_loss: 0.6900 - val_accuracy: 0.5717
### Epoch 2/10
### 81/81 - 1s - loss: 0.6872 - accuracy: 0.5616 - val_loss: 0.6823 - val_accuracy: 0.5972
### Epoch 3/10
### 81/81 - 1s - loss: 0.6750 - accuracy: 0.6003 - val_loss: 0.6676 - val_accuracy: 0.6338
### Epoch 4/10
### 81/81 - 1s - loss: 0.6529 - accuracy: 0.6426 - val_loss: 0.6463 - val_accuracy: 0.6536
### Epoch 5/10
### 81/81 - 1s - loss: 0.6250 - accuracy: 0.6713 - val_loss: 0.6251 - val_accuracy: 0.6642
### Epoch 6/10
### 81/81 - 1s - loss: 0.5980 - accuracy: 0.6940 - val_loss: 0.6092 - val_accuracy: 0.6731
### Epoch 7/10
### 81/81 - 1s - loss: 0.5746 - accuracy: 0.7105 - val_loss: 0.5998 - val_accuracy: 0.6771
### Epoch 8/10
### 81/81 - 1s - loss: 0.5557 - accuracy: 0.7259 - val_loss: 0.5940 - val_accuracy: 0.6797
### Epoch 9/10
### 81/81 - 1s - loss: 0.5401 - accuracy: 0.7372 - val_loss: 0.5918 - val_accuracy: 0.6812
### Epoch 10/10
### 81/81 - 1s - loss: 0.5255 - accuracy: 0.7488 - val_loss: 0.5917 - val_accuracy: 0.6831

```

#### è¯„ä¼°æ¨¡å‹

è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªæ¨¡å‹æ˜¯å¦‚ä½•è¿è¡Œçš„ã€‚å°†è¿”å›ä¸¤ä¸ªå€¼ã€‚æŸå¤±å€¼(ä¸€ä¸ªè¡¨ç¤ºæˆ‘ä»¬çš„è¯¯å·®çš„æ•°å­—ï¼Œè¶Šä½çš„å€¼è¶Šå¥½)å’Œå‡†ç¡®æ€§ã€‚

```r
results <- model %>% evaluate(testing$text, as.numeric(testing$tag == "pos"), verbose = 0)
results
###      loss  accuracy
### 0.5864145 0.6879635
```
è¿™ç§ç›¸å½“æœ´ç´ çš„æ–¹æ³•å¯ä»¥è¾¾åˆ°çº¦68ï¼…çš„ç²¾åº¦ã€‚ä½¿ç”¨æ›´é«˜çº§çš„æ–¹æ³•ï¼Œæ¨¡å‹åº”æ¥è¿‘85ï¼…ã€‚

#### åˆ›å»ºä¸€ä¸ªéšæ—¶é—´å˜åŒ–çš„å‡†ç¡®æ€§å’ŒæŸå¤±å›¾è¡¨

*fit*è¿”å›ä¸€ä¸ª*keras_training_history*å¯¹è±¡ï¼Œå®ƒçš„*metrics*åŒ…å«è®­ç»ƒæœŸé—´è®°å½•çš„ä¸¢å¤±å’Œåº¦é‡å€¼( loss and metrics values)ã€‚ä½ å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨å®ƒæ¥ç»˜åˆ¶æŸå¤±å’ŒæŒ‡æ ‡æ›²çº¿:
```r
plot(history)
```
```{r fig7, echo=FALSE,out.width="60%", fig.cap ='è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´2',fig.align='center'} 

knitr::include_graphics('https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_text_classification_files/figure-html/unnamed-chunk-16-1.png')
```
æŸå¤±å’ŒæŒ‡æ ‡çš„æ¼”å˜ï¼Œä¹Ÿå¯ä»¥åœ¨RStudioæµè§ˆå™¨çª—æ ¼è®­ç»ƒä¸­çœ‹å‡ºã€‚

è¯·æ³¨æ„ï¼Œè®­ç»ƒæŸå¤±éšæ¯ä¸ªepoch è€Œå‡å°‘ï¼Œè®­ç»ƒå‡†ç¡®åº¦éšæ¯ä¸ªepoch è€Œå¢åŠ ã€‚ ä½¿ç”¨æ¢¯åº¦ä¸‹é™ä¼˜åŒ–(gradient descent optimization)æ—¶ï¼Œè¿™æ˜¯å¯ä»¥é¢„æœŸçš„-å®ƒåº”åœ¨æ¯æ¬¡è¿­ä»£ä¸­å°†æ‰€éœ€çš„æ•°é‡æœ€å°åŒ–ã€‚

[IMDB]:https://keras.rstudio.com/reference/dataset_imdb.html
[Internet]:https://www.imdb.com/

### ä½¿ç”¨tfhubä¸­çš„å­¦ä¹ æ¨¡å‹

æœ¬æ•™ç¨‹ä½¿ç”¨è¯„è®ºæ–‡æœ¬å°†ç”µå½±è¯„è®ºåˆ†ä¸ºæ­£é¢è¯„è®ºæˆ–è´Ÿé¢è¯„è®ºã€‚è¿™æ˜¯äºŒè¿›åˆ¶ï¼ˆæˆ–ä¸¤ç±»ï¼‰åˆ†ç±»çš„ç¤ºä¾‹ï¼Œå®ƒæ˜¯ä¸€ç§é‡è¦ä¸”å¹¿æ³›é€‚ç”¨çš„æœºå™¨å­¦ä¹ é—®é¢˜ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨[IMDB]æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«æ¥è‡ª[Internet]ç”µå½±æ•°æ®åº“çš„50,000ä¸ªç”µå½±è¯„è®ºçš„æ–‡æœ¬ã€‚è¿™äº›å†…å®¹åˆ†ä¸º25,000æ¡ç”¨äºåŸ¹è®­çš„è¯„è®ºå’Œ25,000æ¡ç”¨äºæµ‹è¯•çš„è¯„è®ºã€‚è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ˜¯å¹³è¡¡çš„ï¼Œè¿™æ„å‘³ç€å®ƒä»¬åŒ…å«ç›¸åŒæ•°é‡çš„æ­£é¢å’Œè´Ÿé¢è¯„è®ºã€‚

æˆ‘ä»¬å°†ä½¿ç”¨[Keras]æ„å»ºå’ŒåŸ¹è®­æ¨¡å‹ï¼Œä½¿ç”¨[tfhub]è¿›è¡Œè¿ç§»å­¦ä¹ ã€‚æˆ‘ä»¬è¿˜å°†ä½¿ç”¨tfdsæ¥åŠ è½½IMDBæ•°æ®é›†ã€‚

å…ˆå¯åŠ¨å¹¶åŠ è½½Kerasä»¥åŠå…¶ä»–ä¸€äº›å¿…éœ€çš„åº“ã€‚

```r
library(keras)
library(tfhub)
library(tfds)
library(tfdatasets)
```
#### ä¸‹è½½IMDBæ•°æ®é›†

IMDBæ•°æ®é›†å¯åœ¨[IMDB reviews]æˆ–[tfd]ä¸Šè·å¾—ã€‚Kerasæ‰“åŒ…çš„æ–‡ä»¶å·²ç»ç»è¿‡äº†é¢„å¤„ç†ï¼Œå› æ­¤å¯¹æœ¬æ•™ç¨‹æ²¡æœ‰ç”¨å¤„ã€‚

ä»¥ä¸‹ä»£ç ä¸‹è½½IMDBæ•°æ®é›†åˆ°æ‚¨çš„æœºå™¨:
```r
imdb <- tfds_load(
  "imdb_reviews:1.0.0", 
  split = list("train[:60%]", "train[-40%:]", "test"), 
  as_supervised = TRUE
)
summary(imdb)
### This is a dataset for binary sentiment classifica
### â¯ Name: imdb_reviews
### â¯ Version: 1.0.0
### â¯ URLs: http://ai.stanford.edu/~amaas/data/sentiment/
### â¯ Size:
### â¯ Splits:
###  â€” test ( examples)
###  â€” train ( examples)
###  â€” unsupervised ( examples)
### â¯ Schema:
```
*tfds_load*è¿”å›ä¸€ä¸ªTensorFlowæ•°æ®é›†ï¼Œæ˜¯è¡¨ç¤ºå…ƒç´ åºåˆ—çš„æŠ½è±¡ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ ç”±ä¸€ä¸ªæˆ–å¤šä¸ªç»„ä»¶ç»„æˆã€‚

è¦è®¿é—®æ•°æ®é›†çš„å•ä¸ªå…ƒç´ ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨:
```r
first <- imdb[[1]] %>% 
  dataset_batch(1) %>% # Used to get only the first example
  reticulate::as_iterator() %>% 
  reticulate::iter_next()
str(first)
### List of 2
###  $ :tf.Tensor([b"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it."], shape=(1,), dtype=string)
###  $ :tf.Tensor([0], shape=(1,), dtype=int64)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°KerasçŸ¥é“å¦‚ä½•è‡ªåŠ¨ä»TensorFlowæ•°æ®é›†æå–å…ƒç´ ï¼Œè¿™æ¯”åœ¨ä¼ é€’ç»™Kerasä¹‹å‰å°†æ•´ä¸ªæ•°æ®é›†åŠ è½½åˆ°RAMä¸­æ›´æœ‰æ•ˆåœ°æé«˜äº†å†…å­˜æ•ˆç‡ã€‚

#### æ„å»ºæ¨¡å‹

ç¥ç»ç½‘ç»œæ˜¯é€šè¿‡å †å å±‚æ¥åˆ›å»ºçš„â€”â€”è¿™éœ€è¦ä¸‰ä¸ªä¸»è¦çš„æ¶æ„å†³ç­–:

- å¦‚ä½•ä»£è¡¨æ–‡å­—ï¼Ÿ

- åœ¨æ¨¡å‹ä¸­ä½¿ç”¨å¤šå°‘å±‚ï¼Ÿ

- æ¯å±‚ä½¿ç”¨å¤šå°‘ä¸ªéšè—å•å…ƒï¼Ÿ

åœ¨æœ¬ä¾‹ä¸­ï¼Œè¾“å…¥æ•°æ®ç”±å¥å­ç»„æˆã€‚è¦é¢„æµ‹çš„æ ‡ç­¾ä¸æ˜¯0å°±æ˜¯1ã€‚

è¡¨ç¤ºæ–‡æœ¬çš„ä¸€ç§æ–¹æ³•æ˜¯å°†å¥å­è½¬æ¢ä¸ºåµŒå…¥å‘é‡ã€‚ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åµŒå…¥ä½œä¸ºç¬¬ä¸€å±‚ï¼Œè¿™å°†å…·æœ‰ä¸‰ä¸ªä¼˜ç‚¹ï¼š

* æˆ‘ä»¬ä¸å¿…æ‹…å¿ƒæ–‡æœ¬é¢„å¤„ç†ï¼Œ

* æˆ‘ä»¬å¯ä»¥ä»è¿ç§»å­¦ä¹ ä¸­å—ç›Šï¼Œ

* åµŒå…¥çš„å¤§å°æ˜¯å›ºå®šçš„ï¼Œå› æ­¤å¤„ç†èµ·æ¥æ›´ç®€å•ã€‚

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ¥è‡ª[TensorFlow Hub]çš„é¢„è®­ç»ƒæ–‡æœ¬åµŒå…¥æ¨¡å‹[google/tf2-preview/gnews-swivel-20dim/1]ã€‚

ä¸ºäº†æœ¬æ•™ç¨‹çš„ç›®çš„ï¼Œè¿˜éœ€è¦æµ‹è¯•å…¶ä»–ä¸‰ä¸ªé¢„å…ˆè®­ç»ƒè¿‡çš„æ¨¡å‹:

- [google/tf2-preview/gnews-swivel-20dim-with-oov/1]æ˜¯ä¸google/tf2-preview/gnews-swivel-20dim/1ç›¸åŒï¼Œä½†æœ‰2.5ï¼…çš„è¯æ±‡é‡è½¬æ¢ä¸ºOOVå­˜å‚¨æ¡¶ã€‚ å¦‚æœä»»åŠ¡çš„è¯æ±‡è¡¨å’Œæ¨¡å‹çš„è¯æ±‡è¡¨æ²¡æœ‰å®Œå…¨é‡å ï¼Œåˆ™å¯ä»¥æä¾›å¸®åŠ©ã€‚

- [google/tf2-preview/nnlm-en-dim50/1]æ˜¯æ›´å¤§çš„æ¨¡å‹ï¼Œè¯æ±‡é‡çº¦ä¸ºä¸€ç™¾ä¸‡(1M)ï¼Œç»´åº¦ä¸º50ã€‚

- [google/tf2-preview/nnlm-en-dim128/1]æ˜¯æ›´åŠ å¤§çš„è¯æ±‡æ¨¡å‹ï¼Œè¯æ±‡é‡çº¦ä¸º1Mï¼Œç»´åº¦ä¸º128ã€‚

è®©æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªKeraså±‚(Keras layer)ï¼Œå®ƒä½¿ç”¨TensorFlow Hubä¸­çš„æ¨¡å‹æ¥åµŒå…¥å¥å­ï¼Œå¹¶åœ¨å‡ ä¸ªè¾“å…¥æ•°æ®çš„ç¤ºä¾‹ä¸­äº†è§£å®ƒã€‚æ³¨æ„ï¼Œæ— è®ºè¾“å…¥æ–‡æœ¬çš„é•¿åº¦æ˜¯å¤šå°‘ï¼ŒåµŒå…¥å±‚çš„è¾“å‡ºå½¢çŠ¶éƒ½æ˜¯:(num_examples, embeddding_dimension)ã€‚

æ³¨æ„ï¼šå¦‚æœå¤§é™†ç½‘ç»œæ— æ³•ä½¿ç”¨httpsè®¿é—®TensorFlow Hubä¸­çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆå°è¯•é€šè¿‡æµè§ˆå™¨å°†æ¨¡å‹æ•°æ®ä¸‹è½½åˆ°æœ¬åœ°(å¦‚[tf2-preview_gnews-swivel-20dim_1.tar.gz])ï¼Œç„¶åè§£å‹å‹ç¼©åŒ…åˆ°æŒ‡å®šè·¯å¾„(å¦‚ï¼š/tmp/tensorflow_hub/tf2-preview_gnews-swivel-20dim_1)ï¼Œåœ¨è°ƒç”¨æ¨¡å‹æ—¶ï¼Œä¾¿å¯ä»¥ç›´æ¥è°ƒç”¨æœ¬åœ°çš„æ¨¡å‹æ•°æ®äº†()ã€‚

```r
embedding_layer <- layer_hub(handle = "https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1")
embedding_layer(first[[1]])

# é€šè¿‡è°ƒç”¨ä¸‹è½½åˆ°æœ¬åœ°çš„æ¨¡å‹æ•°æ®
# embedding_layer <- layer_hub(handle = "/tmp/tensorflow_hub/tf2-preview_gnews-swivel-20dim_1")
# embedding_layer(first[[1]])

### tf.Tensor(
### [[ 1.765786   -3.882232    3.9134233  -1.5557289  -3.3362343  -1.7357955
###   -1.9954445   1.2989551   5.081598   -1.1041286  -2.0503852  -0.72675157
###   -0.65675956  0.24436149 -3.7208383   2.0954835   2.2969332  -2.0689783
###   -2.9489717  -1.1315987 ]], shape=(1, 20), dtype=float32)
```

ç°åœ¨è®©æˆ‘ä»¬æ„å»ºå®Œæ•´çš„æ¨¡å‹:
```r
model <- keras_model_sequential() %>% 
  layer_hub(
    handle = "https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1",
    input_shape = list(),
    dtype = tf$string,
    trainable = TRUE
  ) %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")

summary(model)
### Model: "sequential"
### ________________________________________________________________________________
### Layer (type)                        Output Shape                    Param #
### ================================================================================
### keras_layer_1 (KerasLayer)          (None, 20)                      400020
### ________________________________________________________________________________
### dense_3 (Dense)                     (None, 16)                      336
### ________________________________________________________________________________
### dense_2 (Dense)                     (None, 1)                       17
### ================================================================================
### Total params: 400,373
### Trainable params: 400,373
### Non-trainable params: 0
### ________________________________________________________________________________

```
ä¾æ¬¡å †å å„å±‚ä»¥æ„å»ºåˆ†ç±»å™¨ï¼š

1. ç¬¬ä¸€å±‚æ˜¯TensorFlow Hubå±‚(TensorFlow Hub layer)ã€‚è¯¥å±‚ä½¿ç”¨é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹å°†å¥å­æ˜ å°„åˆ°å…¶åµŒå…¥å‘é‡ä¸­ã€‚å³è¿™é‡Œä½¿ç”¨çš„ç»è¿‡é¢„è®­ç»ƒçš„æ–‡æœ¬åµŒå…¥æ¨¡å‹([google/tf2-preview/gnews-swivel-20dim/1])å°†å¥å­æ‹†åˆ†ä¸ºæ ‡è®°ï¼ŒåµŒå…¥æ¯ä¸ªæ ‡è®°ï¼Œç„¶åç»„åˆåµŒå…¥å±‚ã€‚ ç»“æœç»´åº¦ä¸ºï¼šï¼ˆnum_examplesï¼Œembedding_dimensionï¼‰ã€‚

2. è¯¥å›ºå®šé•¿åº¦çš„è¾“å‡ºçŸ¢é‡é€šè¿‡å…·æœ‰16ä¸ªéšè—å•å…ƒçš„å®Œå…¨è¿æ¥ï¼ˆå¯†é›†ï¼‰å±‚è¿›è¡Œä¼ é€’ã€‚

3. æœ€åä¸€å±‚ä¸å•ä¸ªè¾“å‡ºèŠ‚ç‚¹ç´§å¯†è¿æ¥ã€‚ ä½¿ç”¨*sigmoid*æ¿€æ´»å‡½æ•°ï¼Œè¯¥å€¼æ˜¯0åˆ°1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºæ¦‚ç‡æˆ–ç½®ä¿¡åº¦ã€‚

#### ç¼–è¯‘æ¨¡å‹

##### æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨

ä¸€ä¸ªæ¨¡å‹éœ€è¦ä¸€ä¸ªæŸå¤±å‡½æ•°å’Œä¸€ä¸ªè®­ç»ƒä¼˜åŒ–å™¨ã€‚ç”±äºæœ¬æ¡ˆä¾‹æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œæ¨¡å‹è¾“å‡ºä¸€ä¸ªæ¦‚ç‡(å¸¦æœ‰sigmoidæ¿€æ´»çš„å•ä¸ªå•å…ƒå±‚)ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨*binary_crossentropy*æŸå¤±å‡½æ•°(Loss function)ã€‚

è¿™ä¸æ˜¯æŸå¤±å‡½æ•°çš„å”¯ä¸€é€‰æ‹©ï¼Œä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥é€‰æ‹©*mean_squared_error*ã€‚ä½†æ˜¯ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œ*binary_crossenpy*æ›´é€‚åˆå¤„ç†æ¦‚ç‡â€”â€”å®ƒæµ‹é‡æ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„â€œè·ç¦»â€ï¼Œæˆ–è€…åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œå³æ˜¯çœŸå®åˆ†å¸ƒå’Œé¢„æµ‹ä¹‹é—´çš„â€œè·ç¦»â€ã€‚

ç¨åï¼Œå½“æˆ‘ä»¬æ¢è®¨å›å½’é—®é¢˜(æ¯”å¦‚ï¼Œé¢„æµ‹æˆ¿å±‹ä»·æ ¼)æ—¶ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨å¦ä¸€ä¸ªç§°ä¸ºå‡æ–¹è¯¯å·®(mean squared error)çš„æŸå¤±å‡½æ•°ã€‚

ç°åœ¨ï¼Œé…ç½®æ¨¡å‹ä¸­ä½¿ç”¨çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ï¼š

```r
model %>% 
  compile(
    optimizer = "adam",
    loss = "binary_crossentropy",
    metrics = "accuracy"
  )
```

#### æ¨¡å‹è®­ç»ƒ

æ¨¡å‹è®­ç»ƒä½¿ç”¨åŒ…å«512ä¸ªæ ·æœ¬çš„å°æ‰¹é‡æ•°æ®é›†è¿›è¡Œ20ä¸ªepochsï¼Œä¹Ÿå°±æ˜¯å¯¹x_trainå’Œy_trainå¼ é‡ä¸­çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œ20æ¬¡è¿­ä»£ã€‚åœ¨è®­ç»ƒæ—¶ï¼Œåœ¨éªŒè¯é›†çš„10,000ä¸ªæ ·æœ¬ä¸Šç›‘æ§æ¨¡å‹çš„æŸå¤±å’Œå‡†ç¡®æ€§:

```r
history<-model %>% fit(
    imdb[[1]] %>% dataset_shuffle(10000) %>% dataset_batch(512),
    epochs = 20,
    validation_data = imdb[[2]] %>% dataset_batch(512),
    verbose = 2
  )

```

#### è¯„ä¼°æ¨¡å‹

è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªæ¨¡å‹æ˜¯å¦‚ä½•è¿è¡Œçš„ã€‚å°†è¿”å›ä¸¤ä¸ªå€¼ã€‚æŸå¤±å€¼(ä¸€ä¸ªè¡¨ç¤ºæˆ‘ä»¬çš„è¯¯å·®çš„æ•°å­—ï¼Œè¶Šä½çš„å€¼è¶Šå¥½)å’Œå‡†ç¡®æ€§ã€‚

```r
results <- model %>% 
  evaluate(imdb[[3]] %>%  dataset_batch(512), verbose = 0)
results
###      loss  accuracy
### 0.3169311 0.8660800
```
è¿™ç§ç®€å•çš„æ–¹æ³•å¯ä»¥è¾¾åˆ°çº¦87ï¼…çš„ç²¾åº¦ã€‚ä½¿ç”¨æ›´é«˜çº§çš„æ–¹æ³•ï¼Œæ¨¡å‹å‡†ç¡®åº¦åº”æ¥è¿‘95ï¼…ã€‚

#### å‡†ç¡®æ€§å’ŒæŸå¤±å‡½æ•°çš„å›¾è¡¨

*fit*è¿”å›ä¸€ä¸ª*keras_training_history*å¯¹è±¡ï¼Œå®ƒçš„*metrics*åŒ…å«è®­ç»ƒæœŸé—´è®°å½•çš„ä¸¢å¤±å’Œåº¦é‡å€¼( loss and metrics values)ã€‚ä½ å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨å®ƒæ¥ç»˜åˆ¶æŸå¤±å’ŒæŒ‡æ ‡æ›²çº¿:
```r
plot(history)
```
```{r fig8, echo=FALSE,out.width="60%", fig.cap ='è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´3',fig.align='center'} 

knitr::include_graphics('https://s3.ax1x.com/2020/12/26/rhVyPP.png')
```
[Keras]:https://github.com/rstudio/keras
[tfhub]:https://github.com/rstudio/tfhub
[IMDB reviews]:https://github.com/tensorflow/datasets/blob/master/docs/datasets.md#imdb_reviews
[tfd]:https://github.com/rstudio/tfds
[TensorFlow Hub]:https://github.com/rstudio/tfhub
[google/tf2-preview/gnews-swivel-20dim/1]:https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1

[google/tf2-preview/gnews-swivel-20dim-with-oov/1]:https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1
[google/tf2-preview/nnlm-en-dim50/1]:https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1
[google/tf2-preview/nnlm-en-dim128/1]:https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1
[tf2-preview_gnews-swivel-20dim_1.tar.gz]:https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1?tf-hub-format=compressed


### è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ

åœ¨ä¹‹å‰çš„ä¸¤ä¸ªæ•™ç¨‹ä¸­â€”â€”å¯¹[ç”µå½±è¯„è®ºè¿›è¡Œåˆ†ç±»]å’Œ[é¢„æµ‹æˆ¿ä»·]â€”â€”æˆ‘ä»¬çœ‹åˆ°ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨éªŒè¯æ•°æ®ä¸Šçš„å‡†ç¡®æ€§åœ¨ç»è¿‡è‹¥å¹²ä¸ªepochçš„è®­ç»ƒåå°†è¾¾åˆ°å³°å€¼ï¼Œç„¶åå¼€å§‹ä¸‹é™ã€‚

æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å°†è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚ å­¦ä¹ å¦‚ä½•åº”å¯¹è¿‡åº¦æ‹Ÿåˆéå¸¸é‡è¦ã€‚ å°½ç®¡é€šå¸¸å¯ä»¥åœ¨è®­ç»ƒé›†ä¸Šè¾¾åˆ°å¾ˆé«˜çš„å‡†ç¡®æ€§ï¼Œä½†æˆ‘ä»¬çœŸæ­£æƒ³è¦çš„æ˜¯å¼€å‘å‡ºèƒ½å¤Ÿå¾ˆå¥½åœ°é¢„æµ‹æˆ–è€…æ¦‚æ‹¬æµ‹è¯•æ•°æ®ï¼ˆæˆ–ä¹‹å‰ä»æœªè§è¿‡çš„æ•°æ®ï¼‰çš„æ¨¡å‹ã€‚

è¿‡åº¦æ‹Ÿåˆçš„åé¢æ˜¯æ¬ æ‹Ÿåˆã€‚ å½“å‘ç°æµ‹è¯•æ•°æ®ä»æœ‰æ”¹è¿›ç©ºé—´æ—¶ï¼Œå°±ä¼šå‘ç”Ÿæ¬ æ‹Ÿåˆã€‚ å‘ç”Ÿè¿™ç§æƒ…å†µçš„åŸå› æœ‰å¾ˆå¤šï¼šå¦‚æ¨¡å‹ä¸å¤Ÿå¼ºå¤§ï¼Œæ¨¡å‹è¿‡äºè§„èŒƒåŒ–ï¼Œæˆ–è€…ä»…ä»…æ˜¯æ²¡æœ‰ç»è¿‡è¶³å¤Ÿé•¿æ—¶é—´çš„è®­ç»ƒã€‚ è¿™æ„å‘³ç€ç½‘ç»œå°šæœªå­¦ä¹ è®­ç»ƒæ•°æ®ä¸­çš„ç›¸å…³æ¨¡å¼ã€‚

ä¸ºäº†é˜²æ­¢è¿‡åº¦æ‹Ÿåˆï¼Œæœ€å¥½çš„è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨æ›´å¤šçš„è®­ç»ƒæ•°æ®ã€‚ ç»è¿‡æ›´å¤šæ•°æ®è®­ç»ƒçš„æ¨¡å‹è‡ªç„¶ä¼šæ›´å¥½åœ°æ¨å¹¿ã€‚ å½“è¿™ä¸å†å¯èƒ½æ—¶ï¼Œä¸‹ä¸€ä¸ªæœ€ä½³è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨æ­£åˆ™åŒ–ä¹‹ç±»çš„æŠ€æœ¯ã€‚ è¿™äº›æ­£åˆ™åŒ–ä¹‹ç±»çš„æŠ€æœ¯é™åˆ¶äº†æ¨¡å‹å¯ä»¥å­˜å‚¨çš„ä¿¡æ¯çš„æ•°é‡å’Œç±»å‹ã€‚ å¦‚æœç½‘ç»œæ¨¡å‹åªèƒ½å­˜å‚¨å°‘é‡æ¨¡å¼ï¼Œé‚£ä¹ˆä¼˜åŒ–è¿‡ç¨‹å°†è¿«ä½¿å®ƒä¸“æ³¨äºæœ€çªå‡ºçš„æ¨¡å¼ï¼Œè¿™äº›æ¨¡å¼å…·æœ‰æ›´å¥½çš„æ³›åŒ–æ€§ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ä¸¤ç§å¸¸è§çš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼šæƒé‡æ­£åˆ™åŒ–(weight regularization)å’Œä¸¢åŒ…(dropout)ï¼Œå¹¶ä½¿ç”¨å®ƒä»¬æ¥æ”¹è¿›æˆ‘ä»¬çš„IMDBç”µå½±è¯„è®ºåˆ†ç±»ç»“æœã€‚

å…ˆå¯åŠ¨å¹¶åŠ è½½Kerasä»¥åŠå…¶ä»–ä¸€äº›å¿…éœ€çš„åº“ã€‚

```r
library(keras)
library(dplyr)
library(ggplot2)
library(tidyr)
library(tibble)
```

#### ä¸‹è½½IMDBæ•°æ®é›†

```r
num_words <- 1000
imdb <- dataset_imdb(num_words = num_words)
#https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz
c(train_data, train_labels) %<-% imdb$train
c(test_data, test_labels) %<-% imdb$test
```
ä¸åœ¨å‰é¢çš„ç¬”è®°ä¸­ä½¿ç”¨åµŒå…¥å±‚ä¸åŒï¼Œè¿™é‡Œæˆ‘ä»¬å°†å¯¹å¥å­è¿›è¡Œå¤šæ¬¡çƒ­ç¼–ç ã€‚è¯¥æ¨¡å‹å°†å¿«é€Ÿåœ°å¯¹è®­ç»ƒé›†è¿›è¡Œè¿‡æ‹Ÿåˆã€‚å®ƒå°†è¢«ç”¨æ¥æ¼”ç¤ºä½•æ—¶å‘ç”Ÿè¿‡æ‹Ÿåˆï¼Œä»¥åŠå¦‚ä½•åº”å¯¹è¿‡æ‹Ÿåˆã€‚

å¯¹åˆ—è¡¨è¿›è¡Œå¤šæ¬¡çƒ­ç¼–ç æ„å‘³ç€å°†å®ƒä»¬è½¬æ¢ä¸º0å’Œ1çš„å‘é‡ã€‚ å…·ä½“è€Œè¨€ï¼Œè¿™æ„å‘³ç€ä¾‹å¦‚å°†åºåˆ—[3ï¼Œ5]è½¬æ¢ä¸ºä¸€ä¸ª10,000ç»´å‘é‡ï¼Œè¯¥å‘é‡é™¤ç´¢å¼•3å’Œ5æ˜¯1å¤–ï¼Œå…¶ä½™çš„å…¨æ˜¯é›¶ã€‚

```r
multi_hot_sequences <- function(sequences, dimension) {
  multi_hot <- matrix(0, nrow = length(sequences), ncol = dimension)
  for (i in 1:length(sequences)) {
    multi_hot[i, sequences[[i]]] <- 1
  }
  multi_hot
}

train_data <- multi_hot_sequences(train_data, num_words)
test_data <- multi_hot_sequences(test_data, num_words)
```
è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å…¶ä¸­ä¸€ä¸ªå¤šæ¬¡çƒ­ç¼–ç ç‚¹çŸ¢é‡ã€‚ ç”±äºå•è¯ç´¢å¼•æ˜¯æŒ‰é¢‘ç‡æ’åºï¼Œå› æ­¤å¯ä»¥é¢„æœŸåœ¨ç´¢å¼•0é™„è¿‘æœ‰æ›´å¤šçš„1å€¼ï¼Œå¦‚æˆ‘ä»¬åœ¨è¯¥å›¾ä¸­æ‰€çœ‹åˆ°çš„ï¼š

```r
first_text <- data.frame(word = 1:num_words, value = train_data[1, ])
ggplot(first_text, aes(x = word, y = value)) +
  geom_line() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
```
```{r fig9, echo=FALSE,out.width="60%", fig.cap ='è®­ç»ƒæ¨¡å‹çš„æ”¶æ•›è¿‡ç¨‹å’Œæ—¶é—´3',fig.align='center'} 

knitr::include_graphics('https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_overfit_underfit_files/figure-html/unnamed-chunk-4-1.png')
```

#### è¿‡æ‹Ÿåˆç¤ºä¾‹

é˜²æ­¢è¿‡åº¦æ‹Ÿåˆçš„æœ€ç®€å•æ–¹æ³•æ˜¯å‡å°æ¨¡å‹çš„å¤§å°ï¼Œå³å‡å°æ¨¡å‹ä¸­å¯å­¦ä¹ çš„å‚æ•°çš„æ•°é‡ï¼ˆç”±å±‚æ•°å’Œæ¯å±‚å•å…ƒæ•°ç¡®å®šï¼‰ã€‚ åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ¨¡å‹ä¸­å¯å­¦ä¹ å‚æ•°çš„æ•°é‡é€šå¸¸ç§°ä¸ºæ¨¡å‹çš„â€œå®¹é‡â€ã€‚ ç›´è§‚åœ°è®²ï¼Œå…·æœ‰æ›´å¤šå‚æ•°çš„æ¨¡å‹å°†å…·æœ‰æ›´å¤šçš„â€œè®°å¿†èƒ½åŠ›â€ï¼Œå› æ­¤å°†èƒ½å¤Ÿè½»æ¾å­¦ä¹ è®­ç»ƒæ ·æœ¬ä¸å…¶ç›®æ ‡ä¹‹é—´çš„å®Œç¾çš„å­—å…¸å¼æ˜ å°„ï¼Œè¿™ç§æ˜ å°„æ²¡æœ‰ä»»ä½•æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨å¯¹ä»¥å‰çœ‹ä¸è§çš„æ•°æ®è¿›è¡Œé¢„æµ‹æ—¶ï¼Œè¿™å°†æ¯«æ— ç”¨å¤„ã€‚

>å§‹ç»ˆç‰¢è®°è¿™ä¸€ç‚¹ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹å¾€å¾€æ“…é•¿æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œä½†çœŸæ­£çš„æŒ‘æˆ˜æ˜¯**æ³›åŒ–**ï¼Œè€Œä¸æ˜¯æ‹Ÿåˆã€‚

ä¸å¹¸çš„æ˜¯ï¼Œæ²¡æœ‰ç¥å¥‡çš„å…¬å¼æ¥ç¡®å®šæ¨¡å‹çš„æ­£ç¡®å¤§å°æˆ–ä½“ç³»ç»“æ„ï¼ˆæ ¹æ®å±‚æ•°æˆ–æ¯å±‚çš„å‚æ•°çš„æ­£ç¡®å¤§å°ï¼‰ã€‚ æ‚¨å°†ä¸å¾—ä¸å°è¯•ä½¿ç”¨ä¸€ç³»åˆ—ä¸åŒçš„ä½“ç³»ç»“æ„ã€‚

ä¸ºäº†æ‰¾åˆ°åˆé€‚çš„æ¨¡å‹å°ºå¯¸ï¼Œæœ€å¥½ä»ç›¸å¯¹è¾ƒå°‘çš„å›¾å±‚å’Œå‚æ•°å¼€å§‹ï¼Œç„¶åå¼€å§‹å¢åŠ å›¾å±‚çš„å¤§å°æˆ–æ·»åŠ æ–°çš„å›¾å±‚ï¼Œç›´åˆ°çœ‹åˆ°éªŒè¯æŸå¤±çš„æ”¶ç›Šé€’å‡ä¸ºæ­¢ã€‚ è®©æˆ‘ä»¬åœ¨ç”µå½±è¯„è®ºåˆ†ç±»ç½‘ç»œä¸Šå°è¯•ä¸€ä¸‹ã€‚

æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªä»…ä½¿ç”¨å¯†é›†å±‚çš„åŸºç¡€æ¨¡å‹ï¼Œå’Œä¸€ä¸ªæ¯”è¾ƒå°å‹çš„æ¨¡å‹ï¼Œå¹¶å¯¹å®ƒä»¬è¿›è¡Œè¿›è¡Œæ¯”è¾ƒã€‚

##### å»ºç«‹åŸºç¡€æ¨¡å‹

```r
baseline_model <- 
  keras_model_sequential() %>%
  layer_dense(units = 16, activation = "relu", input_shape = num_words) %>%
  layer_dense(units = 16, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

baseline_model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = list("accuracy")
)

summary(baseline_model)
### Model: "sequential"
### ________________________________________________________________________________
### Layer (type)                        Output Shape                    Param #
### ================================================================================
### dense_2 (Dense)                     (None, 16)                      16016
### ________________________________________________________________________________
### dense_1 (Dense)                     (None, 16)                      272
### ________________________________________________________________________________
### dense (Dense)                       (None, 1)                       17
### ================================================================================
### Total params: 16,305
### Trainable params: 16,305
### Non-trainable params: 0
### ________________________________________________________________________________

baseline_history <- baseline_model %>% fit(
  train_data,
  train_labels,
  epochs = 20,
  batch_size = 512,
  validation_data = list(test_data, test_labels),
  verbose = 2
)
### Epoch 1/20
### 49/49 - 4s - loss: 0.5986 - accuracy: 0.6920 - val_loss: 0.4629 - val_accuracy: 0.8026
### ...
### Epoch 20/20
### 49/49 - 0s - loss: 0.1784 - accuracy: 0.9338 - val_loss: 0.4087 - val_accuracy: 0.8425

```

##### åˆ›å»ºä¸€ä¸ªæ›´å°çš„æ¨¡å‹

è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåŒ…å«è¾ƒå°‘éšè—å•ä½çš„æ¨¡å‹ï¼Œä¸æˆ‘ä»¬åˆšåˆšåˆ›å»ºçš„åŸºç¡€æ¨¡å‹è¿›è¡Œæ¯”è¾ƒ:

```r
smaller_model <- 
  keras_model_sequential() %>%
  layer_dense(units = 4, activation = "relu", input_shape = num_words) %>%
  layer_dense(units = 4, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

smaller_model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = list("accuracy")
)

summary(smaller_model)
### Model: "sequential_1"
### ________________________________________________________________________________
### Layer (type)                        Output Shape                    Param #
### ================================================================================
### dense_5 (Dense)                     (None, 4)                       4004
### ________________________________________________________________________________
### dense_4 (Dense)                     (None, 4)                       20
### ________________________________________________________________________________
### dense_3 (Dense)                     (None, 1)                       5
### ================================================================================
### Total params: 4,029
### Trainable params: 4,029
### Non-trainable params: 0
### ________________________________________________________________________________

```
å¹¶ä½¿ç”¨ç›¸åŒçš„æ•°æ®è®­ç»ƒæ¨¡å‹:

```r
smaller_history <- smaller_model %>% fit(
  train_data,
  train_labels,
  epochs = 20,
  batch_size = 512,
  validation_data = list(test_data, test_labels),
  verbose = 2
)
### Epoch 1/20
### 49/49 - 0s - loss: 0.6219 - accuracy: 0.6821 - val_loss: 0.5364 - val_accuracy: 0.7832
### ...
### Epoch 20/20
### 49/49 - 0s - loss: 0.2952 - accuracy: 0.8787 - val_loss: 0.3320 - val_accuracy: 0.8589
```

##### åˆ›å»ºä¸€ä¸ªæ›´å¤§çš„æ¨¡å‹

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬åœ¨è¿™ä¸ªåŸºå‡†ä¸Šæ·»åŠ ä¸€ä¸ªå®¹é‡æ›´å¤§çš„ç½‘ç»œï¼Œè¿œè¿œè¶…å‡ºäº†é—®é¢˜æ‰€èƒ½ä¿è¯çš„èŒƒå›´:

```r
bigger_model <- 
  keras_model_sequential() %>%
  layer_dense(units = 512, activation = "relu", input_shape = num_words) %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

bigger_model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = list("accuracy")
)

summary(bigger_model)
### Model: "sequential_2"
### ________________________________________________________________________________
### Layer (type)                        Output Shape                    Param #
### ================================================================================
### dense_8 (Dense)                     (None, 512)                     512512
### ________________________________________________________________________________
### dense_7 (Dense)                     (None, 512)                     262656
### ________________________________________________________________________________
### dense_6 (Dense)                     (None, 1)                       513
### ================================================================================
### Total params: 775,681
### Trainable params: 775,681
### Non-trainable params: 0
### ________________________________________________________________________________
```
å¹¶ä½¿ç”¨ç›¸åŒçš„æ•°æ®è®­ç»ƒæ¨¡å‹:
```r
bigger_history <- bigger_model %>% fit(
  train_data,
  train_labels,
  epochs = 20,
  batch_size = 512,
  validation_data = list(test_data, test_labels),
  verbose = 2
)
### Epoch 1/20
### 49/49 - 1s - loss: 0.4507 - accuracy: 0.7849 - val_loss: 0.3708 - val_accuracy: 0.8410
### ...
### Epoch 20/20
### 49/49 - 1s - loss: 5.0736e-05 - accuracy: 1.0000 - val_loss: 0.8649 - val_accuracy: 0.8527
```

#### ç»˜åˆ¶åŸ¹è®­å’ŒéªŒè¯æŸå¤±

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç»˜åˆ¶3ç§æ¨¡å‹çš„æŸè€—æ›²çº¿ã€‚è¾ƒå°çš„ç½‘ç»œæ¨¡å‹å¼€å§‹è¿‡æ‹Ÿåˆçš„æ—¶é—´æ¯”åŸºçº¿æ¨¡å‹ç¨æ™šï¼Œå¹¶ä¸”ä¸€æ—¦å¼€å§‹è¿‡æ‹Ÿåˆï¼Œå®ƒçš„æ€§èƒ½ä¸‹é™å¾—æ›´æ…¢ã€‚è¯·æ³¨æ„ï¼Œè¾ƒå¤§çš„ç½‘ç»œæ¨¡å‹ä»…åœ¨ä¸€ä¸ªepochä¹‹åå°±å¼€å§‹è¿‡åº¦æ‹Ÿåˆï¼Œè€Œä¸”æ˜¯ä¸¥é‡è¿‡åº¦æ‹Ÿåˆã€‚ç½‘ç»œæ¨¡å‹å…·æœ‰çš„å®¹é‡è¶Šå¤šï¼Œå°†èƒ½å¤Ÿæ›´å¿«åœ°å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œå»ºæ¨¡ï¼ˆå¯¼è‡´è¾ƒä½çš„è®­ç»ƒæŸå¤±ï¼‰ï¼Œä½†å®ƒè¶Šå®¹æ˜“è¿‡æ‹Ÿåˆï¼ˆå¯¼è‡´è®­ç»ƒå’ŒéªŒè¯æŸå¤±ä¹‹é—´å­˜åœ¨è¾ƒå¤§å·®å¼‚ï¼‰ã€‚

```r
compare_cx <- data.frame(
  baseline_train = baseline_history$metrics$loss,
  baseline_val = baseline_history$metrics$val_loss,
  smaller_train = smaller_history$metrics$loss,
  smaller_val = smaller_history$metrics$val_loss,
  bigger_train = bigger_history$metrics$loss,
  bigger_val = bigger_history$metrics$val_loss
) %>%
  rownames_to_column() %>%
  mutate(rowname = as.integer(rowname)) %>%
  gather(key = "type", value = "value", -rowname)
  
ggplot(compare_cx, aes(x = rowname, y = value, color = type)) +
  geom_line() +
  xlab("epoch") +
  ylab("loss")
```
```{r fig10, echo=FALSE,out.width="60%", fig.cap ='bä¸åŒå¤æ‚ç¨‹åº¦çš„ç½‘ç»œæ¨¡å‹çš„æ‹Ÿåˆè¿‡ç¨‹å’Œæ—¶é—´',fig.align='center'} 

knitr::include_graphics('https://s3.ax1x.com/2020/12/26/rhbVuF.png')
```

#### ç­–ç•¥

##### æƒé‡æ­£åˆ™åŒ–

ä½ å¯èƒ½ç†Ÿæ‚‰å¥¥å¡å§†å‰ƒåˆ€åŸç†(Occamâ€™s Razor principle): å¯¹äºæŸä»¶äº‹æœ‰ä¸¤ç§è§£é‡Šï¼Œæœ€æœ‰å¯èƒ½æ­£ç¡®çš„è§£é‡Šæ˜¯â€œæœ€ç®€å•çš„â€è¿™ç§è§£é‡Šï¼Œä¹Ÿå°±æ˜¯åšå‡ºæœ€å°‘å‡è®¾çš„é‚£ä¸ªè§£é‡Šã€‚è¿™ä¹Ÿé€‚ç”¨äºç¥ç»ç½‘ç»œå­¦ä¹ çš„æ¨¡å‹:ç»™å®šä¸€äº›è®­ç»ƒæ•°æ®å’Œä¸€ä¸ªç½‘ç»œæ¶æ„ï¼Œæœ‰å¤šä¸ªæƒé‡å€¼é›†(å¤šä¸ªæ¨¡å‹)å¯ä»¥è§£é‡Šæ•°æ®ï¼Œç®€å•çš„æ¨¡å‹æ¯”å¤æ‚çš„æ¨¡å‹æ›´ä¸å®¹æ˜“è¿‡åº¦æ‹Ÿåˆã€‚

åœ¨è¿™ä¸ªä¸Šä¸‹æ–‡ä¸­ï¼Œâ€œç®€å•æ¨¡å‹â€æ˜¯æŒ‡å‚æ•°å€¼åˆ†å¸ƒçš„ç†µæ›´å°‘çš„æ¨¡å‹(æˆ–è€…æ˜¯ä¸€ä¸ªå…·æœ‰æ›´å°‘å‚æ•°çš„æ¨¡å‹ï¼Œå¦‚æˆ‘ä»¬åœ¨ä¸Šé¢ä¸€èŠ‚ä¸­çœ‹åˆ°çš„)ã€‚å› æ­¤ï¼Œå‡å°‘è¿‡åº¦æ‹Ÿåˆçš„ä¸€ç§å¸¸è§æ–¹æ³•æ˜¯é€šè¿‡å¼ºåˆ¶ç½‘ç»œçš„æƒé‡ä»…é‡‡ç”¨è¾ƒå°çš„å€¼æ¥å¯¹ç½‘ç»œçš„å¤æ‚æ€§æ–½åŠ çº¦æŸï¼Œè¿™ä½¿å¾—æƒé‡å€¼çš„åˆ†å¸ƒæ›´åŠ â€œè§„åˆ™â€ã€‚ è¿™ç§°ä¸ºâ€œæƒé‡è°ƒæ•´â€ï¼Œè¿™æ˜¯é€šè¿‡å‘ç½‘ç»œçš„æŸå¤±å‡½æ•°æ·»åŠ ä¸æ‹¥æœ‰å¤§æƒé‡ç›¸å…³çš„ä»£ä»·æ¥å®ç°çš„ã€‚è¿™ç§ä»£ä»·æœ‰ä¸¤ä¸ªæ–¹é¢:

- L1æ­£åˆ™åŒ–ï¼Œå…¶ä¸­å¢åŠ çš„æˆæœ¬ä¸æƒé‡ç³»æ•°çš„ç»å¯¹å€¼æˆæ¯”ä¾‹(å³ä¸æƒé‡çš„â€œL1èŒƒæ•°â€æˆæ¯”ä¾‹)ã€‚
- L2æ­£åˆ™åŒ–ï¼Œå…¶ä¸­å¢åŠ çš„æˆæœ¬ä¸æƒé‡ç³»æ•°çš„å€¼çš„å¹³æ–¹æˆæ­£æ¯”ï¼ˆå³ï¼Œæƒé‡çš„æ‰€è°“â€œ L2èŒƒæ•°â€ï¼‰ã€‚ L2æ­£åˆ™åŒ–åœ¨ç¥ç»ç½‘ç»œä¸­ä¹Ÿç§°ä¸ºæƒé‡è¡°å‡ã€‚ ä¸è¦è®©ä¸åŒçš„åå­—è¿·æƒ‘ä½ :é‡é‡è¡°å‡åœ¨æ•°å­¦ä¸Šå’ŒL2æ­£åˆ™åŒ–æ˜¯å®Œå…¨ä¸€æ ·çš„ã€‚

åœ¨Kerasä¸­ï¼Œæƒé‡æ­£åˆ™åŒ–æ˜¯é€šè¿‡å°†æƒé‡æ­£åˆ™åŒ–å®ä¾‹ä¼ é€’ç»™å±‚æ¥æ·»åŠ çš„ã€‚ç°åœ¨è®©æˆ‘ä»¬å°†L2æƒé‡æ­£åˆ™åŒ–æ·»åŠ åˆ°åŸºçº¿æ¨¡å‹ä¸­ã€‚

```r
l2_model <- 
  keras_model_sequential() %>%
  layer_dense(units = 16, activation = "relu", input_shape = num_words,
              kernel_regularizer = regularizer_l2(l = 0.001)) %>%
  layer_dense(units = 16, activation = "relu",
              kernel_regularizer = regularizer_l2(l = 0.001)) %>%
  layer_dense(units = 1, activation = "sigmoid")

l2_model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = list("accuracy")
)

l2_history <- l2_model %>% fit(
  train_data,
  train_labels,
  epochs = 20,
  batch_size = 512,
  validation_data = list(test_data, test_labels),
  verbose = 2
)
### Epoch 1/20
### 49/49 - 0s - loss: 0.5858 - accuracy: 0.7506 - val_loss: 0.4587 - val_accuracy: 0.8314
### ...
### Epoch 20/20
### 49/49 - 0s - loss: 0.3177 - accuracy: 0.8785 - val_loss: 0.3523 - val_accuracy: 0.8592
```
regularizer_l2(l = 0.001)è¡¨ç¤ºè¯¥å±‚æƒé‡çŸ©é˜µä¸­çš„æ¯ä¸€ä¸ªç³»æ•°éƒ½ä¼šä½¿ç½‘ç»œçš„æ€»æŸè€—å¢åŠ 0.001 * weight_coefficient_valueã€‚æ³¨æ„ï¼Œå› ä¸ºè¿™ä¸ªæƒ©ç½šåªåœ¨è®­ç»ƒæ—¶æ·»åŠ ï¼Œæ‰€ä»¥è¿™ä¸ªç½‘ç»œæ¨¡å‹åœ¨è®­ç»ƒæ—¶çš„æŸå¤±è¦æ¯”åœ¨æµ‹è¯•æ—¶é«˜å¾—å¤šã€‚

ä»¥ä¸‹æ˜¯L2æ­£åˆ™åŒ–æƒ©ç½šçš„å½±å“:

```r
compare_cx <- data.frame(
  baseline_train = baseline_history$metrics$loss,
  baseline_val = baseline_history$metrics$val_loss,
  l2_train = l2_history$metrics$loss,
  l2_val = l2_history$metrics$val_loss
) %>%
  rownames_to_column() %>%
  mutate(rowname = as.integer(rowname)) %>%
  gather(key = "type", value = "value", -rowname)
  
ggplot(compare_cx, aes(x = rowname, y = value, color = type)) +
  geom_line() +
  xlab("epoch") +
  ylab("loss")
```
```{r fig11, echo=FALSE,out.width="60%", fig.cap ='l2æƒé‡æ­£åˆ™åŒ–å¤„ç†çš„ç½‘ç»œæ¨¡å‹çš„æ‹Ÿåˆè¿‡ç¨‹',fig.align='center'} 

knitr::include_graphics('https://s3.ax1x.com/2020/12/26/rhbv26.png')
```
å¦‚æ‚¨æ‰€è§ï¼ŒL2æ­£åˆ™åŒ–æ¨¡å‹æ¯”åŸºç¡€æ¨¡å‹æ›´èƒ½æŠµæŠ—è¿‡æ‹Ÿåˆï¼Œå³ä½¿ä¸¤ä¸ªæ¨¡å‹å…·æœ‰ç›¸åŒæ•°é‡çš„å‚æ•°ã€‚

##### ä¸¢åŒ…

ä¸¢åŒ…(dropout)æ˜¯ç¥ç»ç½‘ç»œæœ€æœ‰æ•ˆå’Œæœ€å¸¸ç”¨çš„æ­£åˆ™åŒ–æŠ€æœ¯ä¹‹ä¸€ï¼Œç”±Hintonå’Œä»–åœ¨å¤šä¼¦å¤šå¤§å­¦çš„å­¦ç”Ÿå¼€å‘ã€‚ä¸¢åŒ…(dropout)åº”ç”¨äºä¸€ä¸ªå±‚ï¼Œç”±è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºâ€œDropoutâ€(å³è®¾ç½®ä¸ºé›¶)è¯¥å±‚çš„ä¸€äº›è¾“å‡ºç‰¹å¾ç»„æˆã€‚å‡è®¾ç»™å®šçš„å±‚é€šå¸¸ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸ºç»™å®šçš„è¾“å…¥æ ·æœ¬è¿”å›ä¸€ä¸ªå‘é‡[0.2,0.5,1.3,0.8,1.1];åº”ç”¨dropoutåï¼Œè¿™ä¸ªå‘é‡å°†æœ‰å‡ ä¸ªéšæœºåˆ†å¸ƒçš„é›¶é¡¹ï¼Œä¾‹å¦‚[0,0.5,1.3,0,1.1]ã€‚â€œé€€å‡ºç‡â€("dropout rate")æ˜¯è¢«å½’é›¶çš„ç‰¹å¾çš„åˆ†æ•°;é€šå¸¸è®¾ç½®åœ¨0.2åˆ°0.5ä¹‹é—´ã€‚åœ¨æµ‹è¯•æ—¶ï¼Œæ²¡æœ‰å•ä½è¢«åˆ é™¤ï¼Œç›¸åï¼Œè¯¥å±‚çš„è¾“å‡ºå€¼è¢«ç¼©å°äº†ä¸€ä¸ªç­‰äºåˆ é™¤ç‡çš„å› å­ï¼Œä»¥ä¾¿å¹³è¡¡æ›´å¤šçš„å•ä½æ¯”è®­ç»ƒæ—¶æ´»è·ƒçš„äº‹å®ã€‚

åœ¨Kerasä¸­ï¼Œæ‚¨å¯ä»¥é€šè¿‡*layer_dropout*åœ¨ç½‘ç»œæ¨¡å‹ä¸­å¼•å…¥ä¸¢åŒ…ï¼Œè¯¥ä¸¢åŒ…å°†ç«‹å³åº”ç”¨äºå›¾å±‚çš„è¾“å‡ºã€‚

è®©æˆ‘ä»¬åœ¨IMDBç½‘ç»œä¸­æ·»åŠ ä¸¤ä¸ªdropoutå±‚ï¼Œçœ‹çœ‹å®ƒä»¬åœ¨å‡å°‘è¿‡æ‹Ÿåˆæ–¹é¢åšå¾—å¦‚ä½•:
```r
dropout_model <- 
  keras_model_sequential() %>%
  layer_dense(units = 16, activation = "relu", input_shape = num_words) %>%
  layer_dropout(0.6) %>%
  layer_dense(units = 16, activation = "relu") %>%
  layer_dropout(0.6) %>%
  layer_dense(units = 1, activation = "sigmoid")

dropout_model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = list("accuracy")
)

dropout_history <- dropout_model %>% fit(
  train_data,
  train_labels,
  epochs = 20,
  batch_size = 512,
  validation_data = list(test_data, test_labels),
  verbose = 2
)
```
å®ƒçš„æ•ˆæœå¦‚ä½•?æ·»åŠ dropoutæ˜¯å¯¹åŸºçº¿æ¨¡å‹çš„æ˜æ˜¾æ”¹è¿›ã€‚

```r
compare_cx <- data.frame(
  baseline_train = baseline_history$metrics$loss,
  baseline_val = baseline_history$metrics$val_loss,
  dropout_train = dropout_history$metrics$loss,
  dropout_val = dropout_history$metrics$val_loss
) %>%
  rownames_to_column() %>%
  mutate(rowname = as.integer(rowname)) %>%
  gather(key = "type", value = "value", -rowname)
  
ggplot(compare_cx, aes(x = rowname, y = value, color = type)) +
  geom_line() +
  xlab("epoch") +
  ylab("loss")

```
```{r fig12, echo=FALSE,out.width="60%", fig.cap ='ä¸¢åŒ…æ­£åˆ™åŒ–å¤„ç†çš„ç½‘ç»œæ¨¡å‹çš„æ‹Ÿåˆè¿‡ç¨‹',fig.align='center'} 

knitr::include_graphics('https://s3.ax1x.com/2020/12/26/rhOF3t.png')
```

æ€»ç»“ä¸€ä¸‹ï¼Œä»¥ä¸‹æ˜¯é˜²æ­¢ç¥ç»ç½‘ç»œè¿‡åº¦æ‹Ÿåˆçš„æœ€å¸¸è§æ–¹æ³•:

- è·å–æ›´å¤šçš„è®­ç»ƒæ•°æ®ã€‚

- è¯·é™ä½ç½‘ç»œå®¹é‡ã€‚

- å¢åŠ æƒé‡æ­£åˆ™åŒ–å¤„ç†

- å¢åŠ ä¸¢åŒ…æ­£åˆ™åŒ–å¤„ç†

æœ¬æŒ‡å—ä¸­æ²¡æœ‰æ¶‰åŠçš„ä¸¤ç§é‡è¦æ–¹æ³•æ˜¯æ•°æ®å¢å¼º(Data augmentation )å’Œæ‰¹å½’ä¸€åŒ–(Batch normalization)ã€‚

[ç”µå½±è¯„è®ºè¿›è¡Œåˆ†ç±»]:https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_overfit_underfit/tutorial_basic_text_classification.html
[é¢„æµ‹æˆ¿ä»·]:https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_overfit_underfit/tutorial_basic_regression.html


### ä¿å­˜å’Œæ¢å¤æ¨¡å‹

å¯ä»¥åœ¨è®­ç»ƒåå’Œè®­ç»ƒä¸­ä¿å­˜æ¨¡å‹è¿›åº¦ã€‚è¿™æ„å‘³ç€ä¸€ä¸ªæ¨¡å‹å¯ä»¥åœ¨å®ƒåœæ­¢çš„åœ°æ–¹æ¢å¤ï¼Œé¿å…é•¿æ—¶é—´çš„è®­ç»ƒã€‚ä¿å­˜è¿˜æ„å‘³ç€æ‚¨å¯ä»¥å…±äº«æ‚¨çš„æ¨¡å‹ï¼Œå…¶ä»–äººå¯ä»¥é‡æ–°åˆ›å»ºæ‚¨çš„å·¥ä½œã€‚åœ¨å‘å¸ƒç ”ç©¶æ¨¡å‹å’ŒæŠ€æœ¯æ—¶ï¼Œä¸å¤§å¤šæ•°æœºå™¨å­¦ä¹ å®è·µè€…åˆ†äº«:

- åˆ›å»ºæ¨¡å‹çš„ä»£ç 

- è®­ç»ƒè¿‡çš„æƒé‡ï¼Œæˆ–æ¨¡å‹çš„å‚æ•°

å…±äº«è¿™äº›æ•°æ®å¯ä»¥å¸®åŠ©å…¶ä»–äººç†è§£æ¨¡å‹çš„å·¥ä½œæ–¹å¼ï¼Œå¹¶ä½¿ç”¨æ–°æ•°æ®è‡ªå·±å°è¯•ã€‚

#### é€‰é¡¹

æœ‰å¾ˆå¤šä¸åŒçš„æ–¹æ³•æ¥ä¿å­˜TensorFlowæ¨¡å‹â€”â€”è¿™å–å†³äºä½ ä½¿ç”¨çš„APIã€‚æœ¬æŒ‡å—ä½¿ç”¨Kerasï¼Œä¸€ä¸ªé«˜çº§APIæ¥æ„å»ºå’Œè®­ç»ƒTensorFlowæ¨¡å‹ã€‚å¯¹äºå…¶ä»–æ–¹æ³•ï¼Œå‚è§[TensorFlow Save and Restore guide]æˆ–[Saving in eager]ã€‚

#### è®¾ç½®

æˆ‘ä»¬å°†ä½¿ç”¨[MNIST]æ•°æ®é›†è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹æ¥æ¼”ç¤ºä¿å­˜è®­ç»ƒåçš„æƒé‡ã€‚ä¸ºäº†åŠ å¿«è¿™äº›æ¼”ç¤ºçš„è¿è¡Œé€Ÿåº¦ï¼Œåªä½¿ç”¨å‰1000ä¸ªç¤ºä¾‹:

```r
library(keras)

mnist <- dataset_mnist()

c(train_images, train_labels) %<-% mnist$train
c(test_images, test_labels) %<-% mnist$test

train_labels <- train_labels[1:1000]
test_labels <- test_labels[1:1000]

train_images <- train_images[1:1000, , ] %>%
  array_reshape(c(1000, 28 * 28))
train_images <- train_images / 255

test_images <- test_images[1:1000, , ] %>%
  array_reshape(c(1000, 28 * 28))
test_images <- test_images / 255
```
#### å®šä¹‰ä¸€ä¸ªæ¨¡å‹

è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªç®€å•çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®ƒæ¥æ¼”ç¤ºä¿å­˜å’ŒåŠ è½½æƒé‡ã€‚

```r
# è¿”å›ä¸€ä¸ªçŸ­åºåˆ—æ¨¡å‹
create_model <- function() {
  model <- keras_model_sequential() %>%
    layer_dense(units = 512, activation = "relu", input_shape = 784) %>%
    layer_dropout(0.2) %>%
    layer_dense(units = 10, activation = "softmax")
  model %>% compile(
    optimizer = "adam",
    loss = "sparse_categorical_crossentropy",
    metrics = list("accuracy")
  )
  model
}

model <- create_model()
summary(model)
### Model: "sequential"
### ________________________________________________________________________________
### Layer (type)                        Output Shape                    Param #
### ================================================================================
### dense_1 (Dense)                     (None, 512)                     401920
### ________________________________________________________________________________
### dropout (Dropout)                   (None, 512)                     0
### ________________________________________________________________________________
### dense (Dense)                       (None, 10)                      5130
### ================================================================================
### Total params: 407,050
### Trainable params: 407,050
### Non-trainable params: 0
### ________________________________________________________________________________
### 

```

#### ä¿å­˜æ•´ä¸ªæ¨¡å‹

è°ƒç”¨*save_model_\** å°†æ¨¡å‹çš„æ¶æ„ã€æƒé‡å’Œè®­ç»ƒé…ç½®ä¿å­˜åœ¨å•ä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹ä¸­ã€‚è¿™å…è®¸æ‚¨å¯¼å‡ºæ¨¡å‹ï¼Œä»¥ä¾¿åœ¨ä¸è®¿é—®åŸå§‹ä»£ç çš„æƒ…å†µä¸‹ä½¿ç”¨å®ƒã€‚ç”±äºä¼˜åŒ–å™¨çŠ¶æ€å·²ç»æ¢å¤ï¼Œæ‚¨å¯ä»¥ä»ä¸­æ–­çš„ä½ç½®æ¢å¤è®­ç»ƒã€‚

ä¿å­˜æ¨¡å‹çš„å¸¸ç”¨å‡½æ•°åŠå…¶åŠ è½½å‡½æ•°ï¼š
- save_model_hdf5() å’Œ load_model_hdf5

- save_model_tf() å’Œ load_model_tf()

- save_model_weights_hdf5() å’Œ load_model_weights_hdf5():

- save_model_weights_tf() å’Œ load_model_weights_tf():

ä¿å­˜ä¸€ä¸ªå…¨åŠŸèƒ½æ¨¡å‹æ˜¯éå¸¸æœ‰ç”¨çš„â€”â€”ä½ å¯ä»¥åœ¨TensorFlow.js (HDF5, Saved Model)ä¸­åŠ è½½å®ƒä»¬ï¼Œç„¶ååœ¨webæµè§ˆå™¨ä¸­è®­ç»ƒå’Œè¿è¡Œå®ƒä»¬ï¼Œæˆ–è€…ä½¿ç”¨TensorFlow Lite (HDF5, Saved Nodel)å°†å®ƒä»¬è½¬æ¢åˆ°ç§»åŠ¨è®¾å¤‡ä¸Šè¿è¡Œã€‚

#### SAVEDMODELæ ¼å¼

SavedModelæ ¼å¼æ˜¯ä¸€ç§åºåˆ—åŒ–æ¨¡å‹çš„æ–¹æ³•ã€‚ä»¥è¿™ç§æ ¼å¼ä¿å­˜çš„æ¨¡å‹å¯ä»¥ä½¿ç”¨*load_model_t()*æ¢å¤ï¼Œå¹¶ä¸”ä¸TensorFlowæœåŠ¡å…¼å®¹ã€‚[SavedModelæŒ‡å—]è¯¦ç»†ä»‹ç»äº†å¦‚ä½•æœåŠ¡/æ£€æŸ¥SavedModelã€‚ä¸‹é¢çš„éƒ¨åˆ†æ¼”ç¤ºäº†ä¿å­˜å’Œæ¢å¤æ¨¡å‹çš„æ­¥éª¤ã€‚ä¸‹é¢çš„éƒ¨åˆ†æ¼”ç¤ºäº†ä¿å­˜å’Œæ¢å¤æ¨¡å‹çš„æ­¥éª¤ã€‚

```r
model <- create_model()

model %>% fit(train_images, train_labels, epochs = 5, verbose = 2)

### SavedModel æ ¼å¼æ˜¯ä¸€ä¸ªåŒ…å«protobufäºŒè¿›åˆ¶æ–‡ä»¶å’ŒTensorflowæ£€æŸ¥ç‚¹çš„ç›®å½•ã€‚
model %>% save_model_tf("model")
##æ£€æŸ¥ä¿å­˜çš„æ¨¡å‹ç›®å½•:
list.files("model")

### ä»ä¿å­˜çš„æ¨¡å‹ä¸­é‡æ–°åŠ è½½ä¸€ä¸ªæ–°çš„Kerasæ¨¡å‹:
new_model <- load_model_tf("model")
summary(new_model)
```

#### HDF5æ ¼å¼

Kerasä½¿ç”¨HDF5æ ‡å‡†æä¾›äº†åŸºæœ¬çš„ä¿å­˜æ ¼å¼ã€‚

```r
model <- create_model()
model %>% fit(train_images, train_labels, epochs = 5, verbose = 2)

model %>% save_model_hdf5("my_model.h5")

### ç°åœ¨ä»æ–‡ä»¶ä¸­é‡æ–°åˆ›å»ºæ¨¡å‹:
new_model <- load_model_hdf5("my_model.h5")
summary(new_model)
```
è¿™ç§æŠ€æœ¯å¯ä»¥ä¿å­˜æ‰€æœ‰ä¿¡æ¯ï¼š

- æƒé‡å€¼

- æ¨¡å‹çš„é…ç½®ï¼ˆæ¶æ„ï¼‰

- ä¼˜åŒ–å™¨é…ç½®

Kerasçš„SavedModelé€šè¿‡æ£€æŸ¥æ¶æ„æ¥ä¿å­˜æ¨¡å‹ã€‚ç›®å‰ï¼ŒSavedModelä¸èƒ½ä¿å­˜TensorFlowä¼˜åŒ–å™¨(åœ¨tf$trainä¸­)ã€‚åœ¨ä½¿ç”¨SavedModelæ—¶ï¼Œæ‚¨å°†éœ€è¦åœ¨åŠ è½½åé‡æ–°ç¼–è¯‘æ¨¡å‹ï¼Œå¹¶ä¸”æ‚¨å°†ä¸¢å¤±ä¼˜åŒ–å™¨çš„çŠ¶æ€ã€‚

#### ä¿å­˜è‡ªå®šä¹‰å¯¹è±¡

å¦‚æœæ‚¨ä½¿ç”¨SavedModelæ ¼å¼ï¼Œåˆ™å¯ä»¥è·³è¿‡æœ¬èŠ‚ã€‚HDF5å’ŒSavedModelçš„å…³é”®åŒºåˆ«åœ¨äºï¼ŒHDF5ä½¿ç”¨å¯¹è±¡é…ç½®æ¥ä¿å­˜æ¨¡å‹æ¶æ„ï¼Œè€ŒSavedModelåˆ™ä¿å­˜æ‰§è¡Œå›¾ã€‚

å› æ­¤ï¼ŒSavedModelsèƒ½å¤Ÿä¿å­˜è‡ªå®šä¹‰å¯¹è±¡ï¼Œå¦‚å­ç±»æ¨¡å‹å’Œè‡ªå®šä¹‰å±‚ï¼Œè€Œä¸éœ€è¦åŸå§‹ä»£ç ã€‚

è¦å°†è‡ªå®šä¹‰å¯¹è±¡ä¿å­˜åˆ°HDF5ï¼Œå¿…é¡»æ‰§è¡Œä»¥ä¸‹æ“ä½œ:

1. åœ¨å¯¹è±¡ä¸­å®šä¹‰ä¸€ä¸ªget_configæ–¹æ³•ï¼Œè¿˜æœ‰ä¸€ä¸ªfrom_configç±»æ–¹æ³•ã€‚

    - get_config()è¿”å›ä¸€ä¸ªjsonå¯åºåˆ—åŒ–çš„å‚æ•°å­—å…¸ï¼Œå…¶ä¸­åŒ…å«é‡æ–°åˆ›å»ºå¯¹è±¡æ‰€éœ€çš„å‚æ•°ã€‚

    - from_config(config)ä½¿ç”¨ä»get_config()è¿”å›çš„é…ç½®æ¥åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è±¡ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¯¥å‡½æ•°å°†ä½¿ç”¨configä½œä¸ºåˆå§‹åŒ–å‚æ•°ã€‚

2. åœ¨åŠ è½½æ¨¡å‹æ—¶å°†å¯¹è±¡ä¼ é€’ç»™*custom_objects*å‚æ•°ã€‚å‚æ•°å¿…é¡»æ˜¯ä¸€ä¸ªå°†å­—ç¬¦ä¸²ç±»åæ˜ å°„åˆ°ç±»å®šä¹‰çš„å‘½ååˆ—è¡¨ã€‚ä¾‹å¦‚ load_keras_model_hdf5(path, custom_objects=list("CustomLayer" = CustomLayer)) 

å…³äºcustom_objects()å’Œget_config()çš„ç¤ºä¾‹ï¼Œè¯·å‚é˜…[ä»å¤´ç¼–å†™å±‚å’Œæ¨¡å‹æ•™ç¨‹]ï¼Œ**è²Œä¼¼è¿™éƒ¨åˆ†å†…å®¹è¿˜æ²¡å®Œæˆ**ã€‚


#### åœ¨è®­ç»ƒæœŸé—´ä¿å­˜æ£€æŸ¥ç‚¹

åœ¨è®­ç»ƒæœŸé—´å’Œç»“æŸæ—¶è‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸€ä¸ªè®­ç»ƒè¿‡çš„æ¨¡å‹ï¼Œè€Œä¸å¿…é‡æ–°è®­ç»ƒå®ƒï¼Œæˆ–è€…åœ¨ä½ ç¦»å¼€çš„åœ°æ–¹æ¥ä¸Šè®­ç»ƒï¼Œä»¥é˜²è®­ç»ƒè¿‡ç¨‹ä¸­æ–­ã€‚

callback_model_checkpointæ˜¯æ‰§è¡Œæ­¤ä»»åŠ¡çš„å›è°ƒå‡½æ•°ã€‚

å›è°ƒå‡½æ•°æ¥å—ä¸¤ä¸ªå‚æ•°æ¥é…ç½®æ£€æŸ¥ç‚¹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œsave_weights_onlyè®¾ç½®ä¸ºfalseï¼Œè¿™æ„å‘³ç€ä¿å­˜å®Œæ•´çš„æ¨¡å‹â€”â€”åŒ…æ‹¬æ¶æ„å’Œé…ç½®ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥æŒ‰ç…§å‰ä¸€æ®µæ‰€è¿°çš„æ–¹å¼æ¢å¤æ¨¡å‹ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä¸“æ³¨äºä¿å­˜å’Œæ¢å¤æƒé‡ã€‚åœ¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬å°†save_weights_onlyè®¾ç½®ä¸ºtrueï¼Œå› æ­¤åœ¨æ¢å¤æ—¶éœ€è¦æ¨¡å‹å®šä¹‰ã€‚


##### ä½¿ç”¨æ£€æŸ¥ç‚¹å›è°ƒ

è®­ç»ƒæ¨¡å‹å¹¶ç»™å®ƒä¼ é€’callback_model_checkpoint:

```r
checkpoint_path <- "checkpoints/cp.ckpt"

# Create checkpoint callback
cp_callback <- callback_model_checkpoint(
  filepath = checkpoint_path,
  save_weights_only = TRUE,
  verbose = 0
)

model <- create_model()

model %>% fit(
  train_images,
  train_labels,
  epochs = 10, 
  validation_data = list(test_images, test_labels),
  callbacks = list(cp_callback),  # pass callback to training
  verbose = 2
)
```
æ£€æŸ¥åˆ›å»ºçš„æ–‡ä»¶:

```r
list.files(dirname(checkpoint_path))
```
åˆ›å»ºä¸€ä¸ªæ–°çš„æœªç»è®­ç»ƒçš„æ¨¡å‹ã€‚å½“ä»…ä»æƒé‡æ¢å¤æ¨¡å‹æ—¶ï¼Œæ‚¨å¿…é¡»æ‹¥æœ‰ä¸åŸå§‹æ¨¡å‹å…·æœ‰ç›¸åŒæ¶æ„çš„æ¨¡å‹ã€‚ç”±äºå®ƒæ˜¯ç›¸åŒçš„æ¨¡å‹æ¶æ„ï¼Œæˆ‘ä»¬å¯ä»¥å…±äº«æƒé‡ï¼Œå°½ç®¡å®ƒæ˜¯æ¨¡å‹çš„ä¸åŒå®ä¾‹ã€‚

ç°åœ¨é‡å»ºä¸€ä¸ªæ–°çš„ï¼Œæœªç»è®­ç»ƒçš„æ¨¡å‹ï¼Œå¹¶åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°å®ƒã€‚æœªç»è®­ç»ƒçš„æ¨¡å‹å°†åœ¨æ¦‚ç‡æ°´å¹³(~7% ç²¾ç¡®åº¦)æ‰§è¡Œ:

```r
fresh_model <- create_model()
fresh_model %>% evaluate(test_images, test_labels, verbose = 0)
###     loss accuracy
### 2.326613 0.069000

```

ç„¶åä»æœ€æ–°çš„æ£€æŸ¥ç‚¹(epoch 10)åŠ è½½æƒé‡ï¼Œå¹¶é‡æ–°è¯„ä¼°:

```r
fresh_model %>% load_model_weights_tf(filepath = checkpoint_path)
fresh_model %>% evaluate(test_images, test_labels, verbose = 0)
###      loss  accuracy
### 0.4079803 0.8700000

```

##### æ£€æŸ¥ç‚¹å›è°ƒé€‰é¡¹

å¦å¤–ï¼Œæ‚¨å¯ä»¥å†³å®šä»…ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œæœ€ä½³æ¨¡å‹å®šä¹‰ä¸ºéªŒè¯æŸå¤±æœ€å°ã€‚ æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§[callback_model_checkpointçš„æ–‡æ¡£]ã€‚

```r
checkpoint_path <- "checkpoints/cp.ckpt"

# Create checkpoint callback
cp_callback <- callback_model_checkpoint(
  filepath = checkpoint_path,
  save_weights_only = TRUE,
  save_best_only = TRUE,
  verbose = 1
)

model <- create_model()

model %>% fit(
  train_images,
  train_labels,
  epochs = 10, 
  validation_data = list(test_images, test_labels),
  callbacks = list(cp_callback), # pass callback to training,
  verbose = 2
)

list.files(dirname(checkpoint_path))
```

##### è¿™äº›æ–‡ä»¶æ˜¯ä»€ä¹ˆ?

ä¸Šä¸Šé¢çš„ä»£ç å°†æƒé‡å­˜å‚¨åˆ°[æ£€æŸ¥ç‚¹æ ¼å¼] ([checkpoint-formatted])çš„æ–‡ä»¶é›†åˆä¸­ï¼Œè¿™äº›æ–‡ä»¶ä»…ä»¥äºŒè¿›åˆ¶æ ¼å¼åŒ…å«è®­ç»ƒè¿‡çš„æƒé‡ã€‚ æ£€æŸ¥ç‚¹åŒ…å«ï¼š

- ä¸€ä¸ªæˆ–å¤šä¸ªåŒ…å«æ¨¡å‹æƒé‡çš„ç¢ç‰‡ã€‚

- ä¸€ä¸ªç´¢å¼•æ–‡ä»¶ï¼ŒæŒ‡ç¤ºå“ªäº›æƒé‡å­˜å‚¨åœ¨å“ªä¸ªåˆ†ç‰‡ä¸­ã€‚

å¦‚æœæ‚¨ä»…åœ¨ä¸€å°æœºå™¨ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œåˆ™åç¼€ä¸º *.s-data-00000-of-00001*ã€‚

#### æ‰‹åŠ¨ä¿å­˜æƒé‡

æ‚¨äº†è§£äº†å¦‚ä½•å°†æƒé‡åŠ è½½åˆ°æ¨¡å‹ä¸­ã€‚æ‰‹åŠ¨ä¿å­˜å®ƒä»¬ä½¿ç”¨save_model_weights_tfå‡½æ•°ä¹Ÿä¸€æ ·ç®€å•ã€‚

```r
# ä¿å­˜æƒé‡
model %>% save_model_weights_tf("checkpoints/cp.ckpt")

# åˆ›å»ºä¸€ä¸ªæ–°çš„æ¨¡å‹å®ä¾‹
new_model <- create_model()

# æ¢å¤æƒé‡è¿›å…¥ç¿»è¯‘é¡µé¢
new_model %>% load_model_weights_tf('checkpoints/cp.ckpt')

# è¯„ä»·æ¨¡å‹
new_model %>% evaluate(test_images, test_labels, verbose = 0)
###     loss accuracy
###  0.39937  0.86800

```


[TensorFlow Save and Restore guide]:https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_save_and_restore/todo
[Saving in eager]:https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_save_and_restore/todo
[SavedModelæŒ‡å—]:https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_save_and_restore/todo
[ä»å¤´ç¼–å†™å±‚å’Œæ¨¡å‹æ•™ç¨‹]:https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_save_and_restore/todo
[callback_model_checkpointçš„æ–‡æ¡£]:https://tensorflow.rstudio.com/keras/reference/callback_model_checkpoint.html
[æ£€æŸ¥ç‚¹æ ¼å¼]:https://www.tensorflow.org/guide/saved_model#save_and_restore_variables
[checkpoint-formatted]:https://www.tensorflow.org/guide/saved_model#save_and_restore_variables
[R Interface to Tensorflow]:https://tensorflow.rstudio.com/guide/keras/